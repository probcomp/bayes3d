{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa6d7ec7",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ef7da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import bayes3d as b\n",
    "import trimesh\n",
    "import os\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import jax\n",
    "import cv2\n",
    "\n",
    "\n",
    "# --- creating the model dir from the working directory\n",
    "model_dir = os.path.join(j.utils.get_assets_dir(), \"ycb_video_models/models\")\n",
    "print(f\"{model_dir} exists: {os.path.exists(model_dir)}\")\n",
    "model_names = j.ycb_loader.MODEL_NAMES\n",
    "model_paths = [os.path.join(model_dir,name,\"textured.obj\") for name in model_names]\n",
    "\n",
    "bop_ycb_dir = os.path.join(j.utils.get_assets_dir(), \"bop/ycbv\")\n",
    "rgbd, gt_ids, gt_poses, masks = j.ycb_loader.get_test_img('52', '1', bop_ycb_dir)\n",
    "intrinsics = j.Intrinsics(\n",
    "    height=rgbd.intrinsics.height,\n",
    "    width=rgbd.intrinsics.width,\n",
    "    fx=rgbd.intrinsics.fx, fy=rgbd.intrinsics.fx,\n",
    "    cx=rgbd.intrinsics.width/2.0, cy=rgbd.intrinsics.height/2.0,\n",
    "    near=0.001, far=3.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = j.Renderer(rgbd.intrinsics, num_layers=25)\n",
    "model_dir = os.path.join(j.utils.get_assets_dir(), \"bop/ycbv/models\")\n",
    "model_names = [\"obj_\" + f\"{str(idx+1).rjust(6, '0')}.ply\" for idx in range(21)]\n",
    "mesh_paths = []\n",
    "for name in model_names:\n",
    "    mesh_path = os.path.join(model_dir,name)\n",
    "    mesh_paths.append(mesh_path)\n",
    "    model_scaling_factor = 1.0/1000.0\n",
    "    renderer.add_mesh_from_file(\n",
    "        mesh_path,\n",
    "        scaling_factor=model_scaling_factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab635f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pose = j.t3d.transform_from_pos_target_up(\n",
    "    jnp.array([0.5, 0.5, 0.5]),\n",
    "    jnp.array([0.0, 0.0, 0.0]),\n",
    "    jnp.array([0.0, 0.0, 1.0]),\n",
    ")\n",
    "object_pose = j.t3d.inverse_pose(camera_pose)\n",
    "object_pose2 = object_pose @ j.t3d.transform_from_pos(jnp.array([0.1, 0.1, 0.0]))\n",
    "object_poses = jnp.array([object_pose, object_pose2])\n",
    "IDX = 13\n",
    "IDX2 = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e11e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = j.kubric_interface.render_multiobject_parallel([model_paths[IDX],model_paths[IDX2]], object_poses[:,None,...], intrinsics, scaling_factor=1.0, lighting=3.0) # multi img singleobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a21ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd = all_data[0]\n",
    "j.get_rgb_image(rgbd.rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c51dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function taking the rbgd rgb and intrinstics as well as the renderer and returning the cosypose prediction \n",
    "def cosypose_pred(rgb, intrinsics, renderer):\n",
    "    pred = j.cosypose_utils.cosypose_interface(rgb, j.K_from_intrinsics(intrinsics))\n",
    "    pred_poses, pred_ids, pred_scores = pred['pred_poses'], pred['pred_ids'], pred['pred_scores']\n",
    "    rendered = renderer.render_multiobject(jnp.array(pred_poses[0]), jnp.array(pred_ids[0]))\n",
    "    return j.get_depth_image(rendered[:,:,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f20487",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosypose_pred(rgbd.rgb, rgbd.intrinsics, renderer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efdfc7fb",
   "metadata": {},
   "source": [
    "## Breaking CosyPose, Image Variations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "528dae53",
   "metadata": {},
   "source": [
    "1. lighting variations or illumination changes\n",
    "2. Gaussian noise to rgb or low resolution (failing)\n",
    "    - Reconstruction breaks down even with 0.5 scaling \n",
    "3. Partially off screen (passing)\n",
    "4. Partially occluded by another object (passing)\n",
    "5. Complex Backgrounds\n",
    "6. Warping \n",
    "7. Others \n",
    "    6.1. Multiple Identical Objects: Passes "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc995ad9",
   "metadata": {},
   "source": [
    "### gaussian noise, low resolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf764ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(img, mean=0, variance=100):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to an image.\n",
    "\n",
    "    Parameters:\n",
    "    img (numpy.ndarray): Input image as a NumPy array.\n",
    "    mean (float, optional): Mean of the Gaussian noise. Default is 0.\n",
    "    variance (float, optional): Variance of the Gaussian noise. Default is 0.1.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The noisy image as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Add Gaussian noise\n",
    "    noise = np.random.normal(mean, variance**0.5, img.shape)\n",
    "    noisy_img = np.clip(img + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return noisy_img\n",
    "\n",
    "def make_low_resolution(img, scale_factor=0.5):\n",
    "    \"\"\"\n",
    "    Create a low-resolution version of an image by downsampling and upsampling.\n",
    "\n",
    "    Parameters:\n",
    "    img (numpy.ndarray): Input image as a NumPy array.\n",
    "    scale_factor (float, optional): The scale factor to downsample and upsample the image. Default is 0.5.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The low-resolution image as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Downsample the image\n",
    "    downsampled_img = cv2.resize(img, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Upsample the image\n",
    "    low_res_img = cv2.resize(downsampled_img, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    return low_res_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pose = j.t3d.transform_from_pos_target_up(\n",
    "    jnp.array([0.5, 0.5, 0.5]),\n",
    "    jnp.array([0.0, 0.0, 0.0]),\n",
    "    jnp.array([0.0, 0.0, 1.0]),\n",
    ")\n",
    "# object poses in camera frame\n",
    "object_pose = j.t3d.inverse_pose(camera_pose)\n",
    "\n",
    "# list of positions from 0.1, 0.1 to 0.2, 0.2\n",
    "poses_list = []\n",
    "for i in range(3):\n",
    "    for k in range(3):\n",
    "        poses_list.append(object_pose @ j.t3d.transform_from_pos(jnp.array([0.1*i, 0.1*k, 0.0])))\n",
    "\n",
    "object_poses = jnp.array(poses_list)\n",
    "\n",
    "# testing a variety of models \n",
    "idx_list = [i for i in range(10,19)]\n",
    "m_paths = [] \n",
    "for idx in idx_list:\n",
    "    m_paths.append(model_paths[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = j.kubric_interface.render_multiobject_parallel(m_paths, object_poses[:,None,...], intrinsics, scaling_factor=1.0, lighting=3.0) # multi img singleobj\n",
    "rgbd = all_data[0]\n",
    "j.get_rgb_image(rgbd.rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = add_gaussian_noise(rgbd.rgb, variance=1200)\n",
    "j.get_rgb_image(gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8355999",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosypose_pred(gauss, rgbd.intrinsics, renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1218102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res = make_low_resolution(rgbd.rgb, scale_factor=.5)\n",
    "j.get_rgb_image(low_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosypose_pred(low_res, rgbd.intrinsics, renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c634b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_low_res = make_low_resolution(gauss, scale_factor=.25)\n",
    "low_res_gauss = add_gaussian_noise(low_res, variance=300)\n",
    "j.get_rgb_image(gauss_low_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3562a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosypose_pred(gauss_, rgbd.intrinsics, renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf5d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "j.get_rgb_image(low_res_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513061e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = j.cosypose_utils.cosypose_interface(low_res_gauss, j.K_from_intrinsics(rgbd.intrinsics))\n",
    "pred_poses, pred_ids, pred_scores = pred['pred_poses'], pred['pred_ids'], pred['pred_scores']\n",
    "rendered = renderer.render_multiobject(jnp.array(pred_poses[0]), jnp.array(pred_ids[0]))\n",
    "j.get_depth_image(rendered[:,:,2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b67dd7f",
   "metadata": {},
   "source": [
    "### Partially Occuluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c7f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import bayes3d as b\n",
    "import trimesh\n",
    "import os\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import jax\n",
    "\n",
    "\n",
    "# --- creating the model dir from the working directory\n",
    "model_dir = os.path.join(j.utils.get_assets_dir(), \"ycb_video_models/models\")\n",
    "print(f\"{model_dir} exists: {os.path.exists(model_dir)}\")\n",
    "model_names = j.ycb_loader.MODEL_NAMES\n",
    "model_paths = [os.path.join(model_dir,name,\"textured.obj\") for name in model_names]\n",
    "\n",
    "bop_ycb_dir = os.path.join(j.utils.get_assets_dir(), \"bop/ycbv\")\n",
    "rgbd, gt_ids, gt_poses, masks = j.ycb_loader.get_test_img('52', '1', bop_ycb_dir)\n",
    "intrinsics = j.Intrinsics(\n",
    "    height=rgbd.intrinsics.height,\n",
    "    width=rgbd.intrinsics.width,\n",
    "    fx=rgbd.intrinsics.fx, fy=rgbd.intrinsics.fx,\n",
    "    cx=rgbd.intrinsics.width/2.0, cy=rgbd.intrinsics.height/2.0,\n",
    "    near=0.001, far=3.0\n",
    ")\n",
    "renderer = j.Renderer(rgbd.intrinsics, num_layers=25)\n",
    "model_dir = os.path.join(j.utils.get_assets_dir(), \"bop/ycbv/models\")\n",
    "model_names = [\"obj_\" + f\"{str(idx+1).rjust(6, '0')}.ply\" for idx in range(21)]\n",
    "mesh_paths = []\n",
    "for name in model_names:\n",
    "    mesh_path = os.path.join(model_dir,name)\n",
    "    mesh_paths.append(mesh_path)\n",
    "    model_scaling_factor = 1.0/1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da72360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poses\n",
    "camera_pose = j.t3d.transform_from_pos_target_up(\n",
    "    jnp.array([0.5, 0.5, 0.5]),\n",
    "    jnp.array([0.0, 0.0, 0.0]),\n",
    "    jnp.array([0.0, 0.0, 1.0]),\n",
    ")\n",
    "# object poses in camera frame\n",
    "object_pose = j.t3d.inverse_pose(camera_pose)\n",
    "\n",
    "# list of positions from 0.1, 0.1 to 0.2, 0.2\n",
    "poses_list = []\n",
    "for i in range(3):\n",
    "    for k in range(3):\n",
    "        poses_list.append(object_pose @ j.t3d.transform_from_pos(jnp.array([0.1*i, 0.1*k, 0.0])))\n",
    "\n",
    "object_poses = jnp.array(poses_list)\n",
    "\n",
    "# model paths \n",
    "# a list from one to nine \n",
    "idx_list = [i for i in range(10,19)]\n",
    "\n",
    "#add model paths to list based on idx_list\n",
    "m_paths = [] \n",
    "for idx in idx_list:\n",
    "    m_paths.append(model_paths[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebc8e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = j.kubric_interface.render_multiobject_parallel(m_paths, object_poses[:,None,...], intrinsics, scaling_factor=1.0, lighting=3.0) # multi img singleobj\n",
    "rgbd = all_data[0]\n",
    "j.get_rgb_image(rgbd.rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da4d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = j.cosypose_utils.cosypose_interface(np.array(rgbd.rgb), j.K_from_intrinsics(rgbd.intrinsics))\n",
    "pred_poses, pred_ids, pred_scores = pred['pred_poses'], pred['pred_ids'], pred['pred_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee796238",
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered = renderer.render_multiobject(jnp.array(pred_poses[0]), jnp.array(pred_ids[0]))\n",
    "j.get_depth_image(rendered[:,:,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
