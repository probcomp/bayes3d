{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566eb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/bayes3d')\n",
    "sys.path.append('/workspace/nvdiffrast')\n",
    "sys.path.append('/workspace/nvdiffrast/samples/torch')  # for `import util`\n",
    "# sys.path.append('/workspace/nvdiffrast/nvdiffrast/torch')  # for 'nvdiffrast.torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07bb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup within Docker environment\n",
    "# !pip install -e /workspace/bayes3d\n",
    "## !pip install -e /workspace/nvdiffrast/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23bced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import torch\n",
    "import imageio\n",
    "import util\n",
    "import bayes3d as b\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b917b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.t3d # sanity check import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2af2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvdiffrast.torch as dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter           = 10000\n",
    "repeats            = 1\n",
    "log_interval       = 10\n",
    "display_interval   = None\n",
    "display_res        = 512\n",
    "lr_base            = 1e-3\n",
    "lr_falloff         = 1.0\n",
    "nr_base            = 1.0\n",
    "nr_falloff         = 1e-4\n",
    "grad_phase_start   = 0.5\n",
    "resolution         = 256\n",
    "out_dir            = None\n",
    "log_fn             = None\n",
    "mp4save_interval   = None\n",
    "mp4save_fn         = None\n",
    "use_opengl         = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340387a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "glctx = dr.RasterizeGLContext() #if use_opengl else dr.RasterizeCudaContext()\n",
    "mvp = torch.tensor(np.matmul(util.projection(x=0.4), util.translate(0, 0, -3.5)).astype(np.float32), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5918520",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Quaternion math.\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "# Unit quaternion.\n",
    "def q_unit():\n",
    "    return np.asarray([1, 0, 0, 0], np.float32)\n",
    "\n",
    "# Get a random normalized quaternion.\n",
    "def q_rnd():\n",
    "    u, v, w = np.random.uniform(0.0, 1.0, size=[3])\n",
    "    v *= 2.0 * np.pi\n",
    "    w *= 2.0 * np.pi\n",
    "    return np.asarray([(1.0-u)**0.5 * np.sin(v), (1.0-u)**0.5 * np.cos(v), u**0.5 * np.sin(w), u**0.5 * np.cos(w)], np.float32)\n",
    "\n",
    "# Get a random quaternion from the octahedral symmetric group S_4.\n",
    "_r2 = 0.5**0.5\n",
    "_q_S4 = [[ 1.0, 0.0, 0.0, 0.0], [ 0.0, 1.0, 0.0, 0.0], [ 0.0, 0.0, 1.0, 0.0], [ 0.0, 0.0, 0.0, 1.0],\n",
    "         [-0.5, 0.5, 0.5, 0.5], [-0.5,-0.5,-0.5, 0.5], [ 0.5,-0.5, 0.5, 0.5], [ 0.5, 0.5,-0.5, 0.5],\n",
    "         [ 0.5, 0.5, 0.5, 0.5], [-0.5, 0.5,-0.5, 0.5], [ 0.5,-0.5,-0.5, 0.5], [-0.5,-0.5, 0.5, 0.5],\n",
    "         [ _r2,-_r2, 0.0, 0.0], [ _r2, _r2, 0.0, 0.0], [ 0.0, 0.0, _r2, _r2], [ 0.0, 0.0,-_r2, _r2],\n",
    "         [ 0.0, _r2, _r2, 0.0], [ _r2, 0.0, 0.0,-_r2], [ _r2, 0.0, 0.0, _r2], [ 0.0,-_r2, _r2, 0.0],\n",
    "         [ _r2, 0.0, _r2, 0.0], [ 0.0, _r2, 0.0, _r2], [ _r2, 0.0,-_r2, 0.0], [ 0.0,-_r2, 0.0, _r2]]\n",
    "def q_rnd_S4():\n",
    "    return np.asarray(_q_S4[np.random.randint(24)], np.float32)\n",
    "\n",
    "# Quaternion slerp.\n",
    "def q_slerp(p, q, t):\n",
    "    d = np.dot(p, q)\n",
    "    if d < 0.0:\n",
    "        q = -q\n",
    "        d = -d\n",
    "    if d > 0.999:\n",
    "        a = p + t * (q-p)\n",
    "        return a / np.linalg.norm(a)\n",
    "    t0 = np.arccos(d)\n",
    "    tt = t0 * t\n",
    "    st = np.sin(tt)\n",
    "    st0 = np.sin(t0)\n",
    "    s1 = st / st0\n",
    "    s0 = np.cos(tt) - d*s1\n",
    "    return s0*p + s1*q\n",
    "\n",
    "# Quaterion scale (slerp vs. identity quaternion).\n",
    "def q_scale(q, scl):\n",
    "    return q_slerp(q_unit(), q, scl)\n",
    "\n",
    "# Quaternion product.\n",
    "def q_mul(p, q):\n",
    "    s1, V1 = p[0], p[1:]\n",
    "    s2, V2 = q[0], q[1:]\n",
    "    s = s1*s2 - np.dot(V1, V2)\n",
    "    V = s1*V2 + s2*V1 + np.cross(V1, V2)\n",
    "    return np.asarray([s, V[0], V[1], V[2]], np.float32)\n",
    "\n",
    "# Angular difference between two quaternions in degrees.\n",
    "def q_angle_deg(p, q):\n",
    "    p = p.detach().cpu().numpy()\n",
    "    q = q.detach().cpu().numpy()\n",
    "    d = np.abs(np.dot(p, q))\n",
    "    d = min(d, 1.0)\n",
    "    return np.degrees(2.0 * np.arccos(d))\n",
    "\n",
    "# Quaternion product\n",
    "def q_mul_torch(p, q):\n",
    "    a = p[0]*q[0] - p[1]*q[1] - p[2]*q[2] - p[3]*q[3]\n",
    "    b = p[0]*q[1] + p[1]*q[0] + p[2]*q[3] - p[3]*q[2]\n",
    "    c = p[0]*q[2] + p[2]*q[0] + p[3]*q[1] - p[1]*q[3]\n",
    "    d = p[0]*q[3] + p[3]*q[0] + p[1]*q[2] - p[2]*q[1]\n",
    "    return torch.stack([a, b, c, d])\n",
    "\n",
    "# Convert quaternion to 4x4 rotation matrix.\n",
    "def q_to_mtx(q):\n",
    "    r0 = torch.stack([1.0-2.0*q[1]**2 - 2.0*q[2]**2, 2.0*q[0]*q[1] - 2.0*q[2]*q[3], 2.0*q[0]*q[2] + 2.0*q[1]*q[3]])\n",
    "    r1 = torch.stack([2.0*q[0]*q[1] + 2.0*q[2]*q[3], 1.0 - 2.0*q[0]**2 - 2.0*q[2]**2, 2.0*q[1]*q[2] - 2.0*q[0]*q[3]])\n",
    "    r2 = torch.stack([2.0*q[0]*q[2] - 2.0*q[1]*q[3], 2.0*q[1]*q[2] + 2.0*q[0]*q[3], 1.0 - 2.0*q[0]**2 - 2.0*q[1]**2])\n",
    "    rr = torch.transpose(torch.stack([r0, r1, r2]), 1, 0)\n",
    "    rr = torch.cat([rr, torch.tensor([[0], [0], [0]], dtype=torch.float32).cuda()], dim=1) # Pad right column.\n",
    "    rr = torch.cat([rr, torch.tensor([[0, 0, 0, 1]], dtype=torch.float32).cuda()], dim=0)  # Pad bottom row.\n",
    "    return rr\n",
    "\n",
    "# Transform vertex positions to clip space\n",
    "def transform_pos(mtx, pos):\n",
    "    t_mtx = torch.from_numpy(mtx).cuda() if isinstance(mtx, np.ndarray) else mtx\n",
    "    # (x,y,z) -> (x,y,z,1)\n",
    "    posw = torch.cat([pos, torch.ones([pos.shape[0], 1]).cuda()], axis=1)\n",
    "    return torch.matmul(posw, t_mtx.t())[None, ...]\n",
    "\n",
    "def render(glctx, mtx, pos, pos_idx, col, col_idx, resolution: int):\n",
    "    # Setup TF graph for reference.\n",
    "    depth_ = pos[..., 2:3]\n",
    "    depth = torch.tensor([[[(z_val/1)] for z_val in depth_.squeeze()]], dtype=torch.float32).cuda()\n",
    "    pos_clip    = transform_pos(mtx, pos)\n",
    "    rast_out, _ = dr.rasterize(glctx, pos_clip, pos_idx, resolution=[resolution, resolution])\n",
    "    color   , _ = dr.interpolate(depth, rast_out, pos_idx)\n",
    "    # color       = dr.antialias(color, rast_out, pos_clip, pos_idx)\n",
    "    return color\n",
    "    # return rast_out[:,:,:,2:3]\n",
    "    \n",
    "\n",
    "    \n",
    "################  Added  ######################\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# Convert quaternion and position vector to 4x4 rotation matrix.\n",
    "def q_v_to_mtx(q, v):\n",
    "    r0 = torch.stack([1.0-2.0*q[1]**2 - 2.0*q[2]**2, 2.0*q[0]*q[1] - 2.0*q[2]*q[3], 2.0*q[0]*q[2] + 2.0*q[1]*q[3]])\n",
    "    r1 = torch.stack([2.0*q[0]*q[1] + 2.0*q[2]*q[3], 1.0 - 2.0*q[0]**2 - 2.0*q[2]**2, 2.0*q[1]*q[2] - 2.0*q[0]*q[3]])\n",
    "    r2 = torch.stack([2.0*q[0]*q[2] - 2.0*q[1]*q[3], 2.0*q[1]*q[2] + 2.0*q[0]*q[3], 1.0 - 2.0*q[0]**2 - 2.0*q[1]**2])\n",
    "    rr = torch.transpose(torch.stack([r0, r1, r2]), 1, 0)\n",
    "    rr = torch.cat([rr, torch.reshape(v, (3,1))], dim=1) \n",
    "    rr = torch.cat([rr, torch.tensor([[0, 0, 0, 1]], dtype=torch.float32).cuda()], dim=0)  # Pad bottom row.\n",
    "    return rr\n",
    "\n",
    "# Convert quaternion and position vector to 4x4 rotation matrix.\n",
    "def q_v_to_mtx_batch(qs, vs):\n",
    "    return torch.stack([q_v_to_mtx(q, v) for q,v in zip(qs, vs)])\n",
    "\n",
    "\n",
    "# Get a random position near the origin.\n",
    "def v_rnd():\n",
    "    x, y, z = np.random.uniform(-0.005, 0.005, size=[3])\n",
    "    return np.asarray([x, y, z], np.float32)\n",
    "\n",
    "# Multiple renders\n",
    "def render_multiple(glctx, poses, vtx_pos, pos_idx, vtx_col, col_idx, resolution):\n",
    "    ret = torch.cat([render(glctx, pose, vtx_pos, \n",
    "                             pos_idx, vtx_col, \n",
    "                             col_idx, resolution) for pose in poses], axis=0)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/workspace/nvdiffrast/samples/data/\"\n",
    "with np.load(f'{datadir}/cube_p.npz') as f:\n",
    "    pos_idx, pos, col_idx, col = f.values()\n",
    "print(\"Mesh has %d triangles and %d vertices.\" % (pos_idx.shape[0], pos.shape[0]))\n",
    "\n",
    "# Some input geometry contains vertex positions in (N, 4) (with v[:,3]==1).  Drop\n",
    "# the last column in that case.\n",
    "if pos.shape[1] == 4: pos = pos[:, 0:3]\n",
    "\n",
    "# Create position/triangle index tensors\n",
    "pos_idx = torch.from_numpy(pos_idx.astype(np.int32)).cuda()\n",
    "vtx_pos = torch.from_numpy(pos.astype(np.float32)).cuda()\n",
    "col_idx = torch.from_numpy(col_idx.astype(np.int32)).cuda()\n",
    "vtx_col = torch.from_numpy(col.astype(np.float32)).cuda()\n",
    "\n",
    "# model_dir = os.path.join(b.utils.get_assets_dir(),\"bop/ycbv/models\")\n",
    "# idx = 14\n",
    "# mesh_path = os.path.join(model_dir,\"obj_\" + \"{}\".format(idx).rjust(6, '0') + \".ply\")\n",
    "# m = b.utils.load_mesh(mesh_path)\n",
    "# m = b.utils.scale_mesh(m, 1.0/100.0)\n",
    "\n",
    "# vtx_pos = torch.from_numpy(m.vertices.astype(np.float32)).cuda()\n",
    "# pos_idx = torch.from_numpy(m.faces.astype(np.int32)).cuda()\n",
    "# col_idx = torch.from_numpy(np.zeros((vtx_pos.shape[0],3)).astype(np.int32)).cuda()\n",
    "# vtx_col = torch.from_numpy(np.ones((1,3)).astype(np.float32)).cuda()\n",
    "# print(\"Mesh has %d triangles and %d vertices.\" % (pos_idx.shape[0], pos.shape[0]))\n",
    "# print(pos_idx.shape, vtx_pos.shape, col_idx.shape, vtx_col.shape)\n",
    "# print(vtx_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e22fa8",
   "metadata": {},
   "source": [
    "#### Setup visualization for gradients and particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7475d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIT_VECTOR = np.array([0,0,1])  # unit for viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig2img(fig):\n",
    "    \"\"\"Convert a Matplotlib figure to a PIL Image and return it\"\"\"\n",
    "    import io\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf)\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    return img\n",
    "\n",
    "def plot_polar_angles_on_frame(thetas, phis, curr_ax):\n",
    "    ax = curr_ax\n",
    "    scaling = 0.96\n",
    "    for theta in thetas:\n",
    "        for phi in phis:\n",
    "            x = np.cos(phi)*np.cos(theta)\n",
    "            y = np.cos(phi)*np.sin(theta)\n",
    "            z = np.sin(phi)\n",
    "            ax.scatter(x * scaling, y, z, s=5**2, color=\"red\", alpha=1)\n",
    "            u, v, w = 1,0,0\n",
    "#             ax.quiver(x, y, z, u, v, w, length=0.1, normalize=True, alpha=0.8)\n",
    "# _, ax = generate_sphere_plot()\n",
    "# phis = np.arange(0, np.pi, np.pi/10)\n",
    "# thetas = [0]\n",
    "# plot_polar_angles_on_frame(thetas, phis, ax)\n",
    "\n",
    "def plot_cartesian_point_on_frame(point, curr_ax, color=\"red\", alpha=1):\n",
    "    ax = curr_ax\n",
    "    x, y, z = point\n",
    "    ax.scatter(x, y, z, s=5**2, color=color, alpha=alpha)\n",
    "    \n",
    "def plot_rot_and_pos(rot_pt, pos_pt, ax_r, ax_p, color=\"red\", alpha=1, label=None, rot_title=None, pos_title=None):\n",
    "    \"\"\"Given points on the spherical coord and the cartesian coord,\n",
    "    Plot on the corresponding rotation and position axes\"\"\"\n",
    "    rx, ry, rz = rot_pt[..., 0], rot_pt[..., 1], rot_pt[..., 2]\n",
    "    px, py, pz = pos_pt[..., 0], pos_pt[..., 1], pos_pt[..., 2]\n",
    "    ax_r.scatter(rx, ry, rz, s=5**2, color=color, alpha=alpha, label=label)\n",
    "    ax_p.scatter(px, py, pz, s=5**2, color=color, alpha=alpha, label=label)\n",
    "    \n",
    "    if label is not None:\n",
    "        ax_r.legend()\n",
    "#         ax_p.legend(loc=\"upper left\")\n",
    "    if rot_title is not None:\n",
    "        ax_r.set_title(rot_title)\n",
    "    if pos_title is not None:\n",
    "        ax_p.set_title(pos_title)\n",
    "\n",
    "# _, ax = generate_sphere_plot(show_unit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c7a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sphere_plot(show_unit=False, fig_ax=None):\n",
    "    if fig_ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "    else:\n",
    "        fig, ax = fig_ax\n",
    "        \n",
    "    ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    # make the grid lines transparent\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    u, v = np.mgrid[0:2*np.pi:21j, 0:np.pi:11j]\n",
    "    x = np.cos(u)*np.sin(v)\n",
    "    y = np.sin(u)*np.sin(v)\n",
    "    z = np.cos(v)\n",
    "    ax.set_axis_off()\n",
    "    ax.axes.set_xlim3d(-1.05, 1.05) \n",
    "    ax.axes.set_ylim3d(-1.05, 1.05) \n",
    "    ax.axes.set_zlim3d(-1.05, 1.05) \n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.plot_wireframe(x, y, z, color=(0.0, 0.0, 0.0, 0.3), linewidths=0.5)\n",
    "\n",
    "    ax.axes.set_xlabel(\"x\")\n",
    "    ax.axes.set_ylabel(\"y\")\n",
    "    ax.axes.set_zlabel(\"z\")\n",
    "\n",
    "    if show_unit:\n",
    "        quat_unit = q_to_mtx(torch.tensor([1,0,0,0], device=\"cuda\", dtype=torch.float64)).cpu()[:3, :3] @ torch.tensor(UNIT_VECTOR, dtype=torch.float64) \n",
    "        ax.scatter(quat_unit[0], quat_unit[1], quat_unit[2], color=\"green\", alpha=1)\n",
    "    return fig, ax\n",
    "# _, ax = generate_sphere_plot(show_unit=True)\n",
    "\n",
    "def generate_cartesian_plot(show_unit=False, fig_ax=None):\n",
    "    if fig_ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "    else:\n",
    "        fig, ax = fig_ax\n",
    "#     ax.xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "#     ax.yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "#     ax.zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    \n",
    "    ax.axes.set_xlim3d(-1.5, 1.5) \n",
    "    ax.axes.set_ylim3d(-1.5, 1.5) \n",
    "    ax.axes.set_zlim3d(-1.5, 1.5) \n",
    "    \n",
    "    ax.axes.set_xlabel(\"x\")\n",
    "    ax.axes.set_ylabel(\"y\")\n",
    "    ax.axes.set_zlabel(\"z\")\n",
    "    \n",
    "    if show_unit:\n",
    "        ax.scatter(0.0, 0.0, 0.0, s=5**2, color=\"green\", alpha=1)\n",
    "    return fig, ax\n",
    "# _, ax = generate_cartesian_plot(True)\n",
    "\n",
    "def generate_rotation_translation_plot(show_unit=False):\n",
    "    # set up a figure twice as wide as it is tall\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "\n",
    "    # set up the axes for the first plot\n",
    "    ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    \n",
    "    # Generate the subplots\n",
    "    _, _ = generate_sphere_plot(show_unit, (fig, ax1))\n",
    "    _, _ = generate_cartesian_plot(show_unit, (fig, ax2))\n",
    "\n",
    "    # Label with title\n",
    "    ax1.set_title(\"Rotation evolution\")\n",
    "    ax2.set_title(\"Translation evolution\")\n",
    "    \n",
    "    return fig, (ax1, ax2)\n",
    "\n",
    "\n",
    "_, (ax_r, ax_t) = generate_rotation_translation_plot(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b34c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 0) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a9942",
   "metadata": {},
   "source": [
    "## Single pose hypothesis optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d09c55",
   "metadata": {},
   "source": [
    "#### Define GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT) Rotation, Position poses\n",
    "pose_rot_target = torch.tensor(q_rnd(), device='cuda')\n",
    "pose_pos_target = torch.tensor(v_rnd(), device='cuda')\n",
    "pose_target = q_v_to_mtx(pose_rot_target, pose_pos_target)\n",
    "print(\"TARGET POSE=\", pose_target)\n",
    "\n",
    "# Initial GT render\n",
    "rast_target = render(glctx, torch.matmul(mvp, pose_target), vtx_pos, pos_idx, vtx_col, col_idx, resolution)\n",
    "img_target  = rast_target[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a661233",
   "metadata": {},
   "source": [
    "#### Define hypothesis / setup GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd26396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opt) Rotation, Position poses\n",
    "pose_rot_init   = pose_rot_target.cpu().numpy() + 0.1 #+ 1.5\n",
    "pose_pos_init   = pose_pos_target.cpu().numpy() + np.random.rand(3,)/5\n",
    "\n",
    "pose_rot_opt    = torch.tensor(pose_rot_init / np.sum(pose_rot_init**2)**0.5, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "pose_pos_opt    = torch.tensor(pose_pos_init, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "print(pose_rot_opt, pose_pos_opt)\n",
    "\n",
    "pose_opt = q_v_to_mtx(pose_rot_opt, pose_pos_opt)\n",
    "print(pose_opt.shape)\n",
    "\n",
    "# initialize loss \n",
    "loss_best   = np.inf\n",
    "\n",
    "# Visualize initial state\n",
    "print(f\"target pose={pose_target},\\ncurrent pose={pose_opt}\")\n",
    "\n",
    "# Initial opt render\n",
    "rast_opt = render(glctx, torch.matmul(mvp, pose_opt), vtx_pos, pos_idx, vtx_col, col_idx, resolution)\n",
    "img_opt  = rast_opt[0].detach().cpu().numpy()\n",
    "print(rast_opt.shape, img_opt.shape)\n",
    "\n",
    "b.hstack_images([\n",
    "    b.get_depth_image(img_opt[:,:,0]* 255.0) ,\n",
    "    b.get_depth_image(img_target[:,:,0]* 255.0) ,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad7e78",
   "metadata": {},
   "source": [
    "#### Run GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b89c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descend_gradient(pose_rot_opt, pose_pos_opt, pose_target, rast_opt, rast_target, it=20, verbose=False, plot=False):\n",
    "    OPTIM_GIF_IMGS = []\n",
    "    loss_best = np.inf\n",
    "    optimizer = torch.optim.Adam([pose_rot_opt, pose_pos_opt], betas=(0.9, 0.999), lr=lr_base)\n",
    "    \n",
    "    if plot: \n",
    "        fig, (ax_r, ax_t) = generate_rotation_translation_plot(False)\n",
    "        plot_rot_and_pos(pose_opt.detach().cpu()[:3, :3] @ UNIT_VECTOR, \n",
    "                 pose_opt.detach().cpu()[:3, -1], \n",
    "                 ax_r, ax_t, \n",
    "                 color=\"green\", alpha=1, label=\"Initial\")\n",
    "        plot_rot_and_pos(pose_opt.detach().cpu()[:3, :3] @ UNIT_VECTOR, \n",
    "                         pose_opt.detach().cpu()[:3, -1], \n",
    "                         ax_r, ax_t, \n",
    "                         color=\"blue\", alpha=0.1, label=\"Hypothesis\")\n",
    "        plot_rot_and_pos(pose_target.detach().cpu()[:3, :3] @ UNIT_VECTOR, \n",
    "                         pose_target.detach().cpu()[:3, -1], \n",
    "                         ax_r, ax_t, \n",
    "                         color=\"red\", alpha=1, label=\"Target\")\n",
    "\n",
    "        \n",
    "    for i in tqdm(range(it)):\n",
    "        noise = q_unit()\n",
    "        pose_rot_total_opt = q_mul_torch(pose_rot_opt, noise)\n",
    "        mtx_total_opt  = torch.matmul(mvp, q_v_to_mtx(pose_rot_total_opt, pose_pos_opt))\n",
    "        color_opt      = render(glctx, mtx_total_opt, vtx_pos, pos_idx, vtx_col, col_idx, resolution)\n",
    "\n",
    "        diff = (rast_opt - rast_target)**2 # L2 norm.\n",
    "        diff = torch.tanh(5.0 * torch.max(diff, dim=-1)[0])\n",
    "        loss = torch.mean(diff)\n",
    "        loss_val = float(loss)\n",
    "\n",
    "        if (loss_val < loss_best) and (loss_val > 0.0):\n",
    "            loss_best = loss_val\n",
    "        if (loss_val/loss_best > 1.2):\n",
    "            break\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pose_rot_opt /= torch.sum(pose_rot_opt**2)**0.5\n",
    "\n",
    "        rast_opt = render(glctx, torch.matmul(mvp, q_v_to_mtx(pose_rot_opt, pose_pos_opt)), vtx_pos, pos_idx, vtx_col, col_idx, resolution)\n",
    "        img_opt  = rast_opt[0].detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "        if verbose:\n",
    "            print(f\"loss={loss}, rot={pose_rot_total_opt}, pos={pose_pos_opt}\")\n",
    "\n",
    "        curr_render_imgs = b.hstack_images([\n",
    "                b.get_depth_image(img_opt[:,:,0]* 255.0) ,\n",
    "                b.get_depth_image(img_target[:,:,0]* 255.0) ,\n",
    "                ])\n",
    "        \n",
    "        if plot:\n",
    "            pose_opt_curr_val = q_v_to_mtx(pose_rot_opt, pose_pos_opt).detach().cpu() \n",
    "            plot_rot_and_pos(pose_opt_curr_val[:3, :3] @ UNIT_VECTOR, \n",
    "                         pose_opt_curr_val[:3, -1], \n",
    "                         ax_r, ax_t, \n",
    "                         color=\"blue\", alpha=0.1,\n",
    "                         rot_title=f\"Rotation evolution, iter {i}\", \n",
    "                         pos_title=f\"Translation evolution, iter {i}\")  # current\n",
    "            curr_PIL = fig2img(fig)\n",
    "            OPTIM_GIF_IMGS.append(b.hstack_images([curr_PIL, curr_render_imgs]))\n",
    "        else:\n",
    "            OPTIM_GIF_IMGS.append(curr_render_imgs)\n",
    "\n",
    "    return OPTIM_GIF_IMGS\n",
    "\n",
    "OPTIM_GIF_IMGS = descend_gradient(pose_rot_opt, pose_pos_opt, pose_target, rast_opt, rast_target, it=120, verbose=False, plot=True)\n",
    "b.viz.make_gif_from_pil_images(OPTIM_GIF_IMGS, \"render_imgs.gif\")\n",
    "b.vstack_images([OPTIM_GIF_IMGS[0], OPTIM_GIF_IMGS[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732ae3d9",
   "metadata": {},
   "source": [
    "## Multi pose hypothesis optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9dda1d",
   "metadata": {},
   "source": [
    "#### Define GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc2d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT) Rotation, Position poses\n",
    "pose_rot_target = torch.tensor(q_rnd(), device='cuda')\n",
    "pose_pos_target = torch.tensor(v_rnd(), device='cuda')\n",
    "pose_target = q_v_to_mtx(pose_rot_target, pose_pos_target)\n",
    "print(\"TARGET POSE=\", pose_target)\n",
    "\n",
    "# Initial GT render\n",
    "rast_target = render(glctx, torch.matmul(mvp, pose_target), vtx_pos, pos_idx, vtx_col, col_idx, resolution)\n",
    "img_target  = rast_target[0].detach().cpu().numpy()\n",
    "b.hstack_images([\n",
    "    b.get_depth_image(img_target[:,:,0]* 255.0) ,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb3489",
   "metadata": {},
   "source": [
    "#### Enumerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88481f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Make grid of hypotheses on pose deltas\n",
    "####\n",
    "\n",
    "min_x, min_y, min_z, max_x, max_y, max_z = -0.05, -0.05, -0.05, 0.05, 0.05, 0.05\n",
    "num_x, num_y, num_z = 1,1,1\n",
    "min_rotation_angle, max_rotation_angle = -jnp.pi/10, jnp.pi/10\n",
    "sphere_angle_range = jnp.pi/10\n",
    "fibonacci_sphere_points = 2\n",
    "num_planar_angle_points = 10\n",
    "\n",
    "\n",
    "pose_delta_enums_jax = b.utils.enumerations.make_pose_grid_enumeration(min_x,min_y,min_z, min_rotation_angle, \n",
    "                        max_x,max_y,max_z, max_rotation_angle,\n",
    "                        num_x,num_y,num_z, \n",
    "                        fibonacci_sphere_points, num_planar_angle_points, \n",
    "                        sphere_angle_range=sphere_angle_range)\n",
    "pose_delta_enums = torch.from_dlpack(jax.dlpack.to_dlpack(pose_delta_enums_jax, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d5e21",
   "metadata": {},
   "source": [
    "#### Define hypotheses / prepare GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Define pose hypotheses to run gradient descent on\n",
    "#############\n",
    "pose_enums = pose_target @ pose_delta_enums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db018baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opt) Rotation, Position poses\n",
    "r = R.from_matrix(pose_enums.detach().cpu()[:, :3, :3])\n",
    "poses_rot_init   = r.as_quat()\n",
    "poses_pos_init   = pose_enums[:, :3, -1].cpu().numpy() \n",
    "\n",
    "poses_rot_opt    = torch.tensor(np.divide(poses_rot_init, (np.sum(poses_rot_init**2, axis=1)**0.5)[:, None]), dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "poses_pos_opt    = torch.tensor(poses_pos_init, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "print(pose_rot_opt, pose_pos_opt)\n",
    "\n",
    "poses_opt = q_v_to_mtx_batch(poses_rot_opt, poses_pos_opt)\n",
    "\n",
    "# Initial opt render\n",
    "rast_opts = render_multiple(glctx, torch.matmul(mvp, poses_opt), vtx_pos, pos_idx, vtx_col, col_idx, resolution)\n",
    "img_opts  = rast_opts[4].detach().cpu().numpy()\n",
    "\n",
    "# initialize loss \n",
    "loss_best   = np.inf\n",
    "\n",
    "# Visualize initial state\n",
    "print(f\"target pose={pose_target},\\ncurrent pose={poses_opt[4]}\")\n",
    "\n",
    "b.hstack_images([\n",
    "    b.get_depth_image(img_opts[:,:,0]* 255.0) ,\n",
    "    b.get_depth_image(img_target[:,:,0]* 255.0) ,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f3151",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (ax_r, ax_t) = generate_rotation_translation_plot(False)\n",
    "plot_rot_and_pos(pose_target.detach().cpu()[:3, :3] @ UNIT_VECTOR, \n",
    "                 pose_target.detach().cpu()[:3, -1], \n",
    "                 ax_r, ax_t, \n",
    "                 color=\"red\", alpha=1, label=\"Target\")\n",
    "plot_rot_and_pos(np.einsum('nij,j... -> ni', poses_opt.detach().cpu()[:, :3, :3], UNIT_VECTOR), \n",
    "                 poses_opt.detach().cpu()[:, :3, -1], \n",
    "                 ax_r, ax_t, \n",
    "                 color=\"blue\", alpha=0.1, label=\"Hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c5ccb",
   "metadata": {},
   "source": [
    "#### Run GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf42a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descend_gradient_multi(pose_rot_opt, pose_pos_opt, pose_target, rast_opts, rast_target, it=20, verbose=False, plot=False):\n",
    "    OPTIM_GIF_IMGS = []\n",
    "    loss_best = np.inf\n",
    "    optimizer = torch.optim.Adam([pose_rot_opt, pose_pos_opt], betas=(0.9, 0.999), lr=2e-7)\n",
    "    img_target = rast_target[0].detach().cpu().numpy()\n",
    "    img_target_viz = b.get_depth_image(img_target[:,:,0]* 255.0)\n",
    "    \n",
    "    if plot: \n",
    "        fig, (ax_r, ax_t) = generate_rotation_translation_plot()\n",
    "        \n",
    "        poses_opt = q_v_to_mtx_batch(poses_rot_opt, poses_pos_opt)\n",
    "\n",
    "        plot_rot_and_pos(np.einsum('nij,j... -> ni', poses_opt.detach().cpu()[:, :3, :3], UNIT_VECTOR), \n",
    "                         poses_opt.detach().cpu()[:, :3, -1], \n",
    "                         ax_r, ax_t, \n",
    "                         color=\"green\", alpha=0.1, label=\"Initial\")\n",
    "        plot_rot_and_pos(np.einsum('nij,j... -> ni', poses_opt.detach().cpu()[:, :3, :3], UNIT_VECTOR),\n",
    "                         poses_opt.detach().cpu()[:, :3, -1], \n",
    "                         ax_r, ax_t, \n",
    "                         color=\"blue\", alpha=0.1, label=\"Hypothesis\")\n",
    "        plot_rot_and_pos(pose_target.detach().cpu()[:3, :3] @ UNIT_VECTOR, \n",
    "                         pose_target.detach().cpu()[:3, -1], \n",
    "                         ax_r, ax_t, \n",
    "                         color=\"red\", alpha=1, label=\"Target\")\n",
    "\n",
    "    \n",
    "    # TODO better convergence condition\n",
    "    for i in tqdm(range(it)):\n",
    "    #     noise = q_unit()\n",
    "        poses_rot_total_opt = poses_rot_opt #q_mul_torch(pose_rot_opt, noise)\n",
    "        mtx_total_opt  = torch.matmul(mvp, q_v_to_mtx_batch(poses_rot_total_opt, poses_pos_opt))\n",
    "        color_opts = render_multiple(glctx, mtx_total_opt, vtx_pos, pos_idx, vtx_col, col_idx, resolution)\n",
    "\n",
    "        diff = (rast_opts - rast_target)**2 # L2 norm.\n",
    "        diff = torch.tanh(5.0 * torch.max(diff, dim=-1)[0])\n",
    "        loss = torch.mean(diff)\n",
    "        loss_val = float(loss)\n",
    "\n",
    "        if (loss_val < loss_best) and (loss_val > 0.0):\n",
    "            loss_best = loss_val\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    #     with torch.no_grad():\n",
    "    #         pose_rot_opt /= torch.sum(poses_rot_opt**2, axis=1)**0.5\n",
    "\n",
    "        rast_opts = render_multiple(glctx, torch.matmul(mvp, q_v_to_mtx_batch(poses_rot_opt, poses_pos_opt)), vtx_pos, pos_idx, vtx_col, col_idx, resolution)\n",
    "        img_opts  = rast_opts.detach().cpu().numpy()\n",
    "    \n",
    "        if verbose:\n",
    "            print(f\"loss={loss}, pos[0]={pose_pos_opt[0]}\")\n",
    "\n",
    "        curr_render_imgs = b.hvstack_images([b.get_depth_image(img_opts[i][:,:,0]* 255.0) for i in range(len(rast_opts))], \n",
    "                                       fibonacci_sphere_points*num_x,\n",
    "                                       num_planar_angle_points*num_y*num_z,\n",
    "                                       border=10)\n",
    "        curr_render_imgs = b.vstack_images([img_target_viz, b.scale_image(curr_render_imgs, 0.3)])\n",
    "\n",
    "        if plot:\n",
    "            poses_opt_curr_val = q_v_to_mtx_batch(poses_rot_opt, poses_pos_opt).detach().cpu() \n",
    "            plot_rot_and_pos(np.einsum('nij,j... -> ni', poses_opt_curr_val[:, :3, :3], UNIT_VECTOR), \n",
    "                         poses_opt_curr_val[:, :3, -1], \n",
    "                         ax_r, ax_t, \n",
    "                         color=\"blue\", alpha=0.1,\n",
    "                         rot_title=f\"Rotation evolution, iter {i}\", \n",
    "                         pos_title=f\"Translation evolution, iter {i}\")  # current\n",
    "            curr_fig = fig2img(fig)\n",
    "            OPTIM_GIF_IMGS.append(b.hstack_images([curr_fig, curr_render_imgs]))\n",
    "        else:\n",
    "            OPTIM_GIF_IMGS.append(curr_render_imgs)\n",
    "\n",
    "    return OPTIM_GIF_IMGS\n",
    "\n",
    "OPTIM_GIF_IMGS = descend_gradient_multi(poses_rot_opt, poses_pos_opt, pose_target, \n",
    "                                        rast_opts, rast_target, \n",
    "                                        it=30, verbose=False, plot=True)\n",
    "b.viz.make_gif_from_pil_images(OPTIM_GIF_IMGS, \"render_imgs_multi.gif\")\n",
    "b.vstack_images([OPTIM_GIF_IMGS[0], OPTIM_GIF_IMGS[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de255c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0797e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb61c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f16cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25a8118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
