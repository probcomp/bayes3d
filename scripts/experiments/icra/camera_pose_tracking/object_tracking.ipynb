{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db2e0ef8-4473-411e-8908-86620d224bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import bayes3d as b\n",
    "import time\n",
    "from PIL import Image\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import trimesh\n",
    "import os\n",
    "\n",
    "# Can be helpful for debugging:\n",
    "# jax.config.update('jax_enable_checks', True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f3ab786-2d80-49c3-83a7-ae264401fdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7014/static/\n"
     ]
    }
   ],
   "source": [
    "b.setup_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eb7675a6-815f-4225-8a38-2571aa5cd7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing frame buffer size to (width, height, depth) = (64, 64, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E rasterize_gl.cpp:121] OpenGL version reported as 4.6\n"
     ]
    }
   ],
   "source": [
    "original_intrinsics = b.Intrinsics(\n",
    "    height=100,\n",
    "    width=100,\n",
    "    fx=80.0, fy=80.0,\n",
    "    cx=50.0, cy=50.0,\n",
    "    near=0.001, far=6.0\n",
    ")\n",
    "\n",
    "intrinsics = b.scale_camera_parameters(original_intrinsics, 0.5)\n",
    "\n",
    "b.setup_renderer(intrinsics)\n",
    "model_dir = os.path.join(b.utils.get_assets_dir(),\"bop/ycbv/models\")\n",
    "idx = 15\n",
    "mesh_path = os.path.join(model_dir,\"obj_\" + \"{}\".format(idx).rjust(6, '0') + \".ply\")\n",
    "b.RENDERER.add_mesh_from_file(mesh_path, scaling_factor=1.0/100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c6e4c544-b083-495a-aa45-2547695a717d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.84241, 1.87434, 0.57317]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.RENDERER.model_box_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f3105f1f-ba33-4fb7-b5ff-6ce7fedebfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pose = b.t3d.transform_from_pos_target_up(\n",
    "    jnp.array([0.0, 1.5, 1.0]),\n",
    "    jnp.array([0.0, 0.0, 0.0]),\n",
    "    jnp.array([0.0, 0.0, 1.0]),\n",
    ")\n",
    "\n",
    "camera_poses = jnp.array([\n",
    "    b.t3d.transform_from_axis_angle(jnp.array([0.0, 0.0, 1.0]), angle) @ camera_pose\n",
    "    for angle in jnp.linspace(0, 2*jnp.pi, 120)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6bea2feb-1945-4e8d-854a-fa21c76e4cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed_images.shape (120, 50, 50, 4)\n"
     ]
    }
   ],
   "source": [
    "poses = jnp.linalg.inv(camera_poses)\n",
    "\n",
    "observed_images = b.RENDERER.render_many(poses[:,None,...],  jnp.array([0]))\n",
    "print(\"observed_images.shape\", observed_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bcb2b542-62e8-4091-8398-24a9ed0eaadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_viz_images = [b.get_depth_image(i[:,:,2]) for i in observed_images]\n",
    "b.make_gif_from_pil_images(input_viz_images, \"input.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "106215af-5455-4fcd-a526-0961e552a37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1.5517244338989258\n",
      "FPS: 77.33331858317338\n"
     ]
    }
   ],
   "source": [
    "translation_deltas = b.utils.make_translation_grid_enumeration(-0.2, -0.2, -0.2, 0.2, 0.2, 0.2, 11, 11, 11)\n",
    "rotation_deltas = jax.vmap(lambda key: b.distributions.gaussian_vmf_zero_mean(key, 0.00001, 800.0))(\n",
    "    jax.random.split(jax.random.PRNGKey(3), 500)\n",
    ")\n",
    "\n",
    "likelihood = jax.vmap(b.threedp3_likelihood_old, in_axes=(None, 0, None, None, None, None, None))\n",
    "\n",
    "def update_pose_estimate(pose_estimate, gt_image):\n",
    "    proposals = jnp.einsum(\"ij,ajk->aik\", pose_estimate, translation_deltas)\n",
    "    rendered_images = jax.vmap(b.RENDERER.render, in_axes=(0, None))(proposals[:,None, ...], jnp.array([0]))\n",
    "    weights_new = likelihood(gt_image, rendered_images, 0.05, 0.1, 10**3, 0.1, 3)\n",
    "    pose_estimate = proposals[jnp.argmax(weights_new)]\n",
    "\n",
    "    proposals = jnp.einsum(\"ij,ajk->aik\", pose_estimate, rotation_deltas)\n",
    "    rendered_images = jax.vmap(b.RENDERER.render, in_axes=(0, None))(proposals[:, None, ...], jnp.array([0]))\n",
    "    weights_new = likelihood(gt_image, rendered_images, 0.05, 0.1, 10**3, 0.1, 3)\n",
    "    pose_estimate = proposals[jnp.argmax(weights_new)]\n",
    "    return pose_estimate, pose_estimate\n",
    "\n",
    "inference_program = jax.jit(lambda p,x: jax.lax.scan(update_pose_estimate, p,x)[1])\n",
    "inferred_poses = inference_program(poses[0], observed_images)\n",
    "\n",
    "start = time.time()\n",
    "pose_estimates_over_time = inference_program(poses[0], observed_images)\n",
    "end = time.time()\n",
    "print (\"Time elapsed:\", end - start)\n",
    "print (\"FPS:\", poses.shape[0] / (end - start))\n",
    "\n",
    "\n",
    "max_depth = 10.0\n",
    "rerendered_images = b.RENDERER.render_many(pose_estimates_over_time[:, None, ...], jnp.array([0]))\n",
    "viz_images = []\n",
    "for (r, d) in zip(rerendered_images, observed_images):\n",
    "    viz_r = b.viz.scale_image(b.viz.get_depth_image(r[:,:,2]), 5.0)\n",
    "    viz_d = b.viz.scale_image(b.viz.get_depth_image(d[:,:,2]), 5.0)\n",
    "    overlay = b.viz.overlay_image(viz_r,viz_d)\n",
    "    viz_images.append(b.viz.multi_panel(\n",
    "        [\n",
    "            viz_d, viz_r, overlay\n",
    "        ],\n",
    "        [\"Ground Truth\", \"Inferred Reconstruction\", \"Overlay\"],\n",
    "    ))\n",
    "\n",
    "b.make_gif_from_pil_images(viz_images, \"demo.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b71a47-468a-4e3e-baa4-0a0e1e6f6efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801f265-436d-4b12-9bc1-8fcfbb20bd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ea691-0e0f-4980-bf9e-6be777624e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
