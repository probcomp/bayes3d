{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1477c737-919d-4445-bc46-c139b9a3febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes3d as b\n",
    "import os\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import bayes3d.genjax\n",
    "import genjax\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2db391b-3dfd-4b03-9e28-ae49df8839aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "from flax.training.train_state import TrainState\n",
    "import flax\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af096265-4e27-4ac7-ac04-0d633c8bbe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27824992-5bbb-4581-b5f5-43b8a2c73d5b",
   "metadata": {},
   "source": [
    "## CNN Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45fd6be-ea64-41fd-b671-2575fa322afb",
   "metadata": {},
   "source": [
    "C1: conv with 10x10 filter stride 3 32 channels (input 100x100x1, output 31 x 31 x 32)\n",
    "\n",
    "relu (input 31 x 31 x 32, output 31 x 31 x 32)\n",
    "\n",
    "max pooling 3x3 stride 2 32 channels (input 31 x 31 x 32, output 15 x 15x 32)\n",
    "\n",
    "C2: conv with 5x5 filter stride 2 64 channels (input 15 x 15 x 32, output 6 x 6 x 64)\n",
    "\n",
    "relu (input 6 x 6 x 64, output 6 x 6 x 64)\n",
    "\n",
    "max pooling 2x2 stride 2 64 channels (input 6 x 6 x 64, output 3 x 3 x 64)\n",
    "\n",
    "flatten (input 3 x 3 x 64, output 1 x 576)\n",
    "\n",
    "L1: linear (input 1 x 576, output 1x 576)\n",
    "\n",
    "relu\n",
    "\n",
    "L2: linear (input 1 x 576, output 1x 192)\n",
    "\n",
    "relu\n",
    "\n",
    "L3: linear (input 1 x 192, output 1x 24)\n",
    "\n",
    "relu\n",
    "\n",
    "L4: linear (input 1 x 24, output 1 x 2)\n",
    "\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7103a-c828-4b5e-806d-ee73ae10387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, imgs): # XXX todo: make sure the sizes all line up\n",
    "        x = nn.Conv(64, (10, 10), strides=(3, 3), padding='VALID')(imgs)\n",
    "        x = nn.activation.relu(x)\n",
    "        x = nn.max_pool(x, (3, 3), strides=(2, 2))\n",
    "        \n",
    "        x = nn.Conv(128, (5, 5), strides=(2, 2), padding='VALID')(x)\n",
    "        x = nn.activation.relu(x)\n",
    "        x = nn.max_pool(x, (2, 2), strides=(2, 2))\n",
    "        \n",
    "        x = nn.Dense(1024)(x.reshape(imgs.shape[0], -1))\n",
    "        x = nn.activation.relu(x)\n",
    "        \n",
    "        x = nn.Dense(1024)(x)\n",
    "        x = nn.activation.relu(x)\n",
    "        \n",
    "        x = nn.Dense(576)(x)\n",
    "        x = nn.activation.relu(x)\n",
    "\n",
    "        x = nn.Dense(192)(x)\n",
    "        x = nn.activation.relu(x)\n",
    "\n",
    "        x = nn.Dense(24)(x)\n",
    "        x = nn.activation.relu(x)\n",
    "\n",
    "        x = nn.Dense(2)(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf044e-ca96-444e-936c-12ba302d9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "cnn.tabulate(jax.random.PRNGKey(0), jnp.zeros((1, 100, 100, 1)), console_kwargs={'force_jupyter': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8dbb6c-96e4-4f05-89bb-37dfb597cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, rng, learning_rate, momentum):\n",
    "    \"\"\"Creates an initial `TrainState`.\"\"\"\n",
    "    params = module.init(rng, jnp.ones([BATCH_SIZE, 100, 100, 1]))['params'] # initialize parameters by passing a template image\n",
    "    tx = optax.sgd(learning_rate, momentum)\n",
    "    return TrainState.create(apply_fn=module.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d94c23-8182-4379-aba7-81ebc8a5fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, img_batch, label_batch): \n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn({'params': params}, img_batch, mutable=False)\n",
    "        loss = optax.softmax_cross_entropy(logits=logits, labels=label_batch).mean()\n",
    "        return loss\n",
    "    grad_fn = jax.grad(loss_fn)\n",
    "    grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss_fn(state.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914ecee-34fe-4669-8846-b6d87c3563b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def calc_loss(train_state, imgs, labels):\n",
    "    return optax.softmax_cross_entropy(\n",
    "        #logits= train_state.apply_fn({'params': train_state.params}, imgs),\n",
    "        logits= train_state.apply_fn({'params': train_state.params}, imgs, mutable=False),\n",
    "        labels=labels).mean()\n",
    "\n",
    "def calc_loss_batched(train_state, imgs, labels):\n",
    "    n_batches = imgs.shape[0] // BATCH_SIZE\n",
    "    return jnp.array([calc_loss(train_state, img_batch, label_batch)\n",
    "                      for (img_batch, label_batch) in zip(imgs.reshape(n_batches, BATCH_SIZE, 100, 100, 1),\n",
    "                                                          labels.reshape(n_batches, BATCH_SIZE, 2))]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7de21-c52e-4a9d-8c90-a3bc74e34cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = jnp.load('train_data.npz')\n",
    "test_data_file = jnp.load('test_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a6966-7f35-4f6a-b77d-f4b1558d046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = train_data_file['arr_0']\n",
    "train_labels = train_data_file['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718f500-0574-4627-8147-7115768531a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c49c57-5041-4dc3-aa11-6fc5b10a77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = test_data_file['arr_0']\n",
    "test_labels = test_data_file['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d78ebca-432e-40ca-9d66-1bafe84e8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c764c89b-a127-4ccf-b731-3122c945e097",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = train_imgs.shape[0]\n",
    "N_TEST = test_imgs.shape[0]\n",
    "N_EPOCHS = 20\n",
    "BATCH_SIZE = 200\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "assert N_TRAIN % BATCH_SIZE == 0\n",
    "assert N_TEST % BATCH_SIZE == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d11caa-3935-4ba5-acf3-6fe685de7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(cnn, jax.random.PRNGKey(0), LEARNING_RATE, MOMENTUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc04fea-c89a-49f4-be30-eedc8ae10579",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffling_key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58289c66-acac-4942-bf14-c503a66a911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c65902-e84b-4d87-937c-089ec9c3694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    training_losses.append([])\n",
    "    perm = jax.random.permutation(shuffling_key, N_TRAIN)\n",
    "    train_imgs = train_imgs[perm]\n",
    "    train_labels = train_labels[perm]\n",
    "    shuffling_key = jax.random.split(shuffling_key, 2)[1]\n",
    "\n",
    "    assert N_TRAIN % BATCH_SIZE == 0\n",
    "    for step in range(N_TRAIN // BATCH_SIZE):\n",
    "        img_batch = train_imgs[step*BATCH_SIZE:(step+1)*BATCH_SIZE]\n",
    "        label_batch = train_labels[step*BATCH_SIZE:(step+1)*BATCH_SIZE]\n",
    "        \n",
    "        state, loss = train_step(state, img_batch, label_batch) \n",
    "        training_losses[-1].append(loss)\n",
    "        #os.system('nvidia-smi')\n",
    "        print('.', end='')\n",
    "    print()\n",
    "\n",
    "    epoch_loss = jnp.array(training_losses[-1]).mean()\n",
    "    epoch_train_loss = calc_loss_batched(state, train_imgs, train_labels)\n",
    "    epoch_test_loss = calc_loss_batched(state, test_imgs, test_labels)\n",
    "    #epoch_train_loss = 'not calculated'\n",
    "    #epoch_test_loss = 'not calculated'\n",
    "    print(f'epoch: {epoch}, average loss: {epoch_loss}, '\n",
    "          f'train loss: {epoch_train_loss}, '\n",
    "          f'test loss: {epoch_test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fc54da-c346-4406-b934-034b4313eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([jnp.array(l).mean() for l in training_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6de522-d88c-46c9-a036-3a458277b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 44\n",
    "__img = test_imgs[IDX].reshape(1, 100, 100, 1)\n",
    "logits = state.apply_fn({'params': state.params}, __img)\n",
    "print(logits)\n",
    "print(b.utils.normalize_log_scores(logits))\n",
    "print(test_labels[IDX])\n",
    "print(optax.softmax_cross_entropy(\n",
    "        #logits= train_state.apply_fn({'params': train_state.params}, imgs),\n",
    "        logits=logits,\n",
    "        labels=test_labels[IDX]))\n",
    "b.get_depth_image(test_imgs[IDX][...,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd656d7-89ec-4fa7-ae25-31178f961a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e2dc2-facf-4755-ab31-70d29d09b57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c785163f-a49f-47fa-ae20-23b90ca7ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('param_file.pkl', 'wb') as params_file:\n",
    "    pickle.dump(state.params, params_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8702e8-0e42-4fb7-89ff-a2e23d2642aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics = b.Intrinsics(\n",
    "    height=100,\n",
    "    width=100,\n",
    "    fx=200.0, fy=200.0,\n",
    "    cx=50.0, cy=50.0,\n",
    "    near=0.0001, far=2.0\n",
    ")\n",
    "\n",
    "b.setup_renderer(intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb82a3f-8a8d-4af7-bc87-3ce07d52a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "fork_mesh_path = b.utils.get_assets_dir() + '/ycb_video_models/models/030_fork/nontextured.ply'\n",
    "knife_mesh_path = b.utils.get_assets_dir() + '/ycb_video_models/models/032_knife/nontextured.ply'\n",
    "box_mesh_path = b.utils.get_assets_dir() + '/bop/ycbv/models/obj_000002.ply'\n",
    "table_mesh_path = b.utils.get_assets_dir() + '/sample_objs/cube.obj'\n",
    "fork_scale = knife_scale = 1.0\n",
    "box_scale = 1e-3\n",
    "table_scale = 1e-6\n",
    "mesh_paths = (fork_mesh_path, knife_mesh_path, box_mesh_path, table_mesh_path)\n",
    "scales = (fork_scale, knife_scale, box_scale, table_scale)\n",
    "for mesh_path, scale in zip(mesh_paths, scales):\n",
    "    b.RENDERER.add_mesh_from_file(mesh_path, scaling_factor=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641a876-0ac7-4e1e-a5cb-f342f662712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_pose = b.t3d.inverse_pose(\n",
    "    b.t3d.transform_from_pos_target_up(\n",
    "        jnp.array([0.0, 0.7, 0.5]),\n",
    "        jnp.array([0.0, 0.0, 0.0]),\n",
    "        jnp.array([0.0, 0.0, 1.0]),\n",
    "    )\n",
    ")\n",
    "\n",
    "FORK_IDX, KNIFE_IDX, CHEESEITZ_BOX_IDX, TABLE_IDX = 0, 1, 2, 3\n",
    "\n",
    "SHIFT_MIN = -0.2\n",
    "SHIFT_SCALE = 0.4\n",
    "CHEESEITZ_BOX_CONTACT_PARAMS = jnp.array([0.0, 0.1, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f679145-f96b-4b74-a9d8-f330d174ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fork_spoon_from_known_params(is_fork, shift):\n",
    "    indices = jax.lax.cond(is_fork,\n",
    "                           lambda: jnp.array([TABLE_IDX, CHEESEITZ_BOX_IDX, FORK_IDX]),\n",
    "                           lambda: jnp.array([TABLE_IDX, CHEESEITZ_BOX_IDX, KNIFE_IDX]))\n",
    "\n",
    "    box_dims = b.RENDERER.model_box_dims[indices]\n",
    "    root_poses = jnp.array([table_pose, table_pose, table_pose])\n",
    "    parents = jnp.array([-1, 0, 0])\n",
    "    contact_params = jnp.array([[0.0, 0.0, 0.0],\n",
    "                                [*CHEESEITZ_BOX_CONTACT_PARAMS],\n",
    "                                [shift*jnp.cos(jnp.pi/12), -0.05 + shift*jnp.sin(jnp.pi/12), 10*jnp.pi/12]])\n",
    "    faces_parents = jnp.array([0, 2, 2])\n",
    "    faces_child = jnp.array([0, 3, 3])\n",
    "    poses = b.scene_graph.poses_from_scene_graph(\n",
    "        root_poses, box_dims, parents, contact_params, faces_parents, faces_child)\n",
    "    camera_pose = jnp.eye(4)\n",
    "    rendered = b.RENDERER.render(\n",
    "        jnp.linalg.inv(camera_pose) @ poses , indices\n",
    "    )[...,:3]\n",
    "    return (is_fork, rendered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf0924-7ff7-4bdb-83c7-666577864239",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = -0.1\n",
    "b.viz.hstack_images([b.viz.scale_image(b.get_depth_image(fork_spoon_from_known_params(True, ss)[1][...,2]), 2),\n",
    "                     b.viz.scale_image(b.get_depth_image(fork_spoon_from_known_params(False, ss)[1][...,2]), 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586b71e-9f86-4816-b65c-34a827ff7667",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_onehot = lambda b: jax.lax.cond(b, lambda: jnp.array([0.0, 1.0]), lambda: jnp.array([1.0, 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a56bed-b10b-42a2-830e-e48dab7e8918",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fork, __img, = fork_spoon_from_known_params(False, 0.0)\n",
    "__img = __img[:, :, 2].reshape(1, 100, 100, 1)\n",
    "logits = state.apply_fn({'params': state.params}, __img)\n",
    "\n",
    "print(f'true: {make_onehot(is_fork)} predicted: {jax.nn.softmax(logits)}')\n",
    "\n",
    "b.viz.scale_image(b.get_depth_image(__img.reshape(100, 100)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae87da9-2cda-4441-a1fc-31a7471e716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_batch, label_batch = make_batch(batch_keys)\n",
    "#logits = state.apply_fn({'params': state.params}, img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c15278-a10d-4e06-942b-84553af4f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i = 33 #23 # 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d88a95-ecc7-4bf4-90bb-48b1fc2a0935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b.viz.scale_image(b.get_depth_image(img_batch[i, :, :, 0]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0420f5-f05c-4633-a6bd-b169810ba6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_batch[i], jax.nn.softmax(logits[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20675fe5-c1e1-4cb4-813e-a7419de93d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f772915-288d-4f34-813b-0214bba0ae33",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
