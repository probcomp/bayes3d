{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import diff_gaussian_rasterization as dgr\n",
    "from diff_gaussian_rasterization import GaussianRasterizationSettings, GaussianRasterizer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import bayes3d as b\n",
    "import jax.numpy as jnp\n",
    "from random import randint\n",
    "import pytorch3d.transforms\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.setup_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics = b.Intrinsics(\n",
    "    height=100,\n",
    "    width=100,\n",
    "    fx=100.0, fy=100.0,\n",
    "    cx=50.0, cy=50.0,\n",
    "    near=0.01, far=0.75\n",
    ")\n",
    "fovX = jnp.arctan(intrinsics.width / 2 / intrinsics.fx) * 2\n",
    "fovY = jnp.arctan(intrinsics.height / 2 / intrinsics.fy) * 2\n",
    "tan_fovx = math.tan(fovX)\n",
    "tan_fovy = math.tan(fovY)\n",
    "\n",
    "\n",
    "def getProjectionMatrix(intrinsics):\n",
    "    top = intrinsics.near / intrinsics.fy * intrinsics.height / 2.0\n",
    "    bottom = -top\n",
    "    right = intrinsics.near / intrinsics.fy * intrinsics.height / 2.0\n",
    "    left = -right\n",
    "\n",
    "    P = torch.zeros(4, 4)\n",
    "\n",
    "    z_sign = 1.0\n",
    "\n",
    "    P[0, 0] = 2.0 * intrinsics.near / (right - left)\n",
    "    P[1, 1] = 2.0 * intrinsics.near / (top - bottom)\n",
    "    P[0, 2] = (right + left) / (right - left)\n",
    "    P[1, 2] = (top + bottom) / (top - bottom)\n",
    "    P[2, 2] = z_sign * (intrinsics.far + intrinsics.near) / (intrinsics.far - intrinsics.near)\n",
    "    P[2, 3] = -2.0 * (intrinsics.far * intrinsics.near) / (intrinsics.far - intrinsics.near)\n",
    "    P[3, 2] = z_sign\n",
    "    return torch.transpose(P, 0, 1)\n",
    "\n",
    "proj_matrix = torch.tensor(getProjectionMatrix(intrinsics), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.setup_renderer(intrinsics)\n",
    "model_dir = os.path.join(b.utils.get_assets_dir(),\"bop/ycbv/models\")\n",
    "mesh_path = os.path.join(model_dir,\"obj_\" + \"{}\".format(17).rjust(6, '0') + \".ply\")\n",
    "b.RENDERER.add_mesh_from_file(mesh_path, scaling_factor=1.0/1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_pose = b.transform_from_pos(jnp.array([0.0, 0.0, 0.3]))\n",
    "camera_poses = [jnp.eye(4), b.transform_from_axis_angle(jnp.array([1.0, 0.0, 0.0]), jnp.pi/40), b.transform_from_axis_angle(jnp.array([1.0, 0.0, 0.0]), jnp.pi/20)]\n",
    "\n",
    "point_cloud_images = [b.RENDERER.render(b.inverse_pose(cp) @ object_pose[None,...], jnp.array([0])) for cp in camera_poses]\n",
    "gt_images = [torch.tensor(np.array(gt_img[...,2]),device=device).detach() for gt_img in point_cloud_images]\n",
    "gt_images_stacked = torch.stack(gt_images)\n",
    "b.hstack_images([b.get_depth_image(img[:,:,2]) for img in point_cloud_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(means3D, means2D, opacity, scales, rotations, camera_pose):\n",
    "    view_matrix = torch.transpose(torch.tensor(np.array(b.inverse_pose(camera_pose))),0,1).cuda()\n",
    "    raster_settings = GaussianRasterizationSettings(\n",
    "        image_height=int(intrinsics.height),\n",
    "        image_width=int(intrinsics.width),\n",
    "        tanfovx=tan_fovx,\n",
    "        tanfovy=tan_fovy,\n",
    "        bg=torch.tensor([intrinsics.far, intrinsics.far, intrinsics.far]).cuda(),\n",
    "        scale_modifier=1.0,\n",
    "        viewmatrix=view_matrix,\n",
    "        projmatrix=view_matrix @ proj_matrix,\n",
    "        sh_degree=0,\n",
    "        campos=torch.zeros(3).cuda(),\n",
    "        prefiltered=False,\n",
    "        debug=None\n",
    "    )\n",
    "    rasterizer = GaussianRasterizer(raster_settings=raster_settings)\n",
    "\n",
    "    gt_rendered_image, radii = rasterizer(\n",
    "        means3D = means3D,\n",
    "        means2D = means2D,\n",
    "        shs = None,\n",
    "        colors_precomp = means3D[:,2:3].repeat(1,3),\n",
    "        opacities = opacity,\n",
    "        scales = torch.exp(scales),\n",
    "        rotations = rotations\n",
    "    )\n",
    "    return gt_rendered_image[2,...]\n",
    "\n",
    "def convert_to_numpy(img):\n",
    "    return img.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud = point_cloud_image.reshape(-1,3)\n",
    "point_cloud_not_far = point_cloud[point_cloud[:,2] < intrinsics.far, :]\n",
    "point_cloud_not_far = np.array(point_cloud_not_far).repeat(5,axis=0)\n",
    "point_cloud_not_far = point_cloud_not_far + (np.random.rand(*point_cloud_not_far.shape) -0.5)* 0.01\n",
    "means3D = torch.tensor(point_cloud_not_far.astype(np.float32),requires_grad=True,device=device)\n",
    "N = means3D.shape[0]\n",
    "means2D = torch.tensor(torch.rand((N, 3)),requires_grad=True,device=device)\n",
    "opacity = torch.tensor(torch.ones((N, 1)),requires_grad=True,device=device)\n",
    "scales = torch.tensor(torch.rand((N, 3)) * 0.01 - 10.2,requires_grad=True,device=device)\n",
    "rotations = torch.tensor(torch.rand((N, 4)),requires_grad=True,device=device)\n",
    "\n",
    "imgs = [convert_to_numpy(render(means3D, means2D, opacity, scales, rotations,camera_pose)) for camera_pose in camera_poses ]\n",
    "b.clear()\n",
    "b.show_cloud(\"gt\",b.unproject_depth_jit(gt_img, intrinsics).reshape(-1,3)) \n",
    "b.show_cloud(\"reconstruction\",b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3),color=b.BLUE) \n",
    "b.hstack_images([b.get_depth_image(d) for d in imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\n",
    "    {'params': [means3D], 'lr': 0.01 ,\"name\": \"xyz\"},\n",
    "    {'params': [opacity], 'lr': 0.05, \"name\": \"opacity\"},\n",
    "    {'params': [scales], 'lr': 0.05, \"name\": \"scaling\"},\n",
    "    {'params': [rotations], 'lr': 0.01, \"name\": \"rotation\"}\n",
    "]\n",
    "optimizer = torch.optim.SGD(l, lr=0.0)\n",
    "\n",
    "pbar = tqdm(range(1000))\n",
    "for _ in pbar:\n",
    "    imgs = torch.stack([render(means3D, means2D, opacity, scales, rotations, camera_pose) for camera_pose in camera_poses])\n",
    "    loss = torch.abs(gt_images_stacked - imgs).mean()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_description(f\"{loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.clear()\n",
    "b.show_cloud(\"gt\",b.unproject_depth_jit(gt_images_stacked[0].detach().cpu().numpy(), intrinsics).reshape(-1,3)) \n",
    "# b.show_cloud(\"means\", means3D.detach().cpu().numpy(),color=b.RED)\n",
    "b.show_cloud(\"reconstruction\",b.unproject_depth_jit(convert_to_numpy(imgs[0]), intrinsics).reshape(-1,3),color=b.BLUE) \n",
    "\n",
    "b.get_depth_image(convert_to_numpy(imgs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, radii = rasterizer(\n",
    "    means3D = means3D,\n",
    "    means2D = means2D,\n",
    "    shs = None,\n",
    "    colors_precomp = means3D[:,2:3].repeat(1,3),\n",
    "    opacities =  torch.tensor(torch.ones((N, 1)),requires_grad=True,device=device),\n",
    "    scales = torch.exp(scales),\n",
    "    rotations = rotations\n",
    ")\n",
    "depth_image = np.moveaxis(img.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.clear()\n",
    "# b.show_cloud(\"gt\",b.unproject_depth_jit(gt_img, intrinsics).reshape(-1,3)) \n",
    "# b.show_cloud(\"means\", means3D.detach().cpu().numpy(),color=b.RED)\n",
    "b.show_cloud(\"reconstruction\",b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3),color=b.BLUE) \n",
    "\n",
    "b.get_depth_image(depth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(np.abs(depth_image - gt_img))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.tensor([0.0, 0.0, 0.5],device=device)\n",
    "quat =  torch.tensor(torch.rand(4,device=device) - 0.5,device=device)\n",
    "\n",
    "gt_rendered_image =  render(pos, quat).detach()\n",
    "depth_image = np.moveaxis(gt_rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.show_cloud(\"1\", b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3))\n",
    "viz_gt = b.get_depth_image(depth_image)\n",
    "viz_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.tensor([0.0, 0.0, 0.5],device=device, requires_grad=True)\n",
    "quat =  torch.tensor(torch.rand(4,device=device) - 0.5,device=device, requires_grad=True)\n",
    "rendered_image =  render(pos, quat)\n",
    "depth_image = np.moveaxis(rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.show_cloud(\"1\", b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3))\n",
    "viz = b.get_depth_image(depth_image)\n",
    "b.hstack_images([viz, viz_gt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': [pos], 'lr': 0.001, \"name\": \"pos\"},\n",
    "    {'params': [quat], 'lr': 0.001, \"name\": \"quat\"},\n",
    "], lr=0.0, eps=1e-15)\n",
    "\n",
    "pbar = tqdm(range(1000))\n",
    "for _ in pbar:\n",
    "    rendered_image =  render(pos, quat)\n",
    "    loss = torch.abs(gt_rendered_image - rendered_image).mean()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_description(f\"{loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "depth_image = np.moveaxis(rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.show_cloud(\"1\", b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3))\n",
    "viz = b.get_depth_image(depth_image)\n",
    "b.hstack_images([viz, viz_gt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
