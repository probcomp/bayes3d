{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fef143-f8d4-4078-9386-deeff2fd80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import imageio\n",
    "import bayes3d as b\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nvdiffrast.torch as dr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17c219-e6ca-4a3b-a222-87078442decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter           = 10000\n",
    "repeats            = 1\n",
    "log_interval       = 10\n",
    "display_interval   = None\n",
    "display_res        = 512\n",
    "lr_base            = 0.01\n",
    "lr_falloff         = 1.0\n",
    "nr_base            = 1.0\n",
    "nr_falloff         = 1e-4\n",
    "grad_phase_start   = 0.5\n",
    "resolution         = 256\n",
    "out_dir            = None\n",
    "log_fn             = None\n",
    "mp4save_interval   = None\n",
    "mp4save_fn         = None\n",
    "use_opengl         = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce3703-36df-4d82-bebc-751bb974c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(x=0.1, n=1.0, f=50.0):\n",
    "    return np.array([[n/x,    0,            0,              0],\n",
    "                     [  0,  n/x,            0,              0],\n",
    "                     [  0,    0, -(f+n)/(f-n), -(2*f*n)/(f-n)],\n",
    "                     [  0,    0,           -1,              0]]).astype(np.float32)\n",
    "def translate(x, y, z):\n",
    "    return np.array([[1, 0, 0, x],\n",
    "                     [0, 1, 0, y],\n",
    "                     [0, 0, 1, z],\n",
    "                     [0, 0, 0, 1]]).astype(np.float32)\n",
    "glctx = dr.RasterizeGLContext() #if use_opengl else dr.RasterizeCudaContext()\n",
    "mvp = torch.tensor(np.matmul(projection(x=0.4), translate(0, 0, -3.5)).astype(np.float32), device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdf559-094d-46e5-ae8b-b75122891ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Quaternion math.\n",
    "#----------------------------------------------------------------------------\n",
    "\n",
    "# Unit quaternion.\n",
    "def q_unit():\n",
    "    return np.asarray([1, 0, 0, 0], np.float32)\n",
    "\n",
    "# Get a random normalized quaternion.\n",
    "def q_rnd():\n",
    "    u, v, w = np.random.uniform(0.0, 1.0, size=[3])\n",
    "    v *= 2.0 * np.pi\n",
    "    w *= 2.0 * np.pi\n",
    "    return np.asarray([(1.0-u)**0.5 * np.sin(v), (1.0-u)**0.5 * np.cos(v), u**0.5 * np.sin(w), u**0.5 * np.cos(w)], np.float32)\n",
    "\n",
    "# Get a random quaternion from the octahedral symmetric group S_4.\n",
    "_r2 = 0.5**0.5\n",
    "_q_S4 = [[ 1.0, 0.0, 0.0, 0.0], [ 0.0, 1.0, 0.0, 0.0], [ 0.0, 0.0, 1.0, 0.0], [ 0.0, 0.0, 0.0, 1.0],\n",
    "         [-0.5, 0.5, 0.5, 0.5], [-0.5,-0.5,-0.5, 0.5], [ 0.5,-0.5, 0.5, 0.5], [ 0.5, 0.5,-0.5, 0.5],\n",
    "         [ 0.5, 0.5, 0.5, 0.5], [-0.5, 0.5,-0.5, 0.5], [ 0.5,-0.5,-0.5, 0.5], [-0.5,-0.5, 0.5, 0.5],\n",
    "         [ _r2,-_r2, 0.0, 0.0], [ _r2, _r2, 0.0, 0.0], [ 0.0, 0.0, _r2, _r2], [ 0.0, 0.0,-_r2, _r2],\n",
    "         [ 0.0, _r2, _r2, 0.0], [ _r2, 0.0, 0.0,-_r2], [ _r2, 0.0, 0.0, _r2], [ 0.0,-_r2, _r2, 0.0],\n",
    "         [ _r2, 0.0, _r2, 0.0], [ 0.0, _r2, 0.0, _r2], [ _r2, 0.0,-_r2, 0.0], [ 0.0,-_r2, 0.0, _r2]]\n",
    "def q_rnd_S4():\n",
    "    return np.asarray(_q_S4[np.random.randint(24)], np.float32)\n",
    "\n",
    "# Quaternion slerp.\n",
    "def q_slerp(p, q, t):\n",
    "    d = np.dot(p, q)\n",
    "    if d < 0.0:\n",
    "        q = -q\n",
    "        d = -d\n",
    "    if d > 0.999:\n",
    "        a = p + t * (q-p)\n",
    "        return a / np.linalg.norm(a)\n",
    "    t0 = np.arccos(d)\n",
    "    tt = t0 * t\n",
    "    st = np.sin(tt)\n",
    "    st0 = np.sin(t0)\n",
    "    s1 = st / st0\n",
    "    s0 = np.cos(tt) - d*s1\n",
    "    return s0*p + s1*q\n",
    "\n",
    "# Quaterion scale (slerp vs. identity quaternion).\n",
    "def q_scale(q, scl):\n",
    "    return q_slerp(q_unit(), q, scl)\n",
    "\n",
    "# Quaternion product.\n",
    "def q_mul(p, q):\n",
    "    s1, V1 = p[0], p[1:]\n",
    "    s2, V2 = q[0], q[1:]\n",
    "    s = s1*s2 - np.dot(V1, V2)\n",
    "    V = s1*V2 + s2*V1 + np.cross(V1, V2)\n",
    "    return np.asarray([s, V[0], V[1], V[2]], np.float32)\n",
    "\n",
    "# Angular difference between two quaternions in degrees.\n",
    "def q_angle_deg(p, q):\n",
    "    p = p.detach().cpu().numpy()\n",
    "    q = q.detach().cpu().numpy()\n",
    "    d = np.abs(np.dot(p, q))\n",
    "    d = min(d, 1.0)\n",
    "    return np.degrees(2.0 * np.arccos(d))\n",
    "\n",
    "# Quaternion product\n",
    "def q_mul_torch(p, q):\n",
    "    a = p[0]*q[0] - p[1]*q[1] - p[2]*q[2] - p[3]*q[3]\n",
    "    b = p[0]*q[1] + p[1]*q[0] + p[2]*q[3] - p[3]*q[2]\n",
    "    c = p[0]*q[2] + p[2]*q[0] + p[3]*q[1] - p[1]*q[3]\n",
    "    d = p[0]*q[3] + p[3]*q[0] + p[1]*q[2] - p[2]*q[1]\n",
    "    return torch.stack([a, b, c, d])\n",
    "\n",
    "# Convert quaternion to 4x4 rotation matrix.\n",
    "def q_to_mtx(q):\n",
    "    r0 = torch.stack([1.0-2.0*q[1]**2 - 2.0*q[2]**2, 2.0*q[0]*q[1] - 2.0*q[2]*q[3], 2.0*q[0]*q[2] + 2.0*q[1]*q[3]])\n",
    "    r1 = torch.stack([2.0*q[0]*q[1] + 2.0*q[2]*q[3], 1.0 - 2.0*q[0]**2 - 2.0*q[2]**2, 2.0*q[1]*q[2] - 2.0*q[0]*q[3]])\n",
    "    r2 = torch.stack([2.0*q[0]*q[2] - 2.0*q[1]*q[3], 2.0*q[1]*q[2] + 2.0*q[0]*q[3], 1.0 - 2.0*q[0]**2 - 2.0*q[1]**2])\n",
    "    rr = torch.transpose(torch.stack([r0, r1, r2]), 1, 0)\n",
    "    rr = torch.cat([rr, torch.tensor([[0], [0], [0]], dtype=torch.float32).cuda()], dim=1) # Pad right column.\n",
    "    rr = torch.cat([rr, torch.tensor([[0, 0, 0, 1]], dtype=torch.float32).cuda()], dim=0)  # Pad bottom row.\n",
    "    return rr\n",
    "\n",
    "# Transform vertex positions to clip space\n",
    "def transform_pos(mtx, pos):\n",
    "    t_mtx = torch.from_numpy(mtx).cuda() if isinstance(mtx, np.ndarray) else mtx\n",
    "    # (x,y,z) -> (x,y,z,1)\n",
    "    posw = torch.cat([pos, torch.ones([pos.shape[0], 1]).cuda()], axis=1)\n",
    "    return torch.matmul(posw, t_mtx.t())[None, ...]\n",
    "\n",
    "def render(glctx, mtx, pos, pos_idx, col, col_idx, resolution: int):\n",
    "    # Setup TF graph for reference.\n",
    "    depth_ = pos[..., 2:3]\n",
    "    depth = torch.tensor([[[(z_val/1)] for z_val in depth_.squeeze()]], dtype=torch.float32).cuda()\n",
    "    pos_clip    = transform_pos(mtx, pos)\n",
    "    rast_out, _ = dr.rasterize(glctx, pos_clip, pos_idx, resolution=[resolution, resolution])\n",
    "    color   , _ = dr.interpolate(depth, rast_out, pos_idx)\n",
    "    # color       = dr.antialias(color, rast_out, pos_clip, pos_idx)\n",
    "    return color\n",
    "    # return rast_out[:,:,:,2:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c2c03-8f55-4625-982d-32479eebfa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/home/nishadgothoskar/bayes3d/nvdiffrast/samples/data/\"\n",
    "with np.load(f'{datadir}/cube_p.npz') as f:\n",
    "    pos_idx, pos, col_idx, col = f.values()\n",
    "print(\"Mesh has %d triangles and %d vertices.\" % (pos_idx.shape[0], pos.shape[0]))\n",
    "\n",
    "# Some input geometry contains vertex positions in (N, 4) (with v[:,3]==1).  Drop\n",
    "# the last column in that case.\n",
    "if pos.shape[1] == 4: pos = pos[:, 0:3]\n",
    "\n",
    "# Create position/triangle index tensors\n",
    "pos_idx = torch.from_numpy(pos_idx.astype(np.int32)).cuda()\n",
    "vtx_pos = torch.from_numpy(pos.astype(np.float32)).cuda()\n",
    "col_idx = torch.from_numpy(col_idx.astype(np.int32)).cuda()\n",
    "vtx_col = torch.from_numpy(col.astype(np.float32)).cuda()\n",
    "print(pos_idx.shape, vtx_pos.shape, col_idx.shape, vtx_col.shape)\n",
    "print(vtx_col)\n",
    "\n",
    "# model_dir = os.path.join(b.utils.get_assets_dir(),\"bop/ycbv/models\")\n",
    "# idx = 14\n",
    "# mesh_path = os.path.join(model_dir,\"obj_\" + \"{}\".format(idx).rjust(6, '0') + \".ply\")\n",
    "# m = b.utils.load_mesh(mesh_path)\n",
    "# m = b.utils.scale_mesh(m, 1.0/100.0)\n",
    "\n",
    "# vtx_pos = torch.from_numpy(m.vertices.astype(np.float32)).cuda()\n",
    "# pos_idx = torch.from_numpy(m.faces.astype(np.int32)).cuda()\n",
    "# col_idx = torch.from_numpy(np.zeros((vtx_pos.shape[0],3)).astype(np.int32)).cuda()\n",
    "# vtx_col = torch.from_numpy(np.ones((1,3)).astype(np.float32)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f93c7-f7e8-427f-8ea5-365370a9560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation_target = torch.tensor(q_rnd(), device='cuda')\n",
    "position_target = torch.tensor(q_rnd(), device='cuda')\n",
    "rast_target = render(glctx, torch.matmul(mvp, q_to_mtx(pose_target)), vtx_pos, pos_idx, vtx_col, col_idx, resolution)\n",
    "img_target  = rast_target[0].detach().cpu().numpy()\n",
    "b.hstack_images([\n",
    "    b.get_depth_image(img_target[:,:,0]* 255.0) ,\n",
    "])\n",
    "pose_init   = pose_target.cpu().numpy() + 0.3\n",
    "pose_opt    = torch.tensor(pose_init / np.sum(pose_init**2)**0.5, dtype=torch.float32, device='cuda', requires_grad=True)\n",
    "loss_best   = np.inf\n",
    "\n",
    "rast_opt = render(glctx, torch.matmul(mvp, q_to_mtx(pose_opt)), vtx_pos, pos_idx, vtx_col, col_idx, resolution)\n",
    "img_opt  = rast_opt[0].detach().cpu().numpy()\n",
    "b.hstack_images([\n",
    "    b.get_depth_image(img_opt[:,:,0]* 255.0) ,\n",
    "    b.get_depth_image(img_target[:,:,0]* 255.0) ,\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98ecb0-6e55-4280-af4f-6639e5d69f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([pose_opt], betas=(0.9, 0.999), lr=0.001)\n",
    "images = []\n",
    "pbar = tqdm(range(600))\n",
    "for _ in pbar:\n",
    "    noise = q_unit()\n",
    "    pose_total_opt = q_mul_torch(pose_opt, noise)\n",
    "    mtx_total_opt  = torch.matmul(mvp, q_to_mtx(pose_total_opt))\n",
    "    rast_opt = render(glctx, torch.matmul(mvp, q_to_mtx(pose_total_opt)), vtx_pos, pos_idx, vtx_col, col_idx, resolution)\n",
    "\n",
    "    diff = (rast_opt - rast_target)**2 # L2 norm.\n",
    "    diff = torch.tanh(5.0 * torch.max(diff, dim=-1)[0])\n",
    "    loss = torch.mean(diff)\n",
    "    loss_val = float(loss)\n",
    "    pbar.set_description(f\"{loss_val}\")\n",
    "    \n",
    "    if (loss_val < loss_best) and (loss_val > 0.0):\n",
    "        loss_best = loss_val\n",
    "                \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pose_opt /= torch.sum(pose_opt**2)**0.5\n",
    "    \n",
    "    img_opt  = rast_opt[0].detach().cpu().numpy()\n",
    "    images.append(\n",
    "b.hstack_images([\n",
    "    b.get_depth_image(img_opt[:,:,0]* 255.0) ,\n",
    "    b.get_depth_image(img_target[:,:,0]* 255.0) ,\n",
    "])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651d8eb-75c3-4453-b58c-09e46ce2b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.vstack_images([images[0],images[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1f6dc-31e1-4c33-97c3-d13fa8e5f34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921bcb5-4d8b-4b0f-8b9f-f3d70ca43522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f58562-0672-4e28-810b-2e30e7c849e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15dc7cd-0aef-44c7-a821-368b512c9fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
