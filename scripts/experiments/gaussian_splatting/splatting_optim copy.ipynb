{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1107990/2151526459.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  proj_matrix = torch.tensor(getProjectionMatrix(intrinsics), device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1000, 0.2000],\n",
      "        [0.0000, 0.1000, 0.2000],\n",
      "        [0.0000, 0.1000, 0.2000],\n",
      "        [0.0000, 0.1000, 0.2000],\n",
      "        [0.0000, 0.1000, 0.2000]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1107990/2151526459.py:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  quat =  torch.tensor(torch.rand(4,device=device) - 0.5,device=device)\n",
      "/var/tmp/ipykernel_1107990/2151526459.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scales = torch.tensor( 0.0025 * torch.rand((N, 3)),requires_grad=True,device=device)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import diff_gaussian_rasterization as dgr\n",
    "from diff_gaussian_rasterization import GaussianRasterizationSettings, GaussianRasterizer\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import bayes3d as b\n",
    "import jax.numpy as jnp\n",
    "from random import randint\n",
    "import pytorch3d.transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "intrinsics = b.Intrinsics(\n",
    "    height=100,\n",
    "    width=100,\n",
    "    fx=100.0, fy=100.0,\n",
    "    cx=50.0, cy=50.0,\n",
    "    near=0.01, far=2.5\n",
    ")\n",
    "fovX = jnp.arctan(intrinsics.width / 2 / intrinsics.fx) * 2\n",
    "fovY = jnp.arctan(intrinsics.height / 2 / intrinsics.fy) * 2\n",
    "tan_fovx = math.tan(fovX)\n",
    "tan_fovy = math.tan(fovY)\n",
    "\n",
    "\n",
    "def getProjectionMatrix(intrinsics):\n",
    "    top = intrinsics.near / intrinsics.fy * intrinsics.height / 2.0\n",
    "    bottom = -top\n",
    "    right = intrinsics.near / intrinsics.fy * intrinsics.height / 2.0\n",
    "    left = -right\n",
    "\n",
    "    P = torch.zeros(4, 4)\n",
    "\n",
    "    z_sign = 1.0\n",
    "\n",
    "    P[0, 0] = 2.0 * intrinsics.near / (right - left)\n",
    "    P[1, 1] = 2.0 * intrinsics.near / (top - bottom)\n",
    "    P[0, 2] = (right + left) / (right - left)\n",
    "    P[1, 2] = (top + bottom) / (top - bottom)\n",
    "    P[2, 2] = z_sign * (intrinsics.far + intrinsics.near) / (intrinsics.far - intrinsics.near)\n",
    "    P[2, 3] = -2.0 * (intrinsics.far * intrinsics.near) / (intrinsics.far - intrinsics.near)\n",
    "    P[3, 2] = z_sign\n",
    "    return torch.transpose(P, 0, 1)\n",
    "\n",
    "proj_matrix = torch.tensor(getProjectionMatrix(intrinsics), device=device)\n",
    "\n",
    "def posevec_to_matrix(position, quat):\n",
    "    return torch.cat(\n",
    "        (\n",
    "            torch.cat((pytorch3d.transforms.quaternion_to_matrix(quat), position.unsqueeze(1)), 1),\n",
    "            torch.tensor([[0.0, 0.0, 0.0, 1.0]],device=device),\n",
    "        ),\n",
    "        0,\n",
    "    )\n",
    "def apply_transform(points, transform):\n",
    "    rels_ = torch.cat(\n",
    "        (\n",
    "            points,\n",
    "            torch.ones((points.shape[0], 1),  device=device),\n",
    "        ),\n",
    "        1,\n",
    "    )\n",
    "    return torch.einsum(\"ij, aj -> ai\", transform, rels_)[...,:3]\n",
    "position = torch.tensor([0.0, 0.1, 0.2], device=device)\n",
    "quat = torch.tensor([1.0, 0.1, 0.2, 0.3],device=device)\n",
    "points = torch.zeros((5,3), device = device)\n",
    "print(apply_transform(points, posevec_to_matrix(position, quat)))\n",
    "\n",
    "camera_pose = jnp.eye(4)\n",
    "view_matrix = torch.transpose(torch.tensor(np.array(b.inverse_pose(camera_pose))),0,1).cuda()\n",
    "raster_settings = GaussianRasterizationSettings(\n",
    "    image_height=int(intrinsics.height),\n",
    "    image_width=int(intrinsics.width),\n",
    "    tanfovx=tan_fovx,\n",
    "    tanfovy=tan_fovy,\n",
    "    bg=torch.tensor([intrinsics.far, intrinsics.far, intrinsics.far]).cuda(),\n",
    "    scale_modifier=1.0,\n",
    "    viewmatrix=view_matrix,\n",
    "    projmatrix=view_matrix @ proj_matrix,\n",
    "    sh_degree=1,\n",
    "    campos=torch.zeros(3).cuda(),\n",
    "    prefiltered=False,\n",
    "    debug=None\n",
    ")\n",
    "rasterizer = GaussianRasterizer(raster_settings=raster_settings)\n",
    "\n",
    "model_dir = os.path.join(b.utils.get_assets_dir(),\"bop/ycbv/models\")\n",
    "mesh_path = os.path.join(model_dir,\"obj_\" + \"{}\".format(14).rjust(6, '0') + \".ply\")\n",
    "mesh = b.utils.load_mesh(mesh_path)\n",
    "vertices = torch.tensor(np.array(jnp.array(mesh.vertices) / 1000.0),device=device)\n",
    "\n",
    "def render(pos,quat):\n",
    "    means3D = apply_transform(vertices, posevec_to_matrix(pos, quat))\n",
    "    N = means3D.shape[0]\n",
    "    means2D = torch.ones((N, 3),requires_grad=True, device=device)\n",
    "    opacity = torch.rand((N, 1),requires_grad=True,device=device)\n",
    "    scales = torch.tensor( 0.0025 * torch.rand((N, 3)),requires_grad=True,device=device)\n",
    "    rotations = torch.rand((N, 4),requires_grad=True,device=device)\n",
    "\n",
    "    data = rasterizer(\n",
    "        means3D = means3D,\n",
    "        means2D = means2D,\n",
    "        shs = None,\n",
    "        colors_precomp = means3D[:,2:3],\n",
    "        opacities = opacity,\n",
    "        scales = scales,\n",
    "        rotations = rotations\n",
    "    )\n",
    "    return data\n",
    "\n",
    "pos = torch.tensor([0.0, 0.0, 0.5],device=device)\n",
    "quat =  torch.tensor(torch.rand(4,device=device) - 0.5,device=device)\n",
    "\n",
    "color, radii =  render(pos, quat)\n",
    "depth_image = np.moveaxis(color.detach().cpu().numpy(),0,-1)[...,2]\n",
    "\n",
    "# out_weights = out_weights.detach().cpu().numpy()\n",
    "# tensor_ranges = tensor_ranges.detach().cpu().numpy()\n",
    "# gaussian_sorted = gaussian_sorted.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "viz_gt = b.get_depth_image(depth_image)\n",
    "viz_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 100])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intrinsics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nishadgothoskar/bayes3d/scripts/experiments/gaussian_splatting/splatting_optim copy.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.70.144.22/home/nishadgothoskar/bayes3d/scripts/experiments/gaussian_splatting/splatting_optim%20copy.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m BLOCK_Y \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.70.144.22/home/nishadgothoskar/bayes3d/scripts/experiments/gaussian_splatting/splatting_optim%20copy.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m BLOCK_SIZE \u001b[39m=\u001b[39m BLOCK_X\u001b[39m*\u001b[39m BLOCK_Y\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B34.70.144.22/home/nishadgothoskar/bayes3d/scripts/experiments/gaussian_splatting/splatting_optim%20copy.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m num_tiles_x \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m((intrinsics\u001b[39m.\u001b[39mwidth \u001b[39m+\u001b[39m BLOCK_X \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m BLOCK_X)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.70.144.22/home/nishadgothoskar/bayes3d/scripts/experiments/gaussian_splatting/splatting_optim%20copy.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m num_tiles_y \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m((intrinsics\u001b[39m.\u001b[39mheight \u001b[39m+\u001b[39m BLOCK_Y \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m BLOCK_Y)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.70.144.22/home/nishadgothoskar/bayes3d/scripts/experiments/gaussian_splatting/splatting_optim%20copy.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m num_tiles \u001b[39m=\u001b[39m num_tiles_x \u001b[39m*\u001b[39m num_tiles_y\n",
      "\u001b[0;31mNameError\u001b[0m: name 'intrinsics' is not defined"
     ]
    }
   ],
   "source": [
    "BLOCK_X = 16\n",
    "BLOCK_Y = 16\n",
    "BLOCK_SIZE = BLOCK_X* BLOCK_Y\n",
    "num_tiles_x = int((intrinsics.width + BLOCK_X - 1) / BLOCK_X)\n",
    "num_tiles_y = int((intrinsics.height + BLOCK_Y - 1) / BLOCK_Y)\n",
    "num_tiles = num_tiles_x * num_tiles_y\n",
    "\n",
    "\n",
    "# Print all relevant info.\n",
    "\n",
    "assert tensor_ranges.shape[0] == num_tiles * 2\n",
    "num_gaussians = gaussian_sorted.shape[0]\n",
    "assert out_weights.shape[0] == num_gaussians * BLOCK_X* BLOCK_Y\n",
    "\n",
    "img = np.zeros((intrinsics.height, intrinsics.width))\n",
    "\n",
    "\n",
    "for tile in tqdm(range(num_tiles)):\n",
    "    print(f\"TILE {tile}\")\n",
    "    range_x, range_y = tensor_ranges[2*tile], tensor_ranges[2*tile + 1]\n",
    "    start_index = (BLOCK_SIZE * range_x)\n",
    "    print(start_index)\n",
    "    num_gaussians_in_this_block = range_y - range_x\n",
    "    print(f\"NUM GAUSSIANS IN THIS BLOCK {num_gaussians_in_this_block}\")\n",
    "    if num_gaussians_in_this_block == 0:\n",
    "        continue\n",
    "    for ii in range(BLOCK_X):\n",
    "        for jj in range(BLOCK_Y):\n",
    "            pixel_index_in_block = jj * BLOCK_X + ii\n",
    "            u,v = (start_index + pixel_index_in_block * num_gaussians_in_this_block, start_index + (pixel_index_in_block + 1) * num_gaussians_in_this_block)\n",
    "            print(u,v)\n",
    "            weights = out_weights[u:v]\n",
    "            maximum_weight = weights.max()\n",
    "            img[tile // num_tiles_y * BLOCK_Y + jj, tile % num_tiles_x * BLOCK_X + ii] = maximum_weight\n",
    "plt.matshow(img)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc9181b92e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(depth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ranges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  4849\n",
      "4849  11793\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "11793  19001\n",
      "19001  28809\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "0  0\n",
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_787001/2567456983.py:100: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scales = torch.tensor( 0.0025 * torch.rand((N, 3)),requires_grad=True,device=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 6916, 15673,  7166, 15981, 15982,  7164, 15980,  7177, 15992,  7151,\n",
       "        15960, 15961, 15962,  7492, 16404, 16405,  7160,  7167, 15983,  7129,\n",
       "         7188,  7296, 16124, 16125,  7494, 16407, 16408,  7162, 15978,  7502,\n",
       "        16412,  7155, 15968,  7183, 15998,  7508, 16414, 16415,  7154, 15967,\n",
       "         7165,  7503, 16413,  7300, 16131, 16132,  7291, 16118,  7493, 16406,\n",
       "         7479, 16394,  7441, 16349, 16350,  7153, 15965, 15966,  7452, 16361,\n",
       "         7152, 15963, 15964,  7125, 15928, 15929,  7170, 15988, 15989,  7146,\n",
       "        15954, 15955,  7128, 15934, 15935, 15936,  7120, 15924, 15925,  7450,\n",
       "        16360,  7124,  7354, 16228, 16229,  7293, 16120,  7169, 15986, 15987,\n",
       "         7837, 16744,  7100, 15894, 15895, 15896, 15897, 15898],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "color, radii, num_rendered, tiles_depth_sorted,gaussian_sorted,tensor_ranges,alpha_tensor=  render(pos, quat)\n",
    "depth_image = np.moveaxis(color.detach().cpu().numpy(),0,-1)[...,2]\n",
    "viz_gt = b.get_depth_image(depth_image)\n",
    "viz_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signedToUnsigned(n, byte_count): \n",
    "  return int.from_bytes(n.to_bytes(byte_count, 'little', signed=True), 'little', signed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4294967289], dtype=uint32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([-7]).astype(np.int32)\n",
    "a.astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7789"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signedToUnsigned(int(t[0]),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7789"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7789, 16670, 16671,  7798, 16681, 16682,  7262, 16079,  7257,\n",
       "       16071, 16072,  7225, 16044, 16045,  7258, 16073, 16074,  7799,\n",
       "       16683,  7791, 16673,  7763, 16636, 16637,  7793, 16675,  7261,\n",
       "       16077, 16078,  7224, 16043,  7790, 16672,  7235,  7775, 16658,\n",
       "       16659,  7248, 16062, 16063,  7249, 16064, 16065,  7766, 16643,\n",
       "        7176,  7229,  7780, 16664,  7251,  7797,  7776, 16660,  7399,\n",
       "       16290,  7230,  7172,  7097, 15892, 15893,  7247,  7222, 16041,\n",
       "       16042,  7231,  7218,  7779,  7091, 15884, 15885,  7214, 16033,\n",
       "       16034,  7244,  7163,  7223,  7217, 16036,  7072, 15851, 15852,\n",
       "        7219, 16037,  7227, 16046,  7401, 16293, 16294,  7211, 16029,\n",
       "        7149, 15957, 15958,  7228, 16047, 16048,  7209,  7252],\n",
       "      dtype=uint32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".view(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7010/static/\n"
     ]
    }
   ],
   "source": [
    "b.setup_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_779547/2926322865.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  proj_matrix = torch.tensor(getProjectionMatrix(intrinsics), device=device)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1000, 0.2000],\n",
      "        [0.0000, 0.1000, 0.2000],\n",
      "        [0.0000, 0.1000, 0.2000],\n",
      "        [0.0000, 0.1000, 0.2000],\n",
      "        [0.0000, 0.1000, 0.2000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16763, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_rendered)\n",
    "print(tiles_depth_sorted.shape)\n",
    "print(gaussian_sorted.shape)\n",
    "print(alpha_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(alpha_tensor.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_depth_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_sorted.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_depth_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_depth_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(tiles_depth_sorted).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_sorted.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_depth_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.tensor([0.0, 0.0, 0.5],device=device)\n",
    "quat =  torch.tensor(torch.rand(4,device=device) - 0.5,device=device)\n",
    "\n",
    "data =  render(pos, quat).detach()\n",
    "depth_image = np.moveaxis(gt_rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.show_cloud(\"1\", b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3))\n",
    "viz_gt = b.get_depth_image(depth_image)\n",
    "viz_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.tensor([0.0, 0.0, 0.5],device=device, requires_grad=True)\n",
    "quat =  torch.tensor(quat + torch.rand(4,device=device)*0.1,device=device, requires_grad=True)\n",
    "rendered_image =  render(pos, quat)\n",
    "depth_image = np.moveaxis(rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.show_cloud(\"1\", b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3))\n",
    "viz = b.get_depth_image(depth_image)\n",
    "parameters_over_time = []\n",
    "losses_over_time = []\n",
    "b.hstack_images([viz, viz_gt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': [pos], 'lr': 0.0001, \"name\": \"pos\"},\n",
    "    {'params': [quat], 'lr': 0.001, \"name\": \"quat\"},\n",
    "], lr=0.0, eps=1e-15)\n",
    "\n",
    "\n",
    "pbar = tqdm(range(25))\n",
    "for _ in pbar:\n",
    "    rendered_image =  render(pos, quat)\n",
    "    loss = torch.abs(gt_rendered_image - rendered_image).mean()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    parameters_over_time.append((pos.detach().clone(),quat.detach().clone()))\n",
    "    losses_over_time.append(loss.item())\n",
    "    pbar.set_description(f\"{loss.item()}\")\n",
    "\n",
    "depth_image = np.moveaxis(rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "b.show_cloud(\"1\", b.unproject_depth_jit(depth_image, intrinsics).reshape(-1,3))\n",
    "viz = b.get_depth_image(depth_image)\n",
    "b.hstack_images([viz, viz_gt])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 0\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(2,2,1)\n",
    "ax.set_title(\"Target\")\n",
    "gt_image = np.moveaxis(gt_rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "img1 = ax.imshow(b.preprocess_for_viz(gt_image),cmap=b.cmap)\n",
    "ax = fig.add_subplot(2,2,2)\n",
    "parameters = parameters_over_time[T]\n",
    "rendered_image = render(*parameters)\n",
    "rendered_image = np.moveaxis(rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "img2 = ax.imshow(b.preprocess_for_viz(rendered_image),cmap=b.cmap)\n",
    "title = ax.set_title(f\"Reconstruction\")\n",
    "ax = fig.add_subplot(2,1,2)\n",
    "line = ax.plot(jnp.arange(T), losses_over_time[:T])\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_title(\"Pixelwise MSE Loss\")\n",
    "# ax.set_ylim(0.01, 1000.0)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_xlim(0,len(losses_over_time))\n",
    "fig.tight_layout()\n",
    "\n",
    "buffs = []\n",
    "for T in tqdm(range(0,len(losses_over_time),3)):\n",
    "    parameters = parameters_over_time[T]\n",
    "    rendered_image = render(*parameters)\n",
    "    rendered_image = np.moveaxis(rendered_image.detach().cpu().numpy(),0,-1)[...,2]\n",
    "    img2.set_array(b.preprocess_for_viz(rendered_image))\n",
    "    line[0].set_xdata(jnp.arange(T))\n",
    "    line[0].set_ydata(losses_over_time[:T])\n",
    "    fig.canvas.draw()\n",
    "    buffs.append(b.pil_image_from_matplotlib(fig))\n",
    "buffs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.make_gif_from_pil_images(buffs, \"optimization.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
