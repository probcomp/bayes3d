{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cognitive Battery Introduction: Jax-3DP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import jax3dp3\n",
    "from jax3dp3.viz import (\n",
    "    get_depth_image,\n",
    "    multi_panel,\n",
    ")\n",
    "from jax3dp3.transforms_3d import transform_from_pos, unproject_depth\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax3dp3.viz import make_gif_from_pil_images\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cog_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = \"gravity\"\n",
    "data_path = f\"/home/khaledshehada/cog_jax3dp3_data/{scene}_data/videos/\"\n",
    "num_frames = len(os.listdir(os.path.join(data_path, \"frames\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing frame buffer size to (width, height, depth) = (320, 320, 1024)\n"
     ]
    }
   ],
   "source": [
    "width = 300\n",
    "height = 300\n",
    "fov = 90\n",
    "\n",
    "fx, fy, cx, cy = utils.get_camera_intrinsics(width, height, fov)\n",
    "near, far = 0.001, 50.0\n",
    "\n",
    "intrinsics = jax3dp3.Intrinsics(height, width, fx, fy, cx, cy, near, far)\n",
    "renderer = jax3dp3.Renderer(intrinsics=intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_images, depth_images, seg_maps = [], [], []\n",
    "rgb_images_pil = []\n",
    "for i in range(num_frames):\n",
    "    rgb_path = os.path.join(data_path, f\"frames/frame_{i}.jpeg\")\n",
    "    if not os.path.isfile(rgb_path):\n",
    "        rgb_path = rgb_path.replace(\"jpeg\", \"png\")\n",
    "    rgb_img = Image.open(rgb_path)\n",
    "    rgb_images_pil.append(rgb_img)\n",
    "    rgb_images.append(np.array(rgb_img))\n",
    "\n",
    "    depth_path = os.path.join(data_path, f\"depths/frame_{i}.npy\")\n",
    "    depth_npy = np.load(depth_path)\n",
    "    depth_images.append(depth_npy)\n",
    "\n",
    "    seg_map = np.load(os.path.join(data_path, f\"segmented/frame_{i}.npy\"))\n",
    "    seg_maps.append(seg_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_images = []  # depth data in 2d view as images\n",
    "seg_images = []  # segmentation data as images\n",
    "\n",
    "for frame_idx in range(num_frames):\n",
    "    coord_image = unproject_depth(depth_images[frame_idx], intrinsics)\n",
    "    segmentation_image = seg_maps[frame_idx].copy()\n",
    "    mask = np.invert(\n",
    "        (coord_image[:, :, 0] < 1.1)\n",
    "        * (coord_image[:, :, 0] > -1)\n",
    "        * (coord_image[:, :, 1] < 0.565)\n",
    "        * (coord_image[:, :, 1] > -1)\n",
    "        * (coord_image[:, :, 2] > 1.2)\n",
    "        * (coord_image[:, :, 2] < 1.35)\n",
    "    )\n",
    "    coord_image[mask, :] = 0.0\n",
    "    segmentation_image[mask, :] = 0.0\n",
    "    coord_images.append(coord_image)\n",
    "    seg_images.append(segmentation_image)\n",
    "\n",
    "coord_images = np.stack(coord_images)\n",
    "seg_images = np.stack(seg_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "tube_s_long\n",
      "bowl\n",
      "tube_s\n"
     ]
    }
   ],
   "source": [
    "# Load meshes\n",
    "meshes = []\n",
    "meshes_path = \"/home/khaledshehada/cog_jax3dp3_data/gravity_data/meshes/\"\n",
    "for mesh_name in os.listdir(meshes_path):\n",
    "    mesh_path = os.path.join(meshes_path, mesh_name)\n",
    "    renderer.add_mesh_from_file(mesh_path, force=\"mesh\")\n",
    "    meshes.append(mesh_name.replace(\".obj\", \"\"))\n",
    "    print(meshes[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=300x300 at 0x7F226CDD7390>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_t = 36\n",
    "seg_img = seg_images[start_t]\n",
    "Image.fromarray(seg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=300x300 at 0x7F225C0B8510>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_objects = 12\n",
    "indices, init_poses = [], []\n",
    "obj_ids = jnp.unique(seg_img.reshape(-1, 3), axis=0)\n",
    "obj_ids = sorted(\n",
    "    obj_ids, key=lambda x: jnp.all(seg_img == x, axis=-1).sum(), reverse=True\n",
    ")\n",
    "for obj_id in obj_ids[: num_objects + 1]:\n",
    "    if jnp.all(obj_id == 0):\n",
    "        # Background\n",
    "        continue\n",
    "\n",
    "    obj_mask = jnp.all(seg_img == obj_id, axis=-1)\n",
    "    masked_depth = coord_images[start_t].copy()\n",
    "    masked_depth[~obj_mask] = 0\n",
    "\n",
    "    object_points = coord_images[start_t][obj_mask]\n",
    "    maxs = np.max(object_points, axis=0)\n",
    "    mins = np.min(object_points, axis=0)\n",
    "    dims = maxs - mins\n",
    "    obj_center = (maxs + mins) / 2\n",
    "    obj_transform = transform_from_pos(obj_center)\n",
    "\n",
    "    best = None\n",
    "    k = np.inf\n",
    "    for m in range(len(meshes)):\n",
    "        obj_transforms = utils.get_object_transforms(meshes[m], obj_transform)\n",
    "        for i, transform in enumerate(obj_transforms):\n",
    "            rendered_image = renderer.render_single_object(transform, m)\n",
    "            keep_points = (\n",
    "                jnp.sum(\n",
    "                    jnp.logical_or(\n",
    "                        (\n",
    "                            (masked_depth[:, :, 2] != 0.0)\n",
    "                            * (rendered_image[:, :, 2] == 0)\n",
    "                        ),\n",
    "                        (\n",
    "                            (masked_depth[:, :, 2] == 0.0)\n",
    "                            * (rendered_image[:, :, 2] != 0)\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "                / (rendered_image[:, :, 2] != 0.0).sum()\n",
    "            )\n",
    "            if keep_points < k:\n",
    "                k = keep_points\n",
    "                best = (m, transform)\n",
    "    if best:\n",
    "        indices.append(best[0])\n",
    "        init_poses.append(best[1])\n",
    "\n",
    "init_poses = jnp.array(init_poses)\n",
    "rendered_image = renderer.render_multiobject(init_poses, indices)\n",
    "get_depth_image(rendered_image[:, :, 2], max=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liklihood parameters\n",
    "r = radius = 0.1\n",
    "outlier_prob = 0.01\n",
    "outlier_volume = 10\n",
    "\n",
    "# Enumeration parameters\n",
    "n = 7  # number of enumerated proposals on each dimension (x, y, z).\n",
    "d = 0.05  # the minimum and maximum position delta on each dimension (x, y, z).\n",
    "\n",
    "# Enumerating proposals\n",
    "translation_deltas = jax3dp3.make_translation_grid_enumeration(\n",
    "    -d, -d, -d, d, d, d, n, n, n\n",
    ")\n",
    "\n",
    "\n",
    "def scorer(rendered_image, gt, prior):\n",
    "    weight = jax3dp3.likelihood.threedp3_likelihood(\n",
    "        gt, rendered_image, r, outlier_prob, outlier_volume\n",
    "    )\n",
    "    return prior * weight\n",
    "\n",
    "\n",
    "scorer_parallel = jax.vmap(scorer, in_axes=(0, None, 0))\n",
    "scorer_parallel_jit = jax.jit(scorer_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea for liklihood model under occlusion:\n",
    "pose_estimates = init_poses.copy()\n",
    "t = start_t\n",
    "gt_image = jnp.array(coord_images[t])\n",
    "\n",
    "translation_deltas_full = jnp.tile(\n",
    "    jnp.eye(4)[None, :, :],\n",
    "    (translation_deltas.shape[0], pose_estimates.shape[0], 1, 1),\n",
    ")\n",
    "translation_deltas_full = translation_deltas_full.at[:, 0, :, :].set(translation_deltas)\n",
    "translation_proposals = jnp.einsum(\n",
    "    \"bij,abjk->abik\", pose_estimates, translation_deltas_full\n",
    ")\n",
    "images = renderer.render_parallel(translation_proposals, 0)\n",
    "prior = jnp.ones((translation_deltas.shape[0],))\n",
    "weights_new = scorer_parallel_jit(images, gt_image, prior)\n",
    "pose_estimates = translation_proposals[jnp.argmax(weights_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "num_steps = num_frames - start_t\n",
    "num_steps = 10\n",
    "inferred_poses = []\n",
    "occlusion_threshold = 10\n",
    "pose_estimates = init_poses.copy()\n",
    "# tqdm = lambda x: x\n",
    "# occluded = False\n",
    "for t in tqdm(range(start_t, start_t + num_steps)):\n",
    "    gt_image = jnp.array(coord_images[t])\n",
    "    # New objects\n",
    "    n_objects = pose_estimates.shape[0]\n",
    "    for i in range(n_objects):\n",
    "        # Check for occlusion\n",
    "        depth_wi = renderer.render_multiobject(pose_estimates, indices)\n",
    "        depth_woi = renderer.render_multiobject(pose_estimates[:i], indices[:i])\n",
    "        if jnp.sum(depth_wi[:, :, 2] != depth_woi[:, :, 2]) < occlusion_threshold:\n",
    "            # prior = (1 - translation_deltas[:,1,3]) * abs(translation_deltas[:,0,3]) * abs(translation_deltas[:,2,3])\n",
    "            prior = (1 - translation_deltas[:, 1, 3]) * abs(translation_deltas[:, 2, 3])\n",
    "        else:\n",
    "            prior = jnp.ones((translation_deltas.shape[0],))\n",
    "\n",
    "        pose_estimate = pose_estimates[i]\n",
    "        translation_proposals = jnp.einsum(\n",
    "            \"ij,ajk->aik\", pose_estimate, translation_deltas\n",
    "        )\n",
    "        images = renderer.render_parallel(translation_proposals, indices[i])\n",
    "        weights_new = scorer_parallel_jit(images, gt_image, prior)\n",
    "        best_weight_idx = jnp.argmax(weights_new)\n",
    "        pose_estimate = translation_proposals[best_weight_idx]\n",
    "        pose_estimates = pose_estimates.at[i].set(pose_estimate)\n",
    "\n",
    "    inferred_poses.append(pose_estimates.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_pos = pose_estimates[-1, :-1, 3]\n",
    "sorted_bowls = sorted(\n",
    "    [\n",
    "        pose_estimates[i, :-1, 3]\n",
    "        for i in range(len(indices))\n",
    "        if meshes[indices[i]] == \"bowl\"\n",
    "    ],\n",
    "    key=lambda x: x[0].item(),\n",
    ")\n",
    "closest_bowl_idx = jnp.argmin(\n",
    "    jnp.array([abs(apple_pos[0] - bowl_pos[0]) for bowl_pos in sorted_bowls])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output to: out/gravity_out.gif\n"
     ]
    }
   ],
   "source": [
    "all_images = []\n",
    "for t in tqdm(range(start_t, start_t + num_steps)):\n",
    "    rgb_viz = Image.fromarray(rgb_images[t].astype(np.int8), mode=\"RGB\")\n",
    "    gt_depth_1 = get_depth_image(coord_images[t][:, :, 2], max=5.0)\n",
    "    poses = inferred_poses[t - start_t]\n",
    "    rendered_image = renderer.render_multiobject(poses, indices)\n",
    "    rendered_image = get_depth_image(rendered_image[:, :, 2], max=5)\n",
    "\n",
    "    apple_pose = poses[-1]\n",
    "    rendered_apple = renderer.render_single_object(apple_pose, indices[-1])\n",
    "    rendered_apple = get_depth_image(rendered_apple[:, :, 2], max=5)\n",
    "    all_images.append(\n",
    "        multi_panel(\n",
    "            [rgb_viz, gt_depth_1, rendered_image, rendered_apple],\n",
    "            [\n",
    "                f\"Class: {closest_bowl_idx}\\nRGB Image\",\n",
    "                f\"   Frame: {t}\\nActual Depth\",\n",
    "                \"\\nReconstructed Depth\",\n",
    "                \"\\nApple Only\",\n",
    "            ],\n",
    "            middle_width=10,\n",
    "            label_fontsize=20,\n",
    "        )\n",
    "    )\n",
    "out_path = f\"out/{scene}_out.gif\"\n",
    "make_gif_from_pil_images(all_images, out_path)\n",
    "print(\"Saved output to:\", out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a3868bdd7d3c8a3e0bdbdcc5d56cecdac1cfc8e4c924f480e3352f5fc391e73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
