{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jax\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import genjax\n",
    "import bayes3d as b\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../\")\n",
    "from viz import *\n",
    "from utils import *\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import bayes3d.transforms_3d as t3d\n",
    "from jax.debug import print as jprint\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from genjax._src.core.pytree.utilities import *\n",
    "from genjax.generative_functions.distributions import ExactDensity\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "import jax.tree_util as jtu\n",
    "from genjax._src.core.transforms.incremental import NoChange, UnknownChange, Diff\n",
    "console = genjax.pretty()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_weights(log_weights):\n",
    "    log_total_weight = logsumexp(log_weights)\n",
    "    log_normalized_weights = log_weights - log_total_weight\n",
    "    return log_normalized_weights\n",
    "\n",
    "def ess(log_normalized_weights):\n",
    "    log_ess = -logsumexp(2. * log_normalized_weights)\n",
    "    return jnp.exp(log_ess)\n",
    "\n",
    "\n",
    "class MCS_Observation:\n",
    "    def __init__(self, rgb, depth, intrinsics, segmentation):\n",
    "        \"\"\"RGBD Image\n",
    "        \n",
    "        Args:\n",
    "            rgb (np.array): RGB image\n",
    "            depth (np.array): Depth image\n",
    "            camera_pose (np.array): Camera pose. 4x4 matrix\n",
    "            intrinsics (b.camera.Intrinsics): Camera intrinsics\n",
    "            segmentation (np.array): Segmentation image\n",
    "        \"\"\"\n",
    "        self.rgb = rgb\n",
    "        self.depth = depth\n",
    "        self.intrinsics = intrinsics\n",
    "        self.segmentation  = segmentation\n",
    "\n",
    "load_observations_npz = lambda x : np.load('val7_physics_npzs' + \"/{}.npz\".format(x),allow_pickle=True)[\"arr_0\"]\n",
    "\n",
    "def observations_to_data_by_frame(observations, frame_idx, scale = 0.5):\n",
    "    intrinsics_data = observations[frame_idx].intrinsics\n",
    "    if 'cam_pose' in dir(observations[frame_idx]):\n",
    "        cam_pose = observations[frame_idx].cam_pose\n",
    "    else:\n",
    "        cam_pose = CAM_POSE_CV2\n",
    "\n",
    "    intrinsics = b.scale_camera_parameters(b.Intrinsics(intrinsics_data[\"height\"],intrinsics_data[\"width\"],\n",
    "                            intrinsics_data[\"fx\"], intrinsics_data[\"fy\"],\n",
    "                            intrinsics_data[\"cx\"],intrinsics_data[\"cy\"],\n",
    "                            intrinsics_data[\"near\"],intrinsics_data[\"far\"]),scale)\n",
    "    \n",
    "    obs = observations[frame_idx]\n",
    "    depth = np.asarray(jax.image.resize(obs.depth, (int(obs.depth.shape[0] * scale), \n",
    "                        int(obs.depth.shape[1] * scale)), 'nearest'))\n",
    "    seg = np.asarray(jax.image.resize(obs.segmentation, (int(obs.segmentation.shape[0] * scale), \n",
    "                        int(obs.segmentation.shape[1] * scale)), 'nearest'))\n",
    "    rgb = np.asarray(jax.image.resize(obs.rgb, (int(obs.rgb.shape[0] * scale), \n",
    "                        int(obs.rgb.shape[1] * scale), 3), 'nearest'))\n",
    "    gt_image = np.asarray(b.unproject_depth_jit(depth, intrinsics))\n",
    "\n",
    "    return gt_image, depth, seg, rgb, intrinsics, cam_pose\n",
    "\n",
    "def observations_to_data(observations, scale = 0.5):\n",
    "    intrinsics_data = observations[0].intrinsics\n",
    "    intrinsics = b.scale_camera_parameters(b.Intrinsics(intrinsics_data[\"height\"],intrinsics_data[\"width\"],\n",
    "                            intrinsics_data[\"fx\"], intrinsics_data[\"fy\"],\n",
    "                            intrinsics_data[\"cx\"],intrinsics_data[\"cy\"],\n",
    "                            intrinsics_data[\"near\"],intrinsics_data[\"far\"]),scale)\n",
    "    \n",
    "    depths = [jax.image.resize(obs.depth, (int(obs.depth.shape[0] * scale), \n",
    "                        int(obs.depth.shape[1] * scale)), 'nearest') for obs in observations]\n",
    "    segs = [jax.image.resize(obs.segmentation, (int(obs.segmentation.shape[0] * scale), \n",
    "                        int(obs.segmentation.shape[1] * scale)), 'nearest') for obs in observations]\n",
    "    rgbs = [jax.image.resize(obs.rgb, (int(obs.rgb.shape[0] * scale), \n",
    "                        int(obs.rgb.shape[1] * scale), 3), 'nearest') for obs in observations]\n",
    "    \n",
    "    gt_images = b.unproject_depth_vmap_jit(np.stack(depths), intrinsics)\n",
    "\n",
    "    return gt_images, depths, segs, rgbs, intrinsics\n",
    "\n",
    "def fake_masker(point_cloud_image, segmentation, object_mask, object_ids, id, iter):\n",
    "    object_ids = object_ids.at[iter].set(-1)\n",
    "    return object_ids, object_mask\n",
    "\n",
    "def inner_add_mask(object_mask, object_ids, segmentation, id,iter):\n",
    "    object_mask += (segmentation == id)\n",
    "    object_ids = object_ids.at[iter].set(id)\n",
    "    return object_ids, object_mask \n",
    "\n",
    "def inner_fake(object_mask, object_ids, segmentation, id,iter):\n",
    "    object_ids = object_ids.at[iter].set(-1)\n",
    "    return object_ids, object_mask\n",
    "\n",
    "def masker_f(point_cloud_image, segmentation, object_mask, object_ids, id, iter):\n",
    "\n",
    "    mask = segmentation == id\n",
    "    # Use the mask to select elements, keeping the original shape\n",
    "    masked_point_cloud_segment = jnp.where(mask[..., None], point_cloud_image, jnp.nan)\n",
    "\n",
    "    bbox_dims = custom_aabb(masked_point_cloud_segment)\n",
    "    jprint(\"{}\",bbox_dims)\n",
    "    is_occluder = jnp.logical_or(jnp.logical_or(jnp.logical_or(jnp.logical_or(\n",
    "                    (bbox_dims[0] < 0.1),\n",
    "                    (bbox_dims[1] < 0.1)),\n",
    "                (bbox_dims[1] > 1.1)),\n",
    "            (bbox_dims[0] > 1.1)),\n",
    "        (bbox_dims[2] > 2.1)\n",
    "    )\n",
    "    return jax.lax.cond(is_occluder, inner_fake, inner_add_mask,*(object_mask, object_ids, segmentation, id, iter))\n",
    "\n",
    "def custom_aabb(object_points):\n",
    "    maxs = jnp.nanmax(object_points, axis = (0,1))\n",
    "    mins = jnp.nanmin(object_points, axis = (0,1))\n",
    "    dims = (maxs - mins)\n",
    "    center = (maxs + mins) / 2\n",
    "    return dims\n",
    "\n",
    "@jax.jit\n",
    "def get_object_mask(point_cloud_image, segmentation):\n",
    "    segmentation_ids = jnp.unique(segmentation, size = 10, fill_value = -1)\n",
    "    object_mask = jnp.zeros(point_cloud_image.shape[:2])\n",
    "    object_ids = jnp.zeros(10)\n",
    "    def scan_fn(carry, id):\n",
    "        object_mask, object_ids, iter = carry\n",
    "        object_ids, object_mask = jax.lax.cond(id == -1, fake_masker, masker_f,*(point_cloud_image, segmentation, object_mask, object_ids, id, iter))\n",
    "        return (object_mask, object_ids, iter + 1), None\n",
    "    \n",
    "    (object_mask, object_ids, _), _ = jax.lax.scan(scan_fn, (object_mask, object_ids, 0), segmentation_ids)\n",
    "                                               \n",
    "    object_mask = object_mask > 0\n",
    "    return object_ids, object_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "WALL_Z = 14.\n",
    "CAM_POSE = np.array([[ 1,0,0,0],\n",
    "[0,0,-1,-4.5], # 4.5 is an arbitrary value\n",
    "[ 0,1,0,1.5],\n",
    "[ 0,0,0,1]])\n",
    "World2Cam = np.linalg.inv(CAM_POSE)\n",
    "World2Cam[1:3] *= -1\n",
    "CAM_POSE_CV2 = np.linalg.inv(World2Cam)\n",
    "cam_pose = CAM_POSE_CV2\n",
    "\n",
    "def in_camera_view(renderer, known_id, pose):\n",
    "    \"\"\" Check if pose point is in camera view \"\"\"\n",
    "    # pose is assumed to be in camera frame\n",
    "    return jnp.any(b.RENDERER.intrinsics.far != jnp.unique(renderer.render(pose[None,...], jnp.array([known_id]))[...,2]))\n",
    "\n",
    "@jax.jit\n",
    "def splice_image(rendered_object_image, obs_image_complement):\n",
    "    keep_masks = jnp.logical_or(\n",
    "        (rendered_object_image[...,2] <= obs_image_complement[..., 2]) * \n",
    "        rendered_object_image[...,2] > 0.0\n",
    "        ,\n",
    "        (obs_image_complement[...,2] == 0)\n",
    "    )[...,None]\n",
    "    rendered_images = keep_masks * rendered_object_image + (1.0 - keep_masks) * obs_image_complement\n",
    "    return rendered_images\n",
    "\n",
    "@jax.jit\n",
    "def splice_image_new(rendered_object_image, obs_image_complement, far=150.0):\n",
    "    keep_masks = jnp.logical_or(\n",
    "        jnp.logical_and((rendered_object_image[...,2] <= obs_image_complement[..., 2]) * \n",
    "        rendered_object_image[...,2] > 0.0, (obs_image_complement[...,2] >= far))\n",
    "        ,\n",
    "        (obs_image_complement[...,2] == 0)\n",
    "    )[...,None]\n",
    "    rendered_images = keep_masks * rendered_object_image + (1.0 - keep_masks) * obs_image_complement\n",
    "    return rendered_images\n",
    "\n",
    "splice_image_vmap = jax.vmap(splice_image, in_axes = (0,None))\n",
    "splice_image_double_vmap = jax.vmap(splice_image, in_axes = (0,None))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "POSSIBLE FAILURE CASES:\n",
    "1) The object moves so fast that it has nothing to do with the boundary\n",
    "2) Min dist is not set right, either too small and the obejct misses it OR too large and other objects get counted\n",
    "3) NOT A BUG but we may have to improve the quality of the object formation\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "BUGS IDENTIFIED:\n",
    "\n",
    "Object masking goes wrong in gravity scenes with that stupid pole entering the top ---> need to mae sure this is not \n",
    "in the mask\n",
    "\n",
    "OBJECT MASKING is wrong for frames where object is entering from the top\n",
    "\"\"\"\n",
    "\n",
    "def preprocess_mcs_physics_scene(observations, MIN_DIST_THRESH = 0.6, scale = 0.1):\n",
    "    # preprocess object information before running it through model by using the gt_images\n",
    "    T = len(observations)\n",
    "    review_stack = []\n",
    "    init_queue = []\n",
    "    review_id = 0\n",
    "    registered_objects = []\n",
    "    gt_images = []\n",
    "    gt_images_bg = []\n",
    "    gt_images_obj = []\n",
    "    # Rule, for first frame, process any object as object model\n",
    "    # Afterwards, everything must come from the edges\n",
    "\n",
    "    get_distance = lambda x,y : np.linalg.norm(x[:3,3]-y[:3,3])\n",
    "    print(\"Extracting Meshes\")\n",
    "    obj_pixels = []\n",
    "\n",
    "    poses = [[] for _ in range(T)]\n",
    "\n",
    "    for t in tqdm(range(T)):\n",
    "    # for t in range(T):\n",
    "        gt_image, depth, seg, rgb, intrinsics, cam_pose = observations_to_data_by_frame(observations, t, scale = 1)\n",
    "        gt_image = np.asarray(gt_image)\n",
    "        gt_images.append(gt_image)\n",
    "        # print(\"t = \",t)\n",
    "        seg_ids = np.unique(seg)\n",
    "        print(t)\n",
    "        obj_ids_fixed_shape, obj_mask = get_object_mask(gt_image, seg)\n",
    "        # remove all the -1 indices\n",
    "        obj_ids = np.delete(np.sort(np.unique(obj_ids_fixed_shape)),0) # This will not be jittable\n",
    "        # print(obj_ids)\n",
    "        depth_bg = depth * (1.0 - obj_mask) + intrinsics.far * (obj_mask)\n",
    "        depth_obj = depth * (obj_mask) + intrinsics.far * (1.0 - obj_mask)\n",
    "        gt_images_bg.append(np.asarray(b.t3d.unproject_depth(depth_bg, intrinsics)))\n",
    "        gt_images_obj.append(np.asarray(b.t3d.unproject_depth(depth_obj, intrinsics)))\n",
    "        obj_pixel_ct = 0\n",
    "\n",
    "        for obj_id in obj_ids:\n",
    "\n",
    "            num_pixels = np.sum(seg == obj_id)\n",
    "            obj_pixel_ct += num_pixels\n",
    "            point_cloud_segment = gt_image[seg == obj_id]\n",
    "            dims, pose = b.utils.aabb(point_cloud_segment)\n",
    "            poses[t].append(pose)\n",
    "            rows, cols = np.where(seg == obj_id)\n",
    "            distance_to_edge_1 = min(np.abs(rows - 0).min(), np.abs(rows - intrinsics.height + 1).min())\n",
    "            distance_to_edge_2 = min(np.abs(cols - 0).min(), np.abs(cols - intrinsics.width + 1).min())\n",
    "            # print(distance_to_edge_1, distance_to_edge_2)\n",
    "\n",
    "            if t == 0:\n",
    "                init_object_model = True\n",
    "                init_object_model_metadata = {\n",
    "                    't_init' : t,\n",
    "                    'pose' : pose,\n",
    "                    't_full' : t,\n",
    "                    'full_pose' : pose,\n",
    "                    'num_pixels' : num_pixels,\n",
    "                    'mask' : seg == obj_id\n",
    "                }\n",
    "                # init_object_model = False\n",
    "            else:\n",
    "                init_object_model = False\n",
    "\n",
    "\n",
    "            if distance_to_edge_1 == 0 or distance_to_edge_2 == 0:\n",
    "                # check to ensure it is not any object in the review stack or in the init queue\n",
    "                new_object = True\n",
    "                if len(review_stack) > 0:\n",
    "                    # check review stack first\n",
    "                    distances_rs = [get_distance(pose,r['updating_pose']) for r in review_stack]\n",
    "                    min_dist = np.min(distances_rs)\n",
    "                    if min_dist < MIN_DIST_THRESH:\n",
    "                        new_object = False\n",
    "                if len(init_queue) > 0:\n",
    "                    # chec init queue next\n",
    "                    distances_iq = [get_distance(pose,i['updating_pose']) for i in init_queue]\n",
    "                    min_dist = np.min(distances_iq)\n",
    "                    init_queue_idx = distances_iq.index(min_dist)\n",
    "                    if min_dist < MIN_DIST_THRESH:\n",
    "                        new_object = False\n",
    "                if new_object:\n",
    "                    # Then this is a new object at the boundary not currently accounted for\n",
    "                    #this means that object is either leaving or entering a scene (at the boundary)\n",
    "                    review_id += 1\n",
    "                    print(\"Adding review\")\n",
    "                    review_stack.append(\n",
    "                        {\n",
    "                            'id' : review_id,\n",
    "                            'num_pixels' : num_pixels,\n",
    "                            't_init' : t,\n",
    "                            'distance_to_edge_1' : distance_to_edge_1,\n",
    "                            'distance_to_edge_2' : distance_to_edge_2,\n",
    "                            'updating_pose' : pose,\n",
    "                            'init_pose' : pose\n",
    "                        }\n",
    "                    )\n",
    "            if len(review_stack) > 0:\n",
    "                # find which object under review is the closest\n",
    "                distances_rs = [get_distance(pose,r['updating_pose']) for r in review_stack if r['t_init'] == t - 1]\n",
    "\n",
    "                if len(distances_rs) > 0:\n",
    "                    min_dist = np.min(distances_rs)\n",
    "                    review_stack_idx = distances_rs.index(min_dist)\n",
    "                    if min_dist < MIN_DIST_THRESH:\n",
    "                        # evaluate if object is moving away or not\n",
    "                        if num_pixels > review_stack[review_stack_idx]['num_pixels'] or (not (distance_to_edge_1 == 0 or distance_to_edge_2 == 0)):\n",
    "                            # review passed!\n",
    "                            # TODO PASS REVIEW\n",
    "                            init_queue.append(review_stack[review_stack_idx])\n",
    "                            print(\"Review passed, added to init queue\")\n",
    "                        else:\n",
    "                            print(\"Review failed\")\n",
    "                        del review_stack[review_stack_idx]                 \n",
    "                    else:\n",
    "                        # Then this object must not be related to the reviewed object\n",
    "                        pass\n",
    "                else:\n",
    "                    # Then all objects in stack were made in this time step and this object can move on\n",
    "                    pass\n",
    "\n",
    "            if len(init_queue) > 0:\n",
    "                distances_iq = [get_distance(pose,i['updating_pose']) for i in init_queue]\n",
    "                min_dist = np.min(distances_iq)\n",
    "                init_queue_idx = distances_iq.index(min_dist)\n",
    "                if min_dist < MIN_DIST_THRESH:\n",
    "                    if not (distance_to_edge_1 == 0 or distance_to_edge_2 == 0):\n",
    "                        # object is now ready to be initialized\n",
    "                        # print(\"Obj init\")\n",
    "                        init_object_model = True\n",
    "                        init_object_model_metadata = {\n",
    "                            't_init' : init_queue[init_queue_idx]['t_init'],\n",
    "                            'pose' : init_queue[init_queue_idx]['init_pose'],  # TODO A MORE ACCURATE ESTIMATION OF INIT POSE\n",
    "                            'full_pose' : pose,\n",
    "                            't_full' : t,\n",
    "                            'num_pixels': num_pixels\n",
    "                        }\n",
    "                        del init_queue[init_queue_idx]\n",
    "                    else:\n",
    "                        # this must be the object but it is still at the boundary, update the pose\n",
    "                        init_queue[init_queue_idx]['updating_pose'] = pose \n",
    "                else:\n",
    "                    # unrelated object\n",
    "                    pass\n",
    "\n",
    "\n",
    "            if init_object_model:\n",
    "                # This part makes the mesh\n",
    "                resolution = 0.01\n",
    "                voxelized = np.rint(point_cloud_segment / resolution).astype(np.int32)\n",
    "                min_z = voxelized[:,2].min()\n",
    "                depth_val = voxelized[:,2].max() - voxelized[:,2].min()\n",
    "\n",
    "                front_face = voxelized[voxelized[:,2] <= min_z+20, :]\n",
    "                slices = [front_face]\n",
    "                for i in range(depth_val):\n",
    "                    slices.append(front_face + np.array([0.0, 0.0, i]))\n",
    "                full_shape = np.vstack(slices) * resolution\n",
    "\n",
    "                dims, pose = b.utils.aabb(full_shape)\n",
    "                # print(\"before making mesh object\", get_gpu_mem())\n",
    "\n",
    "                mesh = b.utils.make_marching_cubes_mesh_from_point_cloud(\n",
    "                    b.t3d.apply_transform(full_shape, b.t3d.inverse_pose(pose)),\n",
    "                    0.075\n",
    "                )\n",
    "                # print(\"before adding\", get_gpu_mem())\n",
    "                # renderer.add_mesh(mesh)\n",
    "                \n",
    "                init_object_model_metadata['mesh'] = mesh\n",
    "                registered_objects.append(init_object_model_metadata)\n",
    "                print(\"Adding new mesh for t = {}\",init_object_model_metadata['t_init'])\n",
    "        # Ensure the every review in the review stack has the same time step as the current review\n",
    "        del_idxs = []\n",
    "        for i in list(reversed(range(len(review_stack)))):\n",
    "            if review_stack[i]['t_init'] < t:\n",
    "                print(\"Review Stack not resolved, object may have left view, deleting review\")\n",
    "                del review_stack[i]\n",
    "\n",
    "        if len(review_stack) > 0 and (not np.all([r['t_init'] == t for r in review_stack])):\n",
    "            print(\"REVIEW STACK HAS NOT BEEN FULLY RESOLVED, LOGIC ERROR\")\n",
    "\n",
    "        obj_pixels.append(obj_pixel_ct)\n",
    "\n",
    "    gt_images = np.stack(gt_images)\n",
    "    gt_images_bg = np.stack(gt_images_bg)\n",
    "    gt_images_obj = np.stack(gt_images_obj)\n",
    "\n",
    "    # now extract the data at low resolution\n",
    "    print(\"Extracting downsampled data\")\n",
    "    gt_images_downsampled, _, _, _, intrinsics_downsampled = observations_to_data(observations,scale = scale)\n",
    "    # get new height and width\n",
    "    new_h = intrinsics_downsampled.height\n",
    "    new_w = intrinsics_downsampled.width\n",
    "    # resize the depths\n",
    "    depths_bg = [jax.image.resize(x[...,2], (new_h, new_w), 'nearest') for x in gt_images_bg]\n",
    "    depths_obj = [jax.image.resize(x[...,2], (new_h, new_w), 'nearest') for x in gt_images_obj]\n",
    "    # get new point clouds based on new intrisics\n",
    "    gt_images_bg_downsampled = jnp.stack([b.t3d.unproject_depth(x, intrinsics_downsampled) for x in depths_bg])\n",
    "    gt_images_obj_downsampled = jnp.stack([b.t3d.unproject_depth(x, intrinsics_downsampled) for x in depths_obj])\n",
    "\n",
    "    # hack to determine gravity scene\n",
    "    is_gravity = len(init_queue) > 0\n",
    "\n",
    "    return (gt_images_downsampled,gt_images_bg_downsampled,gt_images_obj_downsampled,intrinsics_downsampled),(gt_images, gt_images_bg, gt_images_obj,intrinsics), registered_objects, obj_pixels, is_gravity, poses, cam_pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>scene_name = <span style=\"color: #808000; text-decoration-color: #808000\">'passive_physics_validation_object_permanence_0001_01'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 # with open(f\"/home/arijitdasgupta/bayes3d/scripts/experiments/intphys/mcs/pickled_data/</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 #     preprocessed_data = pickle.load(file)</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 8 observations = load_observations_npz(scene_name)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>preprocessed_data = preprocess_mcs_physics_scene(observations, MIN_DIST_THRESH=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.6</span>, scal    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>(gt_images, gt_images_bg, gt_images_obj, intrinsics),\\                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span>(gt_images_orig, gt_images_bg_orig, gt_images_obj_orig, intrinsics_orig),\\                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;lambda&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">27</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 24 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.intrinsics = intrinsics                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 25 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.segmentation  = segmentation                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 26 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 27 load_observations_npz = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span> x : np.load(<span style=\"color: #808000; text-decoration-color: #808000\">'val7_physics_npzs'</span> + <span style=\"color: #808000; text-decoration-color: #808000\">\"/{}.npz\"</span>.format(x),all   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 28 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 29 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">observations_to_data_by_frame</span>(observations, frame_idx, scale = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.5</span>):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 30 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>intrinsics_data = observations[frame_idx].intrinsics                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/ubuntu/miniconda3/envs/bayes3d/lib/python3.9/site-packages/numpy/lib/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">npyio.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">427</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 424 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>fid = file                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 425 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>own_fid = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 426 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 427 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>fid = stack.enter_context(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">open</span>(os_fspath(file), <span style=\"color: #808000; text-decoration-color: #808000\">\"rb\"</span>))                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 428 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>own_fid = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 429 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 430 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Code to distinguish from NumPy binary files and pickles.</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileNotFoundError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> No such file or directory: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'val7_physics_npzs/passive_physics_validation_object_permanence_0001_01.npz'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m8\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0mscene_name = \u001b[33m'\u001b[0m\u001b[33mpassive_physics_validation_object_permanence_0001_01\u001b[0m\u001b[33m'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m# with open(f\"/home/arijitdasgupta/bayes3d/scripts/experiments/intphys/mcs/pickled_data/\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m#     preprocessed_data = pickle.load(file)\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 8 observations = load_observations_npz(scene_name)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0mpreprocessed_data = preprocess_mcs_physics_scene(observations, MIN_DIST_THRESH=\u001b[94m0.6\u001b[0m, scal    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m(gt_images, gt_images_bg, gt_images_obj, intrinsics),\\                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m(gt_images_orig, gt_images_bg_orig, gt_images_obj_orig, intrinsics_orig),\\                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<lambda>\u001b[0m:\u001b[94m27\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 24 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.intrinsics = intrinsics                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 25 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.segmentation  = segmentation                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 26 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 27 load_observations_npz = \u001b[94mlambda\u001b[0m x : np.load(\u001b[33m'\u001b[0m\u001b[33mval7_physics_npzs\u001b[0m\u001b[33m'\u001b[0m + \u001b[33m\"\u001b[0m\u001b[33m/\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m.npz\u001b[0m\u001b[33m\"\u001b[0m.format(x),all   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 28 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 29 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mobservations_to_data_by_frame\u001b[0m(observations, frame_idx, scale = \u001b[94m0.5\u001b[0m):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 30 \u001b[0m\u001b[2m│   \u001b[0mintrinsics_data = observations[frame_idx].intrinsics                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/ubuntu/miniconda3/envs/bayes3d/lib/python3.9/site-packages/numpy/lib/\u001b[0m\u001b[1;33mnpyio.py\u001b[0m:\u001b[94m427\u001b[0m in \u001b[92mload\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 424 \u001b[0m\u001b[2m│   │   │   \u001b[0mfid = file                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 425 \u001b[0m\u001b[2m│   │   │   \u001b[0mown_fid = \u001b[94mFalse\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 426 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 427 \u001b[2m│   │   │   \u001b[0mfid = stack.enter_context(\u001b[96mopen\u001b[0m(os_fspath(file), \u001b[33m\"\u001b[0m\u001b[33mrb\u001b[0m\u001b[33m\"\u001b[0m))                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 428 \u001b[0m\u001b[2m│   │   │   \u001b[0mown_fid = \u001b[94mTrue\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 429 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 430 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Code to distinguish from NumPy binary files and pickles.\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \n",
       "\u001b[32m'val7_physics_npzs/passive_physics_validation_object_permanence_0001_01.npz'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading and preprocessing all data and renderer\n",
    "SCALE = 0.2\n",
    "cam_pose = CAM_POSE_CV2\n",
    "inverse_cam_pose = jnp.linalg.inv(CAM_POSE_CV2)\n",
    "scene_name = 'passive_physics_validation_object_permanence_0001_01'\n",
    "# with open(f\"/home/arijitdasgupta/bayes3d/scripts/experiments/intphys/mcs/pickled_data/{scene_name}.pkl\", 'rb') as file:\n",
    "#     preprocessed_data = pickle.load(file)\n",
    "observations = load_observations_npz(scene_name)\n",
    "preprocessed_data = preprocess_mcs_physics_scene(observations, MIN_DIST_THRESH=0.6, scale=SCALE)\n",
    "(gt_images, gt_images_bg, gt_images_obj, intrinsics),\\\n",
    "(gt_images_orig, gt_images_bg_orig, gt_images_obj_orig, intrinsics_orig),\\\n",
    "registered_objects, obj_pixels, is_gravity, poses = preprocessed_data\n",
    "\n",
    "# get obj indices padded\n",
    "all_obj_indices = [np.argwhere(gt_images_obj[i,...,2] != intrinsics.far) for i in range(gt_images.shape[0])]\n",
    "max_rows = max(obj_indices.shape[0] for obj_indices in all_obj_indices)\n",
    "def pad_array(array, max_rows):\n",
    "    padding = ((0, max_rows - array.shape[0]), (0, 0))  # Pad rows, not columns\n",
    "    return jnp.pad(array, padding, constant_values=-1)\n",
    "\n",
    "padded_all_obj_indices = jnp.stack([pad_array(array, max_rows) for array in all_obj_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video([b.get_depth_image(gt_images_bg_orig[i,...,2]) for i in range(len)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(poses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gravity_scene_plausible(poses, gt_images_obj_orig, gt_images_bg_orig, intrinsics, registered_objects):\n",
    "\n",
    "    # account for case where support is identified as an object\n",
    "    max_poses_detected = 0\n",
    "    for i in range(len(poses)):\n",
    "        if len(poses[i]) > max_poses_detected:\n",
    "            max_poses_detected = len(poses[i])\n",
    "    new_poses = [[] for _ in range(len(poses))]\n",
    "    if max_poses_detected > 2:\n",
    "        support_pose = poses[0][0]\n",
    "        for i in range(len(poses)):\n",
    "            for j in range(len(poses[i])):\n",
    "                diff = np.linalg.norm(support_pose[:3,3] - poses[i][j][:3,3])\n",
    "                if diff > 0.01:\n",
    "                    new_poses[i].append(poses[i][j])\n",
    "\n",
    "        poses = new_poses\n",
    "\n",
    "    idx = 0\n",
    "    while len(poses[idx]) < 2:\n",
    "        idx += 1\n",
    "    while len(poses[idx]) > 1:\n",
    "        idx += 1\n",
    "\n",
    "    first_checkpt = idx\n",
    "\n",
    "    while len(poses[idx]) < 2:\n",
    "        diff = np.linalg.norm(poses[idx+1][0][:3,3] - poses[idx][0][:3,3])\n",
    "        if diff == 0.0:\n",
    "            break\n",
    "        idx+=1\n",
    "\n",
    "    second_checkpt = idx\n",
    "\n",
    "    ref_pose = poses[idx][0]\n",
    "    ref_depth_obj = gt_images_obj_orig[idx,...,2]\n",
    "    ref_depth_bg = gt_images_bg_orig[idx,...,2]\n",
    "\n",
    "    if max_poses_detected > 2:\n",
    "        ref_depth_bg  = np.where(registered_objects[0]['mask'], ref_depth_obj, ref_depth_bg)\n",
    "        ref_depth_obj = np.where(registered_objects[0]['mask'], intrinsics.far, ref_depth_obj)\n",
    "\n",
    "    obj_indices = np.argwhere(ref_depth_obj != intrinsics.far)\n",
    "    bottom_i = np.max(obj_indices[:,0])\n",
    "\n",
    "    base_pixel_offset = 20\n",
    "    base_depth_delta_thresh = 1\n",
    "    line = ref_depth_bg[bottom_i+base_pixel_offset]\n",
    "    base_j_min = None\n",
    "    base_j_max = None\n",
    "    on_support = False\n",
    "    for j in range(len(line)-1):\n",
    "        if not on_support and line[j+1] < line[j] - base_depth_delta_thresh:\n",
    "            base_j_min = j\n",
    "            on_support = True\n",
    "        if on_support and line[j+1] > line[j] + base_depth_delta_thresh:\n",
    "            base_j_max = j\n",
    "            break\n",
    "        if j == len(line) - 2:\n",
    "            print(\"Error: There is no base for support\")\n",
    "            return True, [True for _ in range(len(poses))], 1e+20\n",
    "        \n",
    "    pixels_stable = np.sum(np.logical_and(obj_indices[:,1] <= base_j_max , obj_indices[:,1] >= base_j_min))\n",
    "    pixels_unstable = np.sum(np.logical_or(obj_indices[:,1] > base_j_max , obj_indices[:,1] < base_j_min))\n",
    "    stable = pixels_stable >= pixels_unstable\n",
    "    ref_height = (cam_pose @ ref_pose)[2,3]\n",
    "    end_height = (cam_pose @ poses[-1][0])[2,3]\n",
    "    # fell = ref_height > end_height + 0.2\n",
    "    fell = np.linalg.norm(ref_pose[:3,3] - poses[-1][0][:3,3]) > 0.1\n",
    "    perc = 100*(np.abs(pixels_unstable - pixels_stable)/(pixels_stable+pixels_unstable))\n",
    "\n",
    "    if perc < 5: # any outcome should be plausible\n",
    "        return True, [True for _ in range(len(poses))], 1e+20\n",
    "\n",
    "    t_violation = 1e+20\n",
    "    if stable and fell:\n",
    "        plausible = False\n",
    "        t_violation = second_checkpt\n",
    "    elif not stable and not fell:\n",
    "        plausible = False\n",
    "        t_violation = first_checkpt\n",
    "    else:\n",
    "        plausible = True\n",
    "\n",
    "    plausibility_list = []\n",
    "    for t in range(len(poses)):\n",
    "        if t >= t_violation:\n",
    "            plausibility_list.append(False)\n",
    "        else:\n",
    "            plausibility_list.append(True)\n",
    "\n",
    "            \n",
    "    return plausible, plausibility_list, t_violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plausible, plausibility_list, _  = gravity_scene_plausible(poses, gt_images_obj_orig, gt_images_bg_orig, intrinsics_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plausible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_depth_bg = gt_images_bg_orig[34,...,2]\n",
    "ref_depth_obj = gt_images_obj_orig[34,...,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = np.where(registered_objects[0]['mask'], ref_depth_obj, ref_depth_bg)\n",
    "test2 = np.where(registered_objects[0]['mask'], intrinsics.far, ref_depth_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test2[registered_objects[0]['mask']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.setup_renderer(intrinsics, num_layers= 1024)\n",
    "for i,registered_obj in enumerate(registered_objects):\n",
    "    b.RENDERER.add_mesh(registered_obj['mesh'])\n",
    "    # f_p = registered_objects[i][\"full_pose\"]\n",
    "    # registered_objects[i][\"full_pose\"] = f_p.at[2,3].set(f_p[2,3] + 0.5*b.RENDERER.model_box_dims[i][2])\n",
    "if len(registered_objects) == 0:\n",
    "    t_start = gt_images.shape[0]-100\n",
    "    registered_objects.append({'t_init' : gt_images.shape[0]-100,\n",
    "                            'pose' : jnp.eye(4).at[:3,3].set([0,0,1e+5]),\n",
    "                            'full_pose' : jnp.eye(4).at[:3,3].set([0,0,1e+5]),\n",
    "                            't_full' : gt_images.shape[0]-100})\n",
    "    b.RENDERER.add_mesh_from_file(os.path.join(b.utils.get_assets_dir(),\"sample_objs/cube.obj\"), scaling_factor = 0.1)\n",
    "else:\n",
    "    t_start = np.min([x[\"t_full\"] for x in registered_objects])\n",
    "# video_from_rendered(gt_images, scale = int(1/SCALE), framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model time!\n",
    "\n",
    "def get_height_bounds(i, world_pose):\n",
    "    # Half dimensions to get the corner points relative to the center\n",
    "    rotation_matrix = world_pose[:3,:3]\n",
    "    center = world_pose[:3,3]\n",
    "    dimensions = b.RENDERER.model_box_dims[i]\n",
    "    half_dims = dimensions / 2\n",
    "\n",
    "    # Local corner points of the box in its local coordinate system\n",
    "    local_corners = jnp.array([\n",
    "        [-half_dims[0], -half_dims[1], -half_dims[2]],  # Lower rear left corner\n",
    "        [ half_dims[0], -half_dims[1], -half_dims[2]],  # Lower rear right corner\n",
    "        [-half_dims[0],  half_dims[1], -half_dims[2]],  # Lower front left corner\n",
    "        [ half_dims[0],  half_dims[1], -half_dims[2]],  # Lower front right corner\n",
    "        [-half_dims[0], -half_dims[1],  half_dims[2]],  # Upper rear left corner\n",
    "        [ half_dims[0], -half_dims[1],  half_dims[2]],  # Upper rear right corner\n",
    "        [-half_dims[0],  half_dims[1],  half_dims[2]],  # Upper front left corner\n",
    "        [ half_dims[0],  half_dims[1],  half_dims[2]]   # Upper front right corner\n",
    "    ])\n",
    "\n",
    "    # Apply rotation to each corner point\n",
    "    global_corners = jnp.stack([center + rotation_matrix @ corner for corner in local_corners])\n",
    "\n",
    "    # Find the bottom-most point\n",
    "    bottom_most_point_z = jnp.min(global_corners[:,2])\n",
    "    top_most_point_z = jnp.max(global_corners[:,2])\n",
    "    # distance from centre of bbox to bottom of bbox\n",
    "    center_to_bottom_dist = center[2] - bottom_most_point_z\n",
    "    return bottom_most_point_z,top_most_point_z, center_to_bottom_dist\n",
    "\n",
    "def get_translation_direction(all_poses, t_full, t):\n",
    "    direction = all_poses[t-1][:3,3] - all_poses[t_full+1][:3,3]\n",
    "    direction = cam_pose[:3,:3] @ direction\n",
    "    direction_xy = direction.at[2].set(0)\n",
    "\n",
    "    normalized_direction_xy = jax.lax.cond(jnp.equal(jnp.linalg.norm(direction_xy), 0),\n",
    "                                         lambda: direction_xy,\n",
    "                                         lambda: direction_xy/jnp.linalg.norm(direction_xy))\n",
    "    return normalized_direction_xy\n",
    "\n",
    "\n",
    "# This model has to be recompiled for different # objects for now this is okay\n",
    "@genjax.gen\n",
    "def physics_stepper(all_poses, t, t_full, i, friction, gravity):\n",
    "    # TODO: SAMPLING FRICTION SCHEME --> can be of a hmm style\n",
    "\n",
    "    #################################################################\n",
    "    # First let us consider timestep t-1\n",
    "    #################################################################\n",
    "    # Step 2: find world pose\n",
    "    pose_prev = all_poses[t-1]\n",
    "    pose_prev_world = cam_pose @ pose_prev\n",
    "\n",
    "    # Step 3: check if we are already on the floor\n",
    "    bottom_z, top_z, center_to_bottom = get_height_bounds(i, pose_prev_world)\n",
    "    # within 20% of the object's height in world frame\n",
    "    already_on_floor = jnp.less_equal(bottom_z,0.2 * (top_z - bottom_z))\n",
    "    \n",
    "    # Step 1: Find world velocity\n",
    "    vel_pose_camera = jnp.linalg.solve(all_poses[t-2], all_poses[t-1])\n",
    "    pre_vel_xyz_world = cam_pose[:3,:3] @ vel_pose_camera[:3,3]\n",
    "    mag_xy = jnp.linalg.norm(pre_vel_xyz_world[:2])\n",
    "    \n",
    "    mag_xy_friction = mag_xy - friction * mag_xy\n",
    "\n",
    "    # mag_xy_friction = jax.lax.cond(\n",
    "    #     jnp.less_equal(jnp.abs(mag_xy_friction),3e-3),\n",
    "    #     lambda:0.0,\n",
    "    #     lambda:mag_xy_friction)\n",
    "    \n",
    "    mag_xy, gravity = jax.lax.cond(already_on_floor,lambda:(mag_xy_friction,gravity),lambda:(mag_xy, gravity))\n",
    "\n",
    "    dir_xy_world = get_translation_direction(all_poses, t_full, t)\n",
    "\n",
    "    # Step 7: Determine mag and gravity\n",
    "\n",
    "    vel_xyz_world = mag_xy * dir_xy_world\n",
    "    # Step 6: apply z axis change\n",
    "    vel_xyz_world = vel_xyz_world.at[2].set(pre_vel_xyz_world[2] - gravity * 1./20)\n",
    "\n",
    "    # Step 5: find peturbed velocity (equal to original norm) with random rotation\n",
    "    perturbed_rot_pose = GaussianVMFPoseUntraced()(jnp.eye(4), *(1e-20, 10000.0))  @ \"perturb\"\n",
    "\n",
    "    vel_xyz_world_perturbed = perturbed_rot_pose[:3,:3] @ vel_xyz_world # without friction\n",
    "\n",
    "    vel_xyz_camera = inverse_cam_pose[:3,:3] @ vel_xyz_world_perturbed\n",
    "\n",
    "    # Step 8: Get velocity update in camera frame\n",
    "    vel = pose_prev.at[:3,3].set(vel_xyz_camera)\n",
    "\n",
    "    # Step 9: Identify next pose\n",
    "    next_pose = pose_prev.at[:3,3].set(pose_prev[:3,3] + vel[:3,3]) # trans only, no rot\n",
    "\n",
    "    # Step 10: Ensure new bottom of object is above floor --> ground collision\n",
    "    next_pose_world = cam_pose @ next_pose\n",
    "    bottom_z,_,center_to_bottom = get_height_bounds(i, next_pose_world)\n",
    "    next_pose = jax.lax.cond(\n",
    "        jnp.less_equal(bottom_z,0),\n",
    "        lambda:inverse_cam_pose @ next_pose_world.at[2,3].set(center_to_bottom),\n",
    "        lambda:next_pose\n",
    "    )\n",
    "\n",
    "    return next_pose\n",
    "\n",
    "def threedp3_likelihood_arijit(\n",
    "    observed_xyz: jnp.ndarray,\n",
    "    rendered_xyz: jnp.ndarray,\n",
    "    variance,\n",
    "    outlier_prob,\n",
    "):\n",
    "    distances = jnp.linalg.norm(observed_xyz - rendered_xyz, axis=-1)\n",
    "    probabilities_per_pixel = (distances < variance/2) / variance\n",
    "    average_probability = 1 * probabilities_per_pixel.mean()\n",
    "    return average_probability\n",
    "\n",
    "threedp3_likelihood_arijit_vmap = jax.vmap(threedp3_likelihood_arijit, in_axes=(None,0,None,None))\n",
    "threedp3_likelihood_arijit_double_vmap = jax.vmap(threedp3_likelihood_arijit, in_axes=(0,0,None,None))\n",
    "\n",
    "def outlier_gaussian(\n",
    "    observed_xyz: jnp.ndarray,\n",
    "    rendered_xyz: jnp.ndarray,\n",
    "    variance,\n",
    "    outlier_prob,\n",
    "):\n",
    "    distances = jnp.linalg.norm(observed_xyz - rendered_xyz, axis=-1)\n",
    "    probabilities_per_pixel = jax.scipy.stats.norm.pdf(\n",
    "        distances,\n",
    "        loc=0.0, \n",
    "        scale=variance\n",
    "    )\n",
    "    average_probability = 0.01 * probabilities_per_pixel.sum()\n",
    "    return average_probability\n",
    "\n",
    "outlier_gaussian_double_vmap = jax.vmap(outlier_gaussian, in_axes=(0,0,None,None))\n",
    "outlier_gaussian_vmap = jax.vmap(outlier_gaussian, in_axes=(None,0,None,None))\n",
    "\n",
    "def outlier_gaussian_per_pixel(\n",
    "    observed_xyz: jnp.ndarray,\n",
    "    rendered_xyz: jnp.ndarray,\n",
    "    variance,\n",
    "    outlier_prob,\n",
    "):\n",
    "    distances = jnp.linalg.norm(observed_xyz - rendered_xyz, axis=-1)\n",
    "    probabilities_per_pixel = jax.scipy.stats.norm.pdf(\n",
    "        distances,\n",
    "        loc=0.0, \n",
    "        scale=variance\n",
    "    )\n",
    "    return 0.01 * probabilities_per_pixel\n",
    "\n",
    "outlier_gaussian_per_pixel_vmap = jax.vmap(outlier_gaussian_per_pixel, in_axes=(None,0,None,None))\n",
    "\n",
    "@dataclass\n",
    "class ImageLikelihoodArijit(ExactDensity):\n",
    "    def sample(self, key, img, variance, outlier_prob):\n",
    "        return img\n",
    "\n",
    "    def logpdf(self, observed_image, latent_image, variance, outlier_prob):\n",
    "        # return threedp3_likelihood_arijit(\n",
    "        #     observed_image, latent_image, variance, outlier_prob,\n",
    "        # )        \n",
    "        return outlier_gaussian(\n",
    "            observed_image, latent_image, variance, outlier_prob,\n",
    "        )\n",
    "    \n",
    "@dataclass\n",
    "class GaussianVMFPoseUntraced(ExactDensity):\n",
    "    def sample(self, key, pose_mean, var, concentration, **kwargs):\n",
    "        return b.distributions.gaussian_vmf(key, pose_mean, var, concentration)\n",
    "\n",
    "    def logpdf(self, pose, pose_mean, var, concentration, **kwargs):\n",
    "        return 0\n",
    "\n",
    "@genjax.gen\n",
    "def mcs_model(prev_state, t_inits, t_fulls, init_poses, full_poses, pose_update_params, variance, outlier_prob):\n",
    "    \"\"\"\n",
    "    Single Object Model HMM\n",
    "    \"\"\"\n",
    "\n",
    "    (_, _, poses, all_poses, friction, t, gravity) = prev_state\n",
    "\n",
    "    # jprint(\"t = {}, f = {}\",t, friction)\n",
    "    num_objects = poses.shape[0]\n",
    "    \n",
    "    # for each object\n",
    "    for i in range(num_objects):        \n",
    "\n",
    "        poses = poses.at[i].set(jax.lax.cond(\n",
    "            jnp.equal(t_fulls[i],t), # full pose at the correct time step\n",
    "            lambda:full_poses[i], \n",
    "            lambda:poses[i]))\n",
    "        \n",
    "        poses = poses.at[i].set(jax.lax.cond(\n",
    "            jnp.equal(t_inits[i],t), # init pose at the correct time step\n",
    "            lambda:init_poses[i], \n",
    "            lambda:poses[i]))\n",
    "\n",
    "        physics_prob = jnp.asarray(jax.lax.cond(jnp.greater_equal(t,t_fulls[i]+2),lambda:1,lambda:0), dtype=int)\n",
    "        physics_pose = physics_stepper(all_poses[:,i,...], t, t_fulls[i], i, friction, gravity) @ f\"physics_{i}\"\n",
    "        final_pose, update_params = jax.lax.cond(physics_prob, lambda:(physics_pose, pose_update_params), lambda:(poses[i], (jnp.array([1e20,1e20,1e20]), 0.)))\n",
    "                \n",
    "        updated_pose = b.gaussian_vmf_pose(final_pose, *update_params)  @ f\"pose_{i}\"\n",
    "        poses = poses.at[i].set(updated_pose)\n",
    "        \n",
    "    all_poses = all_poses.at[t].set(poses)\n",
    "    rendered_image_obj = b.RENDERER.render(\n",
    "        poses, jnp.arange(num_objects))[...,:3]\n",
    "\n",
    "    # NOTE: gt_images_bg is a global variable here as it consumes too much memory for the trace\n",
    "    rendered_image = splice_image(rendered_image_obj, gt_images_bg[t])\n",
    "\n",
    "    sampled_image = ImageLikelihoodArijit()(rendered_image, variance, outlier_prob) @ \"depth\"\n",
    "    # sampled_image = b.old_image_likelihood(rendered_image, 0.1, 0.001,1000,None) @ \"depth\"\n",
    "\n",
    "    return (rendered_image, rendered_image_obj, poses, all_poses, friction, t+1, gravity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_update_v5(key, trace_, pose_grid, enumerator):\n",
    "    num_splits = (pose_grid.shape[0] // 400) + 1\n",
    "    all_weights = jnp.array([])\n",
    "    for split_pose_grid in jnp.array_split(pose_grid, num_splits):\n",
    "        weights = enumerator.enumerate_choices_get_scores(trace_, key, split_pose_grid)\n",
    "        all_weights = jnp.hstack([all_weights, weights])\n",
    "    sampled_idx = all_weights.argmax() # jax.random.categorical(key, weights)\n",
    "    # jprint(\"weights = {}\",all_weights)\n",
    "    # jprint(\"weight mix:{}\",jnp.unique(jnp.sort(all_weights), size = 10))\n",
    "    # jprint(\"idx chosen = {}\",sampled_idx)\n",
    "    return *enumerator.update_choices_with_weight(\n",
    "        trace_, key,\n",
    "        pose_grid[sampled_idx]\n",
    "    ), pose_grid[sampled_idx]\n",
    "\n",
    "\n",
    "pose_update_v5_jit = jax.jit(pose_update_v5, static_argnames=(\"enumerator\",))\n",
    "\n",
    "\n",
    "def c2f_pose_update_v5(key, trace_, reference, gridding_schedule, enumerator, obj_id,):\n",
    "    # for each object (TODO: gibbs sampling)\n",
    "    for i in range(len(gridding_schedule)):\n",
    "        updated_grid = jnp.einsum(\"ij,ajk->aik\", reference, gridding_schedule[i])\n",
    "        # Time to check valid poses that dont intersect with the floor\n",
    "        valid = jnp.logical_not(are_bboxes_intersecting_many_jit(\n",
    "                            (100,100,20),\n",
    "                            b.RENDERER.model_box_dims[obj_id],\n",
    "                            jnp.eye(4).at[:3,3].set([0,0,-10.1]),\n",
    "                            jnp.einsum(\"ij,ajk->aik\",cam_pose,updated_grid)\n",
    "                            ))\n",
    "        # if pose is not valid, use the reference pose\n",
    "        valid_grid = jnp.where(valid[:,None,None], updated_grid, reference[None,...])\n",
    "        weight, trace_, reference = pose_update_v5_jit(key, trace_, valid_grid, enumerator)\n",
    "        # jprint(\"ref position is {}\", reference[:3,3])\n",
    "\n",
    "    return weight, trace_\n",
    "\n",
    "c2f_pose_update_v5_vmap_jit = jax.jit(jax.vmap(c2f_pose_update_v5, in_axes=(0,0,None,None,None)),\n",
    "                                    static_argnames=(\"enumerator\", \"obj_id\"))\n",
    "\n",
    "c2f_pose_update_v5_jit = jax.jit(c2f_pose_update_v5,static_argnames=(\"enumerator\", \"obj_id\"))\n",
    "\n",
    "def make_new_keys(key, N_keys):\n",
    "    key, other_key = jax.random.split(key)\n",
    "    new_keys = jax.random.split(other_key, N_keys)\n",
    "    return key, new_keys\n",
    "\n",
    "def update_choice_map_no_unfold(gt_depths, constant_choices, t):\n",
    "    constant_choices['depth'] = gt_depths[t]\n",
    "    return genjax.choice_map(\n",
    "                constant_choices\n",
    "            )\n",
    "\n",
    "def argdiffs_modelv7(trace):\n",
    "    \"\"\"\n",
    "    Argdiffs specific to mcs_single_obejct model with no unfold\n",
    "    \"\"\"\n",
    "    args = trace.get_args()\n",
    "    argdiffs = (\n",
    "        jtu.tree_map(lambda v: Diff(v, UnknownChange), args[0]),\n",
    "        *jtu.tree_map(lambda v: Diff(v, NoChange), args[1:]),\n",
    "    )\n",
    "    return argdiffs\n",
    "\n",
    "def proposal_choice_map_no_unfold(addresses, args, chm_args):\n",
    "    addr = addresses[0] # custom defined\n",
    "    return genjax.choice_map({\n",
    "                        addr: args[0]\n",
    "            })\n",
    "\n",
    "def resampling_priority_fn(particles, all_padded_idxs, t, outlier_variance=0.1):\n",
    "    rendered = particles.get_retval()[0]\n",
    "    padded_idxs = all_padded_idxs[t]\n",
    "    max_rows, _ = padded_idxs.shape\n",
    "\n",
    "    # Create a mask for valid indices (not padded)\n",
    "    valid_mask = padded_idxs[:, 0] != -1  # Assuming -1 is the padding value\n",
    "\n",
    "    # Use the mask to select valid indices, replace invalid indices with a default valid index (e.g., 0)\n",
    "    valid_row_indices = jnp.where(valid_mask, padded_idxs[:, 0], 0)\n",
    "    valid_col_indices = jnp.where(valid_mask, padded_idxs[:, 1], 0)\n",
    "\n",
    "    # Gather rendered and ground truth values\n",
    "    rendered_values_at_indices = rendered[:, valid_row_indices, valid_col_indices, 2]\n",
    "    gt_values_at_indices = gt_images[t, valid_row_indices, valid_col_indices, 2]\n",
    "\n",
    "    # Compute inliers, using the mask to ignore the contributions of invalid indices\n",
    "    inliers = jnp.where(valid_mask, jnp.abs(rendered_values_at_indices - gt_values_at_indices[None, ...]) < outlier_variance, False)\n",
    "    inliers_per_particle = jnp.sum(inliers, axis=1)\n",
    "\n",
    "    log_probs = jnp.log(inliers_per_particle + 1e-9)  # Add a small constant to avoid log(0)\n",
    "\n",
    "    eff_ss = ess(normalize_weights(log_probs))\n",
    "\n",
    "    return eff_ss, log_probs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_approach_G2(model, gt, gridding_schedules, model_args, init_state, key, t_start, constant_choices, T, addr, n_particles):\n",
    "    \"\"\"\n",
    "    Sequential Importance Sampling on the non-unfolded HMM model\n",
    "    with 3D pose enumeration proposal\n",
    "\n",
    "    WITH JUST ONE PARTICLE\n",
    "    \"\"\"\n",
    "    \n",
    "    num_objects = init_state[2].shape[0]\n",
    "\n",
    "    def get_next_state(particle):\n",
    "        return (None,None,*particle.get_retval()[2:])\n",
    "    get_next_state_vmap = jax.vmap(get_next_state, in_axes = (0,))\n",
    "\n",
    "    # sample friction\n",
    "    key, friction_keys = make_new_keys(key, n_particles)\n",
    "    # frictions = jax.vmap(genjax.normal.sample, in_axes = (0,None,None))(friction_keys,*friction_params)\n",
    "    # frictions = jnp.linspace(-0.03,0.07,n_particles)\n",
    "    qs = jnp.linspace(0.05,0.95,n_particles)\n",
    "    frictions = tfp.distributions.Normal(0.02,0.05).quantile(qs)\n",
    "    # frictions = frictions.at[n_particles-1].set(0.5)\n",
    "    gravities = jnp.linspace(0.5,2,n_particles)\n",
    "    # broadcast init_state to number of particles\n",
    "    init_states = jax.vmap(lambda f,g:(*init_state[:4], f, init_state[4], g), in_axes=(0,0))(frictions, gravities)\n",
    "\n",
    "    # define functions for SIS/SMC\n",
    "    init_fn = jax.jit(jax.vmap(model.importance, in_axes=(0,None,0)))\n",
    "    update_fn = jax.jit(model.update)\n",
    "    proposal_fn = c2f_pose_update_v5_jit\n",
    "\n",
    "    def smc_body(carry, t):\n",
    "        # get new keys\n",
    "        print(\"jit compiling\")\n",
    "        # initialize particle based on last time step\n",
    "        jprint(\"t = {}\",t)\n",
    "        \n",
    "        key, log_weights, states,  = carry\n",
    "        key, importance_keys = make_new_keys(key, n_particles)\n",
    "        key, resample_key = jax.random.split(key)\n",
    "        key, proposal_key = jax.random.split(key)\n",
    "\n",
    "        variance = jax.lax.cond(\n",
    "            jnp.less_equal(t, model_args[1][0] + 2),\n",
    "            lambda: 1 * model_args[5],\n",
    "            lambda: model_args[5]\n",
    "        )\n",
    "\n",
    "        modified_model_args = (*model_args[:5], variance, *model_args[6:])\n",
    "\n",
    "        full_args = jax.vmap(lambda x,y:(x, *y), in_axes=(0,None))(states, modified_model_args)\n",
    "\n",
    "        importance_log_weights, particles = init_fn(importance_keys, update_choice_map_no_unfold(gt,constant_choices, t), full_args)\n",
    "\n",
    "        # propose good poses based on proposal\n",
    "        def proposer(carry, p):\n",
    "            key, idx = carry\n",
    "            proposal_log_weight = 0\n",
    "            # argdiff and enumerator\n",
    "            argdiffs = argdiffs_modelv7(p)\n",
    "            enumerators = [b.make_enumerator([(addr + f'_{i}')], \n",
    "                                        chm_builder = proposal_choice_map_no_unfold,\n",
    "                                        argdiff_f=lambda x: argdiffs\n",
    "                                        ) for i in range(num_objects)] \n",
    "            for obj_id in range(num_objects):\n",
    "                key, new_key = jax.random.split(key)\n",
    "                reference = jax.lax.cond(jnp.equal(t,t_start),\n",
    "                                         lambda:model_args[3][obj_id],\n",
    "                                         lambda:states[2][idx][obj_id])\n",
    "                w, p = proposal_fn(new_key, p, reference, gridding_schedules[obj_id], enumerators[obj_id], obj_id)\n",
    "                proposal_log_weight += w\n",
    "            return (new_key, idx + 1), (proposal_log_weight, p)\n",
    "        _, (proposal_log_weights, particles) = jax.lax.scan(proposer, (proposal_key, 0), particles)\n",
    "\n",
    "        eff_ss, priority_fn_log_probs = resampling_priority_fn(particles, padded_all_obj_indices, t)\n",
    "\n",
    "        # jprint(\"t = {}, ess = {}\", t, eff_ss)\n",
    "\n",
    "        # # Resampling when ess is below threshold\n",
    "        indices = jax.lax.cond(eff_ss <= 0.9*n_particles,\n",
    "                               lambda: jax.random.categorical(resample_key, priority_fn_log_probs, shape=(n_particles,)),\n",
    "                               lambda: jnp.arange(n_particles))\n",
    "        particles = jtu.tree_map(lambda v: v[indices], particles)\n",
    "\n",
    "        # get weights of particles\n",
    "        new_log_weight = log_weights + importance_log_weights\n",
    "        next_states = get_next_state_vmap(particles)\n",
    "\n",
    "        return (key, new_log_weight, next_states), (particles, indices)\n",
    "\n",
    "    (_, final_log_weight, _), (particles, indices) = jax.lax.scan(\n",
    "        smc_body, (key, jnp.zeros(n_particles), init_states), jnp.arange(t_start, T))\n",
    "    rendered = particles.get_retval()[0]\n",
    "    rendered_obj = particles.get_retval()[1]\n",
    "    inferred_poses = particles.get_retval()[2]\n",
    "    print(\"SCAN finished\")\n",
    "    return final_log_weight, rendered, rendered_obj, inferred_poses, particles, indices\n",
    "\n",
    "def reset_renderer():\n",
    "    b.RENDERER = None\n",
    "    b.setup_renderer(intrinsics)\n",
    "    for registered_obj in registered_objects:\n",
    "        b.RENDERER.add_mesh(registered_obj['mesh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumeration grid\n",
    "# TODO: ADAPTIVE GRID SIZING\n",
    "# grid_widths = [1, 0.2,0.04,0.008,0.002,0.0004]\n",
    "# # grid_widths = [0.5, 0.1,0.02]\n",
    "# grid_nums = [(7,7,7),(7,7,7),(7,7,7), (7,7,7), (7,7,7), (7,7,7)]\n",
    "# gridding_schedule_trans = make_schedule_translation_3d(grid_widths, grid_nums)\n",
    "# gridding_schedule_rot = [b.utils.make_rotation_grid_enumeration(10, 15, -jnp.pi/12, jnp.pi/12, jnp.pi/12)]\n",
    "# # gridding_schedule = [gridding_schedule_trans[0], gridding_schedule_trans[1], gridding_schedule_trans[2], gridding_schedule_rot[0]]\n",
    "# gridding_schedule = [gridding_schedule_trans[0], gridding_schedule_trans[1], \n",
    "#                      gridding_schedule_trans[2], gridding_schedule_trans[3],\n",
    "#                      gridding_schedule_trans[4], gridding_schedule_trans[5]]\n",
    "\n",
    "\n",
    "gridding_schedules = []\n",
    "for box_dims in b.RENDERER.model_box_dims:\n",
    "    c2fm1 = 2\n",
    "    c2f0 = 1\n",
    "    c2f1 = 0.35 * c2f0\n",
    "    # c2f1 = 0.7 * c2f0\n",
    "    c2f2 = 0.7 * c2f1\n",
    "    c2f3 = 0.2 * c2f2\n",
    "    c2f4 = 0.2 * c2f3\n",
    "    c2f5 = 0.2 * c2f4\n",
    "    c2f6 = 0.2 * c2f5\n",
    "\n",
    "    c2fs = [c2f0,c2f1,c2f2,c2f3,c2f4]#,c2f5,c2f6] #c2fm1\n",
    "    # c2f0 = 1\n",
    "    # c2f1 = 0.15 * c2f0\n",
    "    # c2f2 = 0.05 * c2f1\n",
    "    # c2f3 = 0.05 * c2f2\n",
    "    # c2fs = [c2f0,c2f1,c2f2,c2f3]\n",
    "\n",
    "    x,y,z = box_dims\n",
    "    grid_widths = [[c2f*x, c2f*y, c2f*z] for c2f in c2fs]\n",
    "\n",
    "    grid_nums = [(13,13,13),(7,7,7),(7,7,7),(7,7,7), (7,7,7)]#,(7,7,7),(7,7,7)]\n",
    "    # grid_nums = [(7,7,7),(5,5,5),(5,5,5), (5,5,5), (5,5,5), (3,3,3), (3,3,3)]\n",
    "    # grid_nums = [(5,5,5),(5,5,5),(5,5,5),(5,5,5), (5,5,5), (5,5,5)]#, (5,5,5), (5,5,5)]\n",
    "    # grid_nums = [(15,15,5), (41,5,5), (41,5,5), (41,5,5)]\n",
    "    gridding_schedule_trans = make_schedule_translation_3d_variable_grid(grid_widths, grid_nums)\n",
    "    gridding_schedules.append(gridding_schedule_trans)\n",
    "\n",
    "# Setup for inference\n",
    "T = gt_images.shape[0]\n",
    "num_registered_objects = len(registered_objects)\n",
    "variance = 0.1\n",
    "INIT_STATE = (\n",
    "        None,\n",
    "        None,\n",
    "        jnp.tile(jnp.eye(4).at[2,3].set(1e+5)[None,...],(num_registered_objects,1,1)),\n",
    "        jnp.zeros((T,num_registered_objects,4,4)),\n",
    "        t_start\n",
    ")\n",
    "MODEL_ARGS = (\n",
    "     jnp.array([r['t_init'] for r in registered_objects]),\n",
    "     jnp.array([r['t_full'] for r in registered_objects]),\n",
    "     jnp.array([r['pose'] for r in registered_objects]),\n",
    "     jnp.array([r['full_pose'] for r in registered_objects]),\n",
    "    #  jnp.array([5e-0, 5e-1]),\n",
    "     (jnp.array([1e-0,1e-0,5e-1]), 5e-1),\n",
    "     variance,\n",
    "     None\n",
    ")\n",
    "CONSTANT_CHOICES = {}\n",
    "\n",
    "key = jax.random.PRNGKey(np.random.randint(0,2332423432))\n",
    "n_particles = 30\n",
    "model = mcs_model\n",
    "\n",
    "start = time.time()\n",
    "lw, rendered, rendered_obj, inferred_poses, trace, indices = inference_approach_G2(model, gt_images, \n",
    "    gridding_schedules, MODEL_ARGS, INIT_STATE, key, t_start, CONSTANT_CHOICES, T, \"pose\", n_particles)\n",
    "print (\"FPS:\", rendered.shape[0] / (time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scs = trace.score\n",
    "rend_ll = trace.project(genjax.select((\"depth\")))\n",
    "phy_ll = trace.project(genjax.select((\"pose_0\")))\n",
    "worst_rend = outlier_gaussian_double_vmap(gt_images[t_start:], gt_images_bg[t_start:], variance,None)\n",
    "\n",
    "w = trace.project(genjax.select(\"depth\"))\n",
    "offst = 3\n",
    "start = t_start +offst\n",
    "gap = w[offst:].max()-w[offst:].min()\n",
    "\n",
    "max_rend_ll = gt_images.shape[1] * gt_images.shape[2]*jax.scipy.stats.norm.pdf(\n",
    "        0.,\n",
    "        loc=0.0, \n",
    "        scale=variance\n",
    "    ) * 0.01\n",
    "\n",
    "rendering_ll_images = []\n",
    "\n",
    "fig, ax = plt.subplots()  # Using subplots to directly access the figure object\n",
    "lines = []\n",
    "for p_id in range(n_particles):\n",
    "    line = ax.plot(np.array([start]),w[offst,p_id], label = f\"Particle {p_id+1}\")[0]\n",
    "    lines.append(line)\n",
    "line = ax.plot(np.array([start]),worst_rend[offst], label = \"Worst\", linestyle = \"--\")[0]\n",
    "lines.append(line)\n",
    "ax.set_xlim([start,T])\n",
    "ax.set_ylim([worst_rend[offst:].min(),max_rend_ll + 0.1*(max_rend_ll - worst_rend[offst:].min())])\n",
    "# ax.set_ylim([w[offst:].min()-0.1*gap,w[offst:].max()+0.1*gap])\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Log Likelihood\")\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "fig.subplots_adjust(right=0.75)\n",
    "fig.canvas.draw()\n",
    "rendering_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "\n",
    "for _ in tqdm(range(0,start)):\n",
    "    rendering_ll_images.append(rendering_ll_img.copy().resize((600,400)))\n",
    "\n",
    "for t in tqdm(range(start,T)):\n",
    "    for p_id in range(n_particles):\n",
    "        lines[p_id].set_data(np.arange(start,t+1),w[:,p_id][offst:offst+t+1-start])\n",
    "    lines[-1].set_data(np.arange(start,t+1),worst_rend[offst:offst+t+1-start])\n",
    "    fig.canvas.draw()\n",
    "    rendering_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "    rendering_ll_images.append(rendering_ll_img.resize((600,400)))\n",
    "    plt.close()\n",
    "\n",
    "w = trace.project(genjax.select(\"pose_0\"))\n",
    "offst = 3\n",
    "start = t_start+offst\n",
    "gap = w[offst:].max()-w[offst:].min()\n",
    "\n",
    "physics_ll_images = []\n",
    "\n",
    "fig, ax = plt.subplots()  # Using subplots to directly access the figure object\n",
    "lines = []\n",
    "for p_id in range(n_particles):\n",
    "    line = ax.plot(np.array([start]),w[offst,p_id], label = f\"Particle {p_id+1}\")[0]\n",
    "    lines.append(line)\n",
    "    \n",
    "ax.set_xlim([start,T]) \n",
    "ax.set_ylim([-4.66,-4.57])\n",
    "# ax.set_ylim([w[offst:].min()-0.1*gap, w[offst:].max()+0.1*gap])\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Log Likelihood\")\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "fig.subplots_adjust(right=0.75)\n",
    "fig.canvas.draw()\n",
    "physics_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "\n",
    "for _ in tqdm(range(0,start)):\n",
    "    physics_ll_images.append(physics_ll_img.copy().resize((600,400)))\n",
    "\n",
    "for t in tqdm(range(start,T)):\n",
    "    for p_id in range(n_particles):\n",
    "        lines[p_id].set_data(np.arange(start,t+1),w[:,p_id][offst:offst+t+1-start])\n",
    "    fig.canvas.draw()\n",
    "    physics_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "    physics_ll_images.append(physics_ll_img.resize((600,400)))\n",
    "    plt.close()\n",
    "\n",
    "dummy_poses = np.tile(jnp.eye(4).at[2,3].set(-1e5)[None,None,None,...], (t_start,n_particles,num_registered_objects,1,1))\n",
    "concat_inferred_poses = np.concatenate([dummy_poses, inferred_poses])\n",
    "\n",
    "p_images = get_particle_images(intrinsics_orig, concat_inferred_poses, T = T)\n",
    "blended_images = [b.overlay_image(p_images[i],b.get_depth_image(gt_images_orig[i][...,2])) for i in range(len(p_images))]\n",
    "images = []\n",
    "for t in tqdm(range(T)):\n",
    "    images.append(b.scale_image(b.multi_panel([\n",
    "                b.get_depth_image(gt_images_orig[t,...,2]),\n",
    "                # b.scale_image(b.get_depth_image(rendered[t,particle_id,...,2]),scale),\n",
    "                blended_images[t],\n",
    "                physics_ll_images[t],\n",
    "                rendering_ll_images[t]\n",
    "                # b.scale_image(b.get_depth_image(rendered_obj[t,particle_id,...,2]),3)\n",
    "                ],labels = ['gt/observed', 'particles',\n",
    "                            \"physics likelihood\", \"rendering likelihood\"]), 0.4))\n",
    "display_video(images, framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = phy_ll[3:]\n",
    "\n",
    "fig, axes = plt.subplots(6, 5, figsize=(15, 12))  # Adjust figsize as needed\n",
    "\n",
    "# Set global min and max for y-axis\n",
    "ymin, ymax = np.min(data), np.max(data)\n",
    "\n",
    "for i in range(30):\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.plot(data[3:, i])\n",
    "    ax.set_ylim([-4.66, -4.57])  # Set the same y-axis limits for all plots\n",
    "    ax.set_title(f\"Plot {i+1}\")\n",
    "    # ax.set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "data = rend_ll[3:]\n",
    "\n",
    "fig, axes = plt.subplots(6, 5, figsize=(15, 12))  # Adjust figsize as needed\n",
    "\n",
    "# Set global min and max for y-axis\n",
    "ymin, ymax = np.min(data), np.max(data)\n",
    "\n",
    "for i in range(30):\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.plot(data[3:, i])\n",
    "    ax.set_ylim([94.75, 95.75])  # Set the same y-axis limits for all plots\n",
    "    ax.set_title(f\"Plot {i+1}\")\n",
    "    # ax.set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"rend_ll\":rend_ll, \"phy_ll\":phy_ll, \"all_obj_indices\" :all_obj_indices,\n",
    "        \"inferred_poses\" : concat_inferred_poses,\n",
    "        \"resampled_indices\" : indices, \"heuristic_poses\" : poses, \"worst_rend\":worst_rend,\n",
    "        \"intrinsics\" : intrinsics, \"variance\" : variance}\n",
    "\n",
    "plausible, t_violation, plausibility_list, _ = determine_plausibility(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = {}\n",
    "for i,plausibility in enumerate(plausibility_list):\n",
    "    report[i+1] = {\n",
    "        \"rating\": int(plausibility),\n",
    "        \"score\" : float(plausibility),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = {\"rating\": int(plausible), \"score\" : float(plausible), \"report\" : report }\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particles = data['resampled_indices'].shape[1]\n",
    "resample_bools = np.all(data['resampled_indices'] == np.arange(n_particles), axis = 1)\n",
    "base_indices = np.arange(n_particles)\n",
    "for i in range(data['resampled_indices'].shape[0]):\n",
    "    base_indices = base_indices[data['resampled_indices'][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"phy_ll\"][t_violation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splice_image_double_vmap = jax.vmap(splice_image, in_axes = (0,0))\n",
    "rend_scores = []\n",
    "for p_id in tqdm(range(n_particles)):\n",
    "    # new_rendered_unspliced = b.RENDERER.render_many(inferred_poses[:,p_id,...], jnp.arange(num_registered_objects))[...,:3]\n",
    "    # new_rendered = splice_image_double_vmap(new_rendered_unspliced, gt_images_bg[t_start:])\n",
    "    scores = outlier_gaussian_double_vmap(gt_images[t_start:], gt_images_bg[t_start:], 0.1,None)\n",
    "    rend_scores.append(np.array(scores))\n",
    "rend_scores = np.stack(rend_scores).T\n",
    "rend_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_rend = outlier_gaussian_double_vmap(gt_images[t_start:], gt_images_bg[t_start:], 0.1,None)\n",
    "min_rend = worst_rend.min()\n",
    "for i in range(n_particles):\n",
    "    plt.plot(rend_ll[3:,i])\n",
    "plt.plot(worst_rend[3:], linestyle=\"--\")\n",
    "plt.ylim([min_rend, 95.75]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ registered_objects[0]['full_pose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ concat_inferred_poses[95,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.RENDERER.model_box_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnge = range(t_start,t_start+40)\n",
    "\n",
    "for p_id in range(n_particles):\n",
    "    if p_id > 28:\n",
    "        xs = np.array([(cam_pose @ concat_inferred_poses[i,p_id,0])[0,3] for i in rnge])\n",
    "        ys = np.array([(cam_pose @ concat_inferred_poses[i,p_id,0])[1,3] for i in rnge])\n",
    "        plt.plot(xs,ys, marker = 'o')\n",
    "        # plt.scatter(xs[-1],ys[-1])\n",
    "\n",
    "nxs = []\n",
    "nys = []\n",
    "for i in rnge:\n",
    "    if len(poses[i]) > 0:\n",
    "        nxs.append((cam_pose @ poses[i][0])[0,3])\n",
    "        nys.append((cam_pose @ poses[i][0])[1,3])\n",
    "# xs = [(cam_pose @ poses[i][0])[0,3] for i in range(134,141)]\n",
    "# ys = [(cam_pose @ poses[i][0])[1,3] for i in range(134,141)]\n",
    "plt.plot(nxs,nys, marker = 'x')\n",
    "# plt.ylim(ys.min(),ys.max())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.RENDERER.model_box_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [(cam_pose @ poses[i][0])[0,3] for i in range(134,141)]\n",
    "ys = [(cam_pose @ poses[i][0])[1,3] for i in range(134,141)]\n",
    "plt.plot(xs,ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = 204\n",
    "display(rend_ll[tt-134])\n",
    "display(phy_ll[tt-134])\n",
    "display(scs[tt-134])\n",
    "display(rend_ll[tt-134] + phy_ll[tt-134])\n",
    "concat_inferred_poses[tt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.scale_image(b.get_depth_image(imm[...,2]),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.overlay_image(b.scale_image(b.get_depth_image(imm_unspliced[...,2]),5), b.scale_image(b.get_depth_image(imm[...,2]),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ concat_inferred_poses[134][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ concat_inferred_poses[141][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ debug_physics_stepper(jnp.array(concat_inferred_poses[:,0,0,...]), 142, 134, 0, -0.03, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threedp3_likelihood_arijit(gt_images_bg[-1],gt_images[-1],0.1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_images[-1,all_obj_indices[-1][:,0],all_obj_indices[-1][:,1],2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered[-1,0,all_obj_indices[-1][:,0],all_obj_indices[-1][:,1],2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obj_indices[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered[-1,0][25:31,30:40,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_images[-1][25:31,30:40,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.linalg.norm(gt_images[-1][20:35,20:50,:] - rendered[-1,0][20:35,20:50,:], axis=-1) < 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.sum(jnp.linalg.norm(gt_images[123] - gt_images_bg[123], axis=-1) < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def splice_image(rendered_object_image, obs_image_complement, far=150.0):\n",
    "    keep_masks = jnp.logical_or(\n",
    "        jnp.logical_and((rendered_object_image[...,2] <= obs_image_complement[..., 2]) * \n",
    "        rendered_object_image[...,2] > 0.0, (obs_image_complement[...,2] >= far))\n",
    "        ,\n",
    "        (obs_image_complement[...,2] == 0)\n",
    "    )[...,None]\n",
    "    rendered_images = keep_masks * rendered_object_image + (1.0 - keep_masks) * obs_image_complement\n",
    "    return rendered_images, keep_masks\n",
    "imm_unspliced = b.RENDERER.render(registered_objects[0]['full_pose'][None,...], jnp.array([0]))[...,:3]\n",
    "imm,k = splice_image(imm_unspliced, gt_images_bg[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ concat_inferred_poses[123][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ registered_objects[0]['full_pose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridding_schedules = []\n",
    "for box_dims in b.RENDERER.model_box_dims:\n",
    "    c2fm1 = 2\n",
    "    c2f0 = 1\n",
    "    c2f1 = 0.35 * c2f0\n",
    "    # c2f1 = 0.7 * c2f0\n",
    "    c2f2 = 0.7 * c2f1\n",
    "    c2f3 = 0.2 * c2f2\n",
    "    c2f4 = 0.2 * c2f3\n",
    "    c2f5 = 0.2 * c2f4\n",
    "    c2f6 = 0.2 * c2f5\n",
    "\n",
    "    c2fs = [c2f0,c2f1,c2f2,c2f3,c2f4]#,c2f5,c2f6] #c2fm1\n",
    "    # c2f0 = 1\n",
    "    # c2f1 = 0.15 * c2f0\n",
    "    # c2f2 = 0.05 * c2f1\n",
    "    # c2f3 = 0.05 * c2f2\n",
    "    # c2fs = [c2f0,c2f1,c2f2,c2f3]\n",
    "\n",
    "    x,y,z = box_dims\n",
    "    grid_widths = [[c2f*x, c2f*y, c2f*z] for c2f in c2fs]\n",
    "\n",
    "    grid_nums = [(13,13,7),(7,7,7),(7,7,7),(7,7,7), (7,7,7)]#,(7,7,7),(7,7,7)]\n",
    "    # grid_nums = [(7,7,7),(5,5,5),(5,5,5), (5,5,5), (5,5,5), (3,3,3), (3,3,3)]\n",
    "    # grid_nums = [(5,5,5),(5,5,5),(5,5,5),(5,5,5), (5,5,5), (5,5,5)]#, (5,5,5), (5,5,5)]\n",
    "    # grid_nums = [(15,15,5), (41,5,5), (41,5,5), (41,5,5)]\n",
    "    gridding_schedule_trans = make_schedule_translation_3d_variable_grid(grid_widths, grid_nums)\n",
    "    gridding_schedules.append(gridding_schedule_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_poses = np.tile(jnp.eye(4).at[2,3].set(-1e5)[None,None,None,...], (t_start,n_particles,num_registered_objects,1,1))\n",
    "concat_inferred_poses = np.concatenate([dummy_poses, inferred_poses])\n",
    "\n",
    "# test for bad init\n",
    "tt = 123 # registered_objects[0]['t_full'] + 2\n",
    "reference = concat_inferred_poses[tt][0,0]\n",
    "print(\"original \",(cam_pose @ reference)[:3,3])\n",
    "next_t_step = tt+1\n",
    "obs = gt_images[next_t_step]\n",
    "c2f_imgs = []\n",
    "\n",
    "\n",
    "orig_img = b.RENDERER.render(reference[None,...], jnp.array([0]))[...,:3]\n",
    "xxx_orig = splice_image(orig_img, gt_images_bg[next_t_step])\n",
    "c2f_imgs.append(b.scale_image(b.get_depth_image(xxx_orig[...,2]),5))\n",
    "\n",
    "for i in range(len(gridding_schedules[0])):\n",
    "    updated_grid = jnp.einsum(\"ij,ajk->aik\", reference, gridding_schedules[0][i])\n",
    "\n",
    "    valid = jnp.logical_not(are_bboxes_intersecting_many_jit(\n",
    "                        (100,100,20),\n",
    "                        b.RENDERER.model_box_dims[0],\n",
    "                        jnp.eye(4).at[:3,3].set([0,0,-10.1]),\n",
    "                        jnp.einsum(\"ij,ajk->aik\",cam_pose,updated_grid)\n",
    "                        ))\n",
    "    \n",
    "    # if pose is not valid, use the reference pose\n",
    "    updated_grid = jnp.where(valid[:,None,None], updated_grid, reference[None,...])\n",
    "\n",
    "\n",
    "\n",
    "    imgs = b.RENDERER.render_many(updated_grid[:,None,...], jnp.array([0]))[...,:3]\n",
    "    rendered_images = splice_image_vmap(imgs, gt_images_bg[next_t_step])\n",
    "    scores = outlier_gaussian_vmap(obs, rendered_images, 0.1,None)\n",
    "    # print(scores)\n",
    "    idx = scores.argmax()\n",
    "    reference = updated_grid[idx]\n",
    "    print((cam_pose @ reference)[:3,3])\n",
    "    c2f_imgs.append(b.scale_image(b.get_depth_image(rendered_images[idx,...,2]),5))\n",
    "    print(scores.argmax())\n",
    "for x in c2f_imgs:\n",
    "    display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.RENDERER.model_box_dims/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.array([True]) * jnp.array([False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_images[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gt_images.shape[1] * gt_images.shape[2]*jax.scipy.stats.norm.pdf(\n",
    "        0,\n",
    "        loc=0.0, \n",
    "        scale=variance\n",
    "    ) * 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high memory usage !!!####\n",
    "\n",
    "# b.setup_renderer(intrinsics_orig, num_layers= 1024)\n",
    "# for i,registered_obj in enumerate(registered_objects):\n",
    "#     b.RENDERER.add_mesh(registered_obj['mesh'])\n",
    "# if len(registered_objects) == 0:\n",
    "#     b.RENDERER.add_mesh_from_file(os.path.join(b.utils.get_assets_dir(),\"sample_objs/cube.obj\"), scaling_factor = 0.1)\n",
    "\n",
    "# splice_image_double_vmap = jax.vmap(splice_image, in_axes = (0,0))\n",
    "# rend_scores = []\n",
    "# for p_id in tqdm(range(n_particles)):\n",
    "#     new_rendered_unspliced = b.RENDERER.render_many(inferred_poses[:,p_id,...], jnp.arange(num_registered_objects))[...,:3]\n",
    "#     new_rendered = splice_image_double_vmap(new_rendered_unspliced, gt_images_bg_orig[t_start:])\n",
    "#     scores = threedp3_likelihood_arijit_double_vmap(gt_images_orig[t_start:], new_rendered, 0.1,None)\n",
    "#     rend_scores.append(np.array(scores))\n",
    "# rend_scores = np.stack(rend_scores).T\n",
    "# rend_scores.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
