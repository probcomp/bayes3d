{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jax\n",
    "import time\n",
    "import genjax\n",
    "import bayes3d as b\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../\")\n",
    "from viz import *\n",
    "from utils import *\n",
    "from mcs_utils import *\n",
    "from PIL import Image\n",
    "import bayes3d.transforms_3d as t3d\n",
    "from jax.debug import print as jprint\n",
    "from tqdm import tqdm\n",
    "import jax.tree_util as jtu\n",
    "from genjax._src.core.transforms.incremental import NoChange, UnknownChange, Diff\n",
    "console = genjax.pretty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and preprocessing all data and renderer\n",
    "SCALE = 0.1\n",
    "cam_pose = CAM_POSE_CV2\n",
    "inverse_cam_pose = jnp.linalg.inv(CAM_POSE_CV2)\n",
    "observations = load_observations_npz('passive_physics_validation_object_permanence_0001_01')\n",
    "gt_images, gt_images_bg, gt_images_obj, intrinsics, registered_objects = preprocess_mcs_physics_scene(observations, MIN_DIST_THRESH=0.6, scale=SCALE)\n",
    "b.setup_renderer(intrinsics)\n",
    "for registered_obj in registered_objects:\n",
    "    b.RENDERER.add_mesh(registered_obj['mesh'])\n",
    "video_from_rendered(gt_images, scale = int(1/SCALE), framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model time!\n",
    "\n",
    "def get_bottom_most_height(i, world_pose):\n",
    "    # Half dimensions to get the corner points relative to the center\n",
    "    rotation_matrix = world_pose[:3,:3]\n",
    "    center = world_pose[:3,3]\n",
    "    dimensions = b.RENDERER.model_box_dims[i]\n",
    "    half_dims = dimensions / 2\n",
    "\n",
    "    # Local corner points of the box in its local coordinate system\n",
    "    local_corners = jnp.array([\n",
    "        [-half_dims[0], -half_dims[1], -half_dims[2]],  # Lower rear left corner\n",
    "        [ half_dims[0], -half_dims[1], -half_dims[2]],  # Lower rear right corner\n",
    "        [-half_dims[0],  half_dims[1], -half_dims[2]],  # Lower front left corner\n",
    "        [ half_dims[0],  half_dims[1], -half_dims[2]],  # Lower front right corner\n",
    "        [-half_dims[0], -half_dims[1],  half_dims[2]],  # Upper rear left corner\n",
    "        [ half_dims[0], -half_dims[1],  half_dims[2]],  # Upper rear right corner\n",
    "        [-half_dims[0],  half_dims[1],  half_dims[2]],  # Upper front left corner\n",
    "        [ half_dims[0],  half_dims[1],  half_dims[2]]   # Upper front right corner\n",
    "    ])\n",
    "\n",
    "    # Apply rotation to each corner point\n",
    "    global_corners = jnp.stack([center + rotation_matrix @ corner for corner in local_corners])\n",
    "\n",
    "    # Find the bottom-most point\n",
    "    bottom_most_point_z = jnp.min(global_corners[:,2])\n",
    "    # distance from centre of bbox to bottom of bbox\n",
    "    center_to_bottom_dist = center[2] - bottom_most_point_z\n",
    "    return bottom_most_point_z, center_to_bottom_dist\n",
    "\n",
    "def update_vel_friction(vel_world, friction):\n",
    "    deltax = vel_world[0,3]\n",
    "    deltay = vel_world[1,3]\n",
    "\n",
    "    deltax = deltax - friction*deltax\n",
    "    deltay = deltay - friction*deltay\n",
    "\n",
    "    deltax = jax.lax.cond(\n",
    "        jnp.less_equal(jnp.abs(deltax),5e-4),\n",
    "        lambda:0.0,\n",
    "        lambda:deltax)\n",
    "    \n",
    "    deltay = jax.lax.cond(\n",
    "        jnp.less_equal(jnp.abs(deltay),5e-4),\n",
    "        lambda:0.0,\n",
    "        lambda:deltay)\n",
    "    \n",
    "    return vel_world.at[:2,3].set([deltax,deltay])\n",
    "\n",
    "# This model has to be recompiled for different # objects for now this is okay\n",
    "def determine_next_pose(all_poses, t, i, friction, gravity):\n",
    "    # ignoring rotations for now #\n",
    "    # vel_prev = jnp.linalg.solve(all_poses[t-2], all_poses[t-1])\n",
    "    # vel_prev_prev = jnp.linalg.solve(all_poses[t-3], all_poses[t-2])\n",
    "    # accel = jnp.linalg.solve(vel_prev_prev, vel_prev)\n",
    "    # vel_now = vel_prev @ accel\n",
    "\n",
    "    # simple velocity update\n",
    "    vel_prev_world = cam_pose @ jnp.linalg.solve(all_poses[t-2], all_poses[t-1])\n",
    "    vel_world = vel_prev_world.at[2,3].set(vel_prev_world[2,3] - gravity * 1./20)\n",
    "\n",
    "    # friction check if object is on ground\n",
    "    prev_pose_world = cam_pose @ all_poses[t-1]\n",
    "    vel_world = jax.lax.cond(\n",
    "        jnp.less_equal(get_bottom_most_height(i, prev_pose_world)[0],0.05),\n",
    "        update_vel_friction,\n",
    "        lambda *_:vel_world,\n",
    "        *(vel_world, friction)\n",
    "    )\n",
    "\n",
    "    # go back to cam pose and update pose\n",
    "    vel = inverse_cam_pose @ vel_world\n",
    "    next_pose = all_poses[t-1].at[:3,3].set(all_poses[t-1][:3,3] + vel[:3,3]) # trans only, no rot\n",
    "    # # ground collision\n",
    "    # next_pose_world = cam_pose @ next_pose\n",
    "    # bottom_z, center_to_bottom = get_bottom_most_height(i, next_pose_world)\n",
    "    # next_pose = jax.lax.cond(\n",
    "    #     jnp.less_equal(bottom_z,0),\n",
    "    #     lambda:inverse_cam_pose @ next_pose_world.at[2,3].set(center_to_bottom),\n",
    "    #     lambda:next_pose\n",
    "    # )\n",
    "    \n",
    "    return next_pose\n",
    "\n",
    "@genjax.gen\n",
    "def mcs_single_object(prev_state, t_inits, t_fulls, init_poses, pose_update_params, dynamic_params, variance, outlier_prob):\n",
    "    \"\"\"\n",
    "    Single Object Model HMM\n",
    "    \"\"\"\n",
    "\n",
    "    (_, _, poses, all_poses, active_states, t) = prev_state\n",
    "    friction, gravity = dynamic_params\n",
    "    num_objects = poses.shape[0]\n",
    "    \n",
    "    # for each object\n",
    "    for i in range(num_objects):        \n",
    "        poses = poses.at[i].set(\n",
    "            jax.lax.cond(\n",
    "                jnp.greater_equal(t,t_fulls[i]+2),\n",
    "                determine_next_pose,\n",
    "                lambda *_:poses[i],\n",
    "                *(all_poses[:,i,...], t, i, friction, gravity)\n",
    "            )\n",
    "        )\n",
    "        updated_pose = b.gaussian_vmf_pose(poses[i], *pose_update_params)  @ f\"pose_{i}\"\n",
    "        poses = poses.at[i].set(updated_pose)\n",
    "        # # activate object when t == t_init for that object and initialize the correct pose\n",
    "        # active_states = active_states.at[i].set(jax.lax.cond(\n",
    "        #     jnp.equal(t_inits[i],t), # doing t_init + 1 so in first time step, the pose is fixed \n",
    "        #     lambda:True, \n",
    "        #     lambda:active_states[i]))\n",
    "        \n",
    "        poses = poses.at[i].set(jax.lax.cond(\n",
    "            jnp.equal(t_inits[i],t), # init pose at the corerct time step\n",
    "            lambda:init_poses[i], \n",
    "            lambda:poses[i]))\n",
    "        # jprint(\"t = {}, pose is {}\",t, poses[0][:3,3])\n",
    "\n",
    "    all_poses = all_poses.at[t].set(poses)\n",
    "    rendered_image_obj = b.RENDERER.render(\n",
    "        poses, jnp.arange(num_objects))[...,:3]\n",
    "\n",
    "    # NOTE: gt_images_bg is a global variable here as it consumes too much memory for the trace\n",
    "    rendered_image = splice_image(rendered_image_obj, gt_images_bg[t])\n",
    "\n",
    "    sampled_image = b.image_likelihood(rendered_image, variance, outlier_prob) @ \"depth\"\n",
    "\n",
    "    return (rendered_image, rendered_image_obj, poses, all_poses, active_states, t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_update_v5(key, trace_, pose_grid, enumerator):\n",
    "    \n",
    "    weights = enumerator.enumerate_choices_get_scores(trace_, key, pose_grid)\n",
    "    sampled_idx = weights.argmax() # jax.random.categorical(key, weights)\n",
    "    # jprint(\"weights = {}\",weights)\n",
    "    # jprint(\"idx chosen = {}\",sampled_idx)\n",
    "    return *enumerator.update_choices_with_weight(\n",
    "        trace_, key,\n",
    "        pose_grid[sampled_idx]\n",
    "    ), pose_grid[sampled_idx]\n",
    "\n",
    "\n",
    "pose_update_v5_jit = jax.jit(pose_update_v5, static_argnames=(\"enumerator\",))\n",
    "\n",
    "\n",
    "def c2f_pose_update_v5(key, trace_, reference, gridding_schedule, enumerator, addr, obj_id):\n",
    "    # for each object (TODO: gibbs sampling)\n",
    "    for i in range(len(gridding_schedule)):\n",
    "        updated_grid = jnp.einsum(\"ij,ajk->aik\", reference, gridding_schedule[i])\n",
    "        # Time to check valid poses that dont intersect with the floor\n",
    "        valid = jnp.logical_not(are_bboxes_intersecting_many_jit(\n",
    "                            (100,100,20),\n",
    "                            b.RENDERER.model_box_dims[obj_id],\n",
    "                            jnp.eye(4).at[:3,3].set([0,0,-10]),\n",
    "                            jnp.einsum(\"ij,ajk->aik\",cam_pose,updated_grid)\n",
    "                            ))\n",
    "        # if pose is not valid, use the reference pose\n",
    "        valid_grid = jnp.where(valid[:,None,None], updated_grid, reference[None,...])\n",
    "        weight, trace_, reference = pose_update_v5_jit(key, trace_, valid_grid, enumerator)\n",
    "        # jprint(\"ref position is {}\", reference[:3,3])\n",
    "\n",
    "    return weight, trace_\n",
    "\n",
    "c2f_pose_update_v5_vmap_jit = jax.jit(jax.vmap(c2f_pose_update_v5, in_axes=(0,0,None,None,None)),\n",
    "                                    static_argnames=(\"enumerator\", \"t\", \"addr\"))\n",
    "\n",
    "c2f_pose_update_v5_jit = jax.jit(c2f_pose_update_v5,static_argnames=(\"enumerator\", \"t\", \"addr\"))\n",
    "\n",
    "def make_new_keys(key, N_keys):\n",
    "    key, other_key = jax.random.split(key)\n",
    "    new_keys = jax.random.split(other_key, N_keys)\n",
    "    if N_keys > 1:\n",
    "        return key, new_keys\n",
    "    else:\n",
    "        return key, new_keys[0]\n",
    "\n",
    "\n",
    "def update_choice_map_no_unfold(gt_depths, constant_choices, t):\n",
    "    constant_choices['depth'] = gt_depths[t]\n",
    "    return genjax.choice_map(\n",
    "                constant_choices\n",
    "            )\n",
    "\n",
    "def argdiffs_modelv7(trace):\n",
    "    \"\"\"\n",
    "    Argdiffs specific to mcs_single_obejct model with no unfold\n",
    "    \"\"\"\n",
    "    # print(trace.args)\n",
    "    args = trace.get_args()\n",
    "    argdiffs = (\n",
    "        jtu.tree_map(lambda v: Diff(v, UnknownChange), args[0]),\n",
    "        *jtu.tree_map(lambda v: Diff(v, NoChange), args[1:]),\n",
    "    )\n",
    "    return argdiffs\n",
    "\n",
    "def proposal_choice_map_no_unfold(addresses, args, chm_args):\n",
    "    addr = addresses[0] # custom defined\n",
    "    return genjax.choice_map({\n",
    "                        addr: args[0]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_approach_F4(model, gt, gridding_schedule, model_args, init_state, key, constant_choices, T, addr):\n",
    "    \"\"\"\n",
    "    Sequential Importance Sampling on the non-unfolded HMM model\n",
    "    with 3D pose enumeration proposal\n",
    "\n",
    "    WITH JUST ONE PARTICLE\n",
    "    \"\"\"\n",
    "    # define functions for SIS/SMC\n",
    "    init_fn = jax.jit(model.importance)\n",
    "    update_fn = jax.jit(model.update)\n",
    "    proposal_fn = c2f_pose_update_v5_jit\n",
    "    num_objects = init_state[2].shape[0]\n",
    "    enumerators = [b.make_enumerator([(addr + f'_{i}')], \n",
    "                        chm_builder = proposal_choice_map_no_unfold,\n",
    "                        argdiff_f=lambda x: argdiffs\n",
    "                        ) for i in range(num_objects)]\n",
    "    \n",
    "    def smc_body(carry, t):\n",
    "        # get new keys\n",
    "        print(\"jit compiling\")\n",
    "        jprint(\"t = {}\",t)\n",
    "        # initialize particle based on last time step\n",
    "        \n",
    "        key, log_weight, state,  = carry\n",
    "        key, importance_key = make_new_keys(key, 1)\n",
    "        # key, update_key = make_new_keys(key, 1)\n",
    "        key, proposal_key = make_new_keys(key, 1)\n",
    "        \n",
    "        importance_log_weight, particle = init_fn(importance_key, update_choice_map_no_unfold(gt,constant_choices, t), (state, *model_args))\n",
    "\n",
    "        argdiffs = argdiffs_modelv7(particle)\n",
    "\n",
    "\n",
    "        # propose good poses based on proposal\n",
    "        proposal_log_weight = 0\n",
    "        for obj_id in range(num_objects):\n",
    "            w, particle = proposal_fn(\n",
    "                proposal_key, particle, state[2][obj_id], gridding_schedule, enumerators[0], addr, obj_id)\n",
    "            proposal_log_weight += w\n",
    "\n",
    "        # get weight of particle\n",
    "        new_log_weight = log_weight + importance_log_weight + proposal_log_weight# + update_log_weight\n",
    "        # next state is just the retval\n",
    "        next_state = (None,None,*particle.get_retval()[2:])\n",
    "\n",
    "        return (key, new_log_weight, next_state), particle\n",
    "\n",
    "    (_, final_log_weight, _), trace = jax.lax.scan(\n",
    "        smc_body, (key, 0, init_state), jnp.arange(0, T))\n",
    "    rendered = trace.get_retval()[0]\n",
    "    rendered_obj = trace.get_retval()[1]\n",
    "    inferred_poses = trace.get_retval()[2]\n",
    "    print(\"SCAN finished\")\n",
    "    return final_log_weight, rendered, rendered_obj, inferred_poses, trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumeration grid\n",
    "# TODO: ADAPTIVE GRID SIZING\n",
    "grid_widths = [1, 0.2,0.04]\n",
    "# grid_widths = [0.5, 0.1,0.02]\n",
    "grid_nums = [(7,7,7),(7,7,7),(7,7,7)]\n",
    "gridding_schedule_trans = make_schedule_translation_3d(grid_widths, grid_nums)\n",
    "gridding_schedule_rot = [b.utils.make_rotation_grid_enumeration(10, 15, -jnp.pi/12, jnp.pi/12, jnp.pi/12)]\n",
    "# gridding_schedule = [gridding_schedule_trans[0], gridding_schedule_trans[1], gridding_schedule_trans[2], gridding_schedule_rot[0]]\n",
    "gridding_schedule = [gridding_schedule_trans[0], gridding_schedule_trans[1], gridding_schedule_trans[2]]\n",
    "\n",
    "# Setup for inference\n",
    "T = gt_images.shape[0]\n",
    "num_registered_objects = len(registered_objects)\n",
    "INIT_STATE = (\n",
    "        None,\n",
    "        None,\n",
    "        jnp.tile(jnp.eye(4).at[2,3].set(1e+5)[None,...],(num_registered_objects,1,1)),\n",
    "        jnp.zeros((T,num_registered_objects,4,4)),\n",
    "        jnp.zeros(num_registered_objects, dtype=bool),\n",
    "        0\n",
    ")\n",
    "MODEL_ARGS = (\n",
    "     jnp.array([registered_obj['t_init'] for r in registered_objects]),\n",
    "     jnp.array([registered_obj['t_full'] for r in registered_objects]),\n",
    "     jnp.array([registered_obj['pose'] for r in registered_objects]),\n",
    "     jnp.array([5e-0, 5e-1]),\n",
    "     (0.0, 9.81),\n",
    "     0.1,\n",
    "     None\n",
    ")\n",
    "CONSTANT_CHOICES = {}\n",
    "\n",
    "key = jax.random.PRNGKey(45675456)\n",
    "\n",
    "model = mcs_single_object\n",
    "# inference_approach_F4_jit = jax.jit(inference_approach_F3, static_argnames=(\"T\", \"addr\"))\n",
    "inference_approach_F4_jit = inference_approach_F4\n",
    "\n",
    "start = time.time()\n",
    "lw, rendered, rendered_obj, inferred_poses, trace = inference_approach_F4_jit(model, gt_images, \n",
    "    gridding_schedule, MODEL_ARGS, INIT_STATE, key, CONSTANT_CHOICES, T, \"pose\")\n",
    "print (\"FPS:\", rendered.shape[0] / (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(345345)\n",
    "\n",
    "T = gt_images.shape[0]\n",
    "num_registered_objects = len(registered_objects)\n",
    "INIT_STATE = (\n",
    "        None,\n",
    "        None,\n",
    "        jnp.tile(jnp.eye(4).at[2,3].set(1e+5)[None,...],(num_registered_objects,1,1)),\n",
    "        jnp.zeros((T,num_registered_objects,4,4)),\n",
    "        jnp.zeros(num_registered_objects, dtype=bool),\n",
    "        0\n",
    ")\n",
    "MODEL_ARGS = (\n",
    "     jnp.array([registered_obj['t_init'] for r in registered_objects]),\n",
    "     jnp.array([registered_obj['t_full'] for r in registered_objects]),\n",
    "     jnp.array([registered_obj['pose'] for r in registered_objects]),\n",
    "     jnp.array([5e-5, 5e+6]),\n",
    "     (0.0, 9.81),\n",
    "     0.1,\n",
    "     None\n",
    ")\n",
    "\n",
    "_, tr = mcs_single_object.importance(key,update_choice_map_no_unfold(gt_images[0],{}, 0), (INIT_STATE, *MODEL_ARGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argdiffs = argdiffs_modelv7(tr)\n",
    "enum = b.make_enumerator([('pose_0')], \n",
    "                        chm_builder = proposal_choice_map_no_unfold,\n",
    "                        argdiff_f=lambda x: argdiffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_grid = jnp.tile(jnp.eye(4).at[:3,3].set([0,0,0])[None,...],(10000,1,1))\n",
    "\n",
    "pose_grid = pose_grid.at[0,:3,3].set([100,10,234])\n",
    "\n",
    "scores = enum.enumerate_choices_get_scores(tr, key, pose_grid)\n",
    "\n",
    "print(scores)\n",
    "\n",
    "tr[\"pose_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for t in range(T):\n",
    "    images.append(b.multi_panel([\n",
    "                b.scale_image(b.get_depth_image(gt_images[t][...,2]),6),\n",
    "                b.scale_image(b.get_depth_image(rendered[t][...,2]),6),\n",
    "                b.scale_image(b.get_depth_image(rendered_obj[t][...,2]),6)\n",
    "                ],labels = ['gt/sampled', 'rendered', 'rendered_obj']))\n",
    "display_video(images, framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = tr.get_retval()[3][-1][:,0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ poses[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_poses = tr.get_retval()[3][102][:,0,...]\n",
    "cam_pose @ determine_next_pose(all_poses, 103, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bottom_most_height(0,cam_pose @ poses[135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(cam_pose @ poses[i])[1,3] for i in range(132,240)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 124\n",
    "b.multi_panel([\n",
    "                b.scale_image(b.get_depth_image(gt_images[t][...,2]),6),\n",
    "                b.scale_image(b.get_depth_image(tr.get_retval()[0][t][...,2]),6),\n",
    "                b.scale_image(b.get_depth_image(tr.get_retval()[1][t][...,2]),6)\n",
    "                ],labels = ['gt/sampled', 'rendered', 'rendered_obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_comparison_from_images(tr.get_retval()[0], gt_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vmf param tuner\n",
    "params = (1e+1,1e-1)\n",
    "display(b.gaussian_vmf_pose.logpdf(jnp.eye(4), jnp.eye(4).at[:3,3].set([0,0,0]), *params))\n",
    "display(b.gaussian_vmf_pose.logpdf(jnp.eye(4), jnp.eye(4).at[:3,3].set([1,1,1]), *params))\n",
    "b.gaussian_vmf_pose.logpdf(jnp.eye(4), jnp.eye(4).at[:3,:3].set(R_zyx), *params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.project(genjax.select(\"pose_0\")) + tr.project(genjax.select(\"depth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
