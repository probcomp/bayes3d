{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jax\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import genjax\n",
    "import bayes3d as b\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../\")\n",
    "from viz import *\n",
    "from utils import *\n",
    "from mcs_utils import *\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import bayes3d.transforms_3d as t3d\n",
    "from jax.debug import print as jprint\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from genjax.generative_functions.distributions import ExactDensity\n",
    "import jax.tree_util as jtu\n",
    "from genjax._src.core.transforms.incremental import NoChange, UnknownChange, Diff\n",
    "console = genjax.pretty()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and preprocessing all data and renderer\n",
    "# TODO TODO: CODE MAY CRASH IF NO OBJECTS DETECTED --> need to fix\n",
    "SCALE = 0.2\n",
    "cam_pose = CAM_POSE_CV2\n",
    "inverse_cam_pose = jnp.linalg.inv(CAM_POSE_CV2)\n",
    "observations = load_observations_npz('passive_physics_validation_spatio_temporal_continuity_0001_01')\n",
    "preprocessed_data = preprocess_mcs_physics_scene(observations, MIN_DIST_THRESH=0.6, scale=SCALE)\n",
    "(gt_images, gt_images_bg, gt_images_obj, intrinsics),(gt_images_orig, gt_images_bg_orig, gt_images_obj_orig, intrinsics_orig), registered_objects = preprocessed_data\n",
    "\n",
    "# # Instead of running the code above, i will pickle import in the y_ref\n",
    "# with open(\"obs.pkl\", 'wb') as file:\n",
    "#     pickle.dump(preprocessed_data, file)\n",
    "# with open('obs.pkl', 'rb') as file:\n",
    "#     (gt_images, gt_images_bg, gt_images_obj, intrinsics),(gt_images_orig, gt_images_bg_orig, gt_images_obj_orig, intrinsics_orig), registered_objects = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.setup_renderer(intrinsics)\n",
    "for registered_obj in registered_objects:\n",
    "    b.RENDERER.add_mesh(registered_obj['mesh'])\n",
    "if len(registered_objects) == 0:\n",
    "    registered_objects.append({'t_init' : 11,\n",
    "                            'pose' : jnp.eye(4).at[:3,3].set([0,0,1e+5]),\n",
    "                            'full_pose' : jnp.eye(4).at[:3,3].set([0,0,1e+5]),\n",
    "                            't_full' : 11})\n",
    "    b.RENDERER.add_mesh_from_file(os.path.join(b.utils.get_assets_dir(),\"sample_objs/cube.obj\"), scaling_factor = 0.1)\n",
    "# video_from_rendered(gt_images, scale = int(1/SCALE), framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model time!\n",
    "\n",
    "def get_height_bounds(i, world_pose):\n",
    "    # Half dimensions to get the corner points relative to the center\n",
    "    rotation_matrix = world_pose[:3,:3]\n",
    "    center = world_pose[:3,3]\n",
    "    dimensions = b.RENDERER.model_box_dims[i]\n",
    "    half_dims = dimensions / 2\n",
    "\n",
    "    # Local corner points of the box in its local coordinate system\n",
    "    local_corners = jnp.array([\n",
    "        [-half_dims[0], -half_dims[1], -half_dims[2]],  # Lower rear left corner\n",
    "        [ half_dims[0], -half_dims[1], -half_dims[2]],  # Lower rear right corner\n",
    "        [-half_dims[0],  half_dims[1], -half_dims[2]],  # Lower front left corner\n",
    "        [ half_dims[0],  half_dims[1], -half_dims[2]],  # Lower front right corner\n",
    "        [-half_dims[0], -half_dims[1],  half_dims[2]],  # Upper rear left corner\n",
    "        [ half_dims[0], -half_dims[1],  half_dims[2]],  # Upper rear right corner\n",
    "        [-half_dims[0],  half_dims[1],  half_dims[2]],  # Upper front left corner\n",
    "        [ half_dims[0],  half_dims[1],  half_dims[2]]   # Upper front right corner\n",
    "    ])\n",
    "\n",
    "    # Apply rotation to each corner point\n",
    "    global_corners = jnp.stack([center + rotation_matrix @ corner for corner in local_corners])\n",
    "\n",
    "    # Find the bottom-most point\n",
    "    bottom_most_point_z = jnp.min(global_corners[:,2])\n",
    "    top_most_point_z = jnp.max(global_corners[:,2])\n",
    "    # distance from centre of bbox to bottom of bbox\n",
    "    center_to_bottom_dist = center[2] - bottom_most_point_z\n",
    "    return bottom_most_point_z,top_most_point_z, center_to_bottom_dist\n",
    "\n",
    "def get_translation_direction(all_poses, t_full, t):\n",
    "    direction = all_poses[t-1][:3,3] - all_poses[t_full][:3,3]\n",
    "    direction = cam_pose[:3,:3] @ direction\n",
    "    direction_xy = direction.at[2].set(0)\n",
    "\n",
    "    normalized_direction_xy = jax.lax.cond(jnp.equal(jnp.linalg.norm(direction_xy), 0),\n",
    "                                         lambda: direction_xy,\n",
    "                                         lambda: direction_xy/jnp.linalg.norm(direction_xy))\n",
    "    return normalized_direction_xy\n",
    "\n",
    "\n",
    "# This model has to be recompiled for different # objects for now this is okay\n",
    "@genjax.gen\n",
    "def physics_stepper(all_poses, t, t_full, i, friction, gravity):\n",
    "    # TODO: SAMPLING FRICTION SCHEME --> can be of a hmm style\n",
    "\n",
    "    #################################################################\n",
    "    # First let us consider timestep t-1\n",
    "    #################################################################\n",
    "    # Step 2: find world pose\n",
    "    pose_prev = all_poses[t-1]\n",
    "    pose_prev_world = cam_pose @ pose_prev\n",
    "\n",
    "    # Step 3: check if we are already on the floor\n",
    "    bottom_z, top_z, center_to_bottom = get_height_bounds(i, pose_prev_world)\n",
    "    # within 20% of the object's height in world frame\n",
    "    already_on_floor = jnp.less_equal(bottom_z,0.2 * (top_z - bottom_z))\n",
    "    \n",
    "    # Step 1: Find world velocity\n",
    "    vel_pose_camera = jnp.linalg.solve(all_poses[t-2], all_poses[t-1])\n",
    "    pre_vel_xyz_world = cam_pose[:3,:3] @ vel_pose_camera[:3,3]\n",
    "    mag_xy = jnp.linalg.norm(pre_vel_xyz_world[:2])\n",
    "    \n",
    "    mag_xy_friction = mag_xy - friction * mag_xy\n",
    "\n",
    "    mag_xy_friction = jax.lax.cond(\n",
    "        jnp.less_equal(jnp.abs(mag_xy_friction),3e-2),\n",
    "        lambda:0.0,\n",
    "        lambda:mag_xy_friction)\n",
    "    \n",
    "    mag_xy, gravity = jax.lax.cond(already_on_floor,lambda:(mag_xy_friction,gravity),lambda:(mag_xy, gravity))\n",
    "\n",
    "    dir_xy_world = get_translation_direction(all_poses, t_full, t)\n",
    "\n",
    "    # Step 7: Determine mag and gravity\n",
    "\n",
    "    vel_xyz_world = mag_xy * dir_xy_world\n",
    "    # Step 6: apply z axis change\n",
    "    vel_xyz_world = vel_xyz_world.at[2].set(pre_vel_xyz_world[2] - gravity * 1./20)\n",
    "\n",
    "    # Step 5: find peturbed velocity (equal to original norm) with random rotation\n",
    "    perturbed_rot_pose = GaussianVMFPoseUntraced()(jnp.eye(4), *(1e-20, 1000.0))  @ \"perturb\"\n",
    "\n",
    "    vel_xyz_world_perturbed = perturbed_rot_pose[:3,:3] @ vel_xyz_world # without friction\n",
    "\n",
    "    vel_xyz_camera = inverse_cam_pose[:3,:3] @ vel_xyz_world_perturbed\n",
    "\n",
    "    # Step 8: Get velocity update in camera frame\n",
    "    vel = pose_prev.at[:3,3].set(vel_xyz_camera)\n",
    "\n",
    "    # Step 9: Identify next pose\n",
    "    next_pose = pose_prev.at[:3,3].set(pose_prev[:3,3] + vel[:3,3]) # trans only, no rot\n",
    "\n",
    "    # Step 10: Ensure new bottom of object is above floor --> ground collision\n",
    "    next_pose_world = cam_pose @ next_pose\n",
    "    bottom_z,_,center_to_bottom = get_height_bounds(i, next_pose_world)\n",
    "    next_pose = jax.lax.cond(\n",
    "        jnp.less_equal(bottom_z,0),\n",
    "        lambda:inverse_cam_pose @ next_pose_world.at[2,3].set(center_to_bottom),\n",
    "        lambda:next_pose\n",
    "    )\n",
    "\n",
    "    return next_pose\n",
    "\n",
    "def threedp3_likelihood_arijit(\n",
    "    observed_xyz: jnp.ndarray,\n",
    "    rendered_xyz: jnp.ndarray,\n",
    "    variance,\n",
    "    outlier_prob,\n",
    "):\n",
    "    distances = jnp.linalg.norm(observed_xyz - rendered_xyz, axis=-1)\n",
    "    probabilities_per_pixel = (distances < variance/2) / variance\n",
    "    average_probability = 1 * probabilities_per_pixel.mean()\n",
    "    return average_probability\n",
    "\n",
    "def outlier_gaussian(\n",
    "    observed_xyz: jnp.ndarray,\n",
    "    rendered_xyz: jnp.ndarray,\n",
    "    variance,\n",
    "    outlier_prob,\n",
    "):\n",
    "    distances = jnp.linalg.norm(observed_xyz - rendered_xyz, axis=-1)\n",
    "    probabilities_per_pixel = jax.scipy.stats.norm.pdf(\n",
    "        distances,\n",
    "        loc=0.0, \n",
    "        scale=variance\n",
    "    )\n",
    "    average_probability = probabilities_per_pixel.mean()\n",
    "    return average_probability\n",
    "\n",
    "@dataclass\n",
    "class ImageLikelihoodArijit(ExactDensity):\n",
    "    def sample(self, key, img, variance, outlier_prob):\n",
    "        return img\n",
    "\n",
    "    def logpdf(self, observed_image, latent_image, variance, outlier_prob):\n",
    "        return threedp3_likelihood_arijit(\n",
    "            observed_image, latent_image, variance, outlier_prob,\n",
    "        )\n",
    "    \n",
    "@dataclass\n",
    "class GaussianVMFPoseUntraced(ExactDensity):\n",
    "    def sample(self, key, pose_mean, var, concentration, **kwargs):\n",
    "        return b.distributions.gaussian_vmf(key, pose_mean, var, concentration)\n",
    "\n",
    "    def logpdf(self, pose, pose_mean, var, concentration, **kwargs):\n",
    "        return 0\n",
    "\n",
    "@genjax.gen\n",
    "def mcs_model(prev_state, t_inits, t_fulls, init_poses, full_poses, pose_update_params, gravity, variance, outlier_prob):\n",
    "    \"\"\"\n",
    "    Single Object Model HMM\n",
    "    \"\"\"\n",
    "\n",
    "    (_, _, poses, all_poses, friction, t) = prev_state\n",
    "\n",
    "    # jprint(\"t = {}, f = {}\",t, friction)\n",
    "\n",
    "    num_objects = poses.shape[0]\n",
    "    \n",
    "    # for each object\n",
    "    for i in range(num_objects):        \n",
    "        physics_prob = jnp.asarray(jax.lax.cond(jnp.greater_equal(t,t_fulls[i]+2),lambda:1,lambda:0), dtype=int)\n",
    "        physics_pose = physics_stepper(all_poses[:,i,...], t, t_fulls[i], i, friction, gravity) @ f\"physics_{i}\"\n",
    "        final_pose = jax.lax.cond(physics_prob, lambda:physics_pose, lambda:poses[i])\n",
    "        updated_pose = b.gaussian_vmf_pose(final_pose, *pose_update_params)  @ f\"pose_{i}\"\n",
    "        poses = poses.at[i].set(updated_pose)\n",
    "        \n",
    "        poses = poses.at[i].set(jax.lax.cond(\n",
    "            jnp.equal(t_inits[i],t), # init pose at the correct time step\n",
    "            lambda:init_poses[i], \n",
    "            lambda:poses[i]))\n",
    "        \n",
    "        poses = poses.at[i].set(jax.lax.cond(\n",
    "            jnp.equal(t_fulls[i],t), # full pose at the correct time step\n",
    "            lambda:full_poses[i], \n",
    "            lambda:poses[i]))\n",
    "\n",
    "    all_poses = all_poses.at[t].set(poses)\n",
    "    rendered_image_obj = b.RENDERER.render(\n",
    "        poses, jnp.arange(num_objects))[...,:3]\n",
    "\n",
    "    # NOTE: gt_images_bg is a global variable here as it consumes too much memory for the trace\n",
    "    rendered_image = splice_image(rendered_image_obj, gt_images_bg[t])\n",
    "\n",
    "    sampled_image = ImageLikelihoodArijit()(rendered_image, variance, outlier_prob) @ \"depth\"\n",
    "    # sampled_image = b.old_image_likelihood(rendered_image, 0.1, 0.001,1000,None) @ \"depth\"\n",
    "\n",
    "    return (rendered_image, rendered_image_obj, poses, all_poses, friction, t+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_update_v5(key, trace_, pose_grid, enumerator):\n",
    "    num_splits = (pose_grid.shape[0] // 400) + 1\n",
    "    all_weights = jnp.array([])\n",
    "    for split_pose_grid in jnp.array_split(pose_grid, num_splits):\n",
    "        weights = enumerator.enumerate_choices_get_scores(trace_, key, split_pose_grid)\n",
    "        all_weights = jnp.hstack([all_weights, weights])\n",
    "    sampled_idx = all_weights.argmax() # jax.random.categorical(key, weights)\n",
    "    # jprint(\"weights = {}\",weights)\n",
    "    # jprint(\"idx chosen = {}\",sampled_idx)\n",
    "    return *enumerator.update_choices_with_weight(\n",
    "        trace_, key,\n",
    "        pose_grid[sampled_idx]\n",
    "    ), pose_grid[sampled_idx]\n",
    "\n",
    "\n",
    "pose_update_v5_jit = jax.jit(pose_update_v5, static_argnames=(\"enumerator\",))\n",
    "\n",
    "\n",
    "def c2f_pose_update_v5(key, trace_, reference, gridding_schedule, enumerator, obj_id):\n",
    "    # for each object (TODO: gibbs sampling)\n",
    "    for i in range(len(gridding_schedule)):\n",
    "        updated_grid = jnp.einsum(\"ij,ajk->aik\", reference, gridding_schedule[i])\n",
    "        # Time to check valid poses that dont intersect with the floor\n",
    "        valid = jnp.logical_not(are_bboxes_intersecting_many_jit(\n",
    "                            (100,100,20),\n",
    "                            b.RENDERER.model_box_dims[obj_id],\n",
    "                            jnp.eye(4).at[:3,3].set([0,0,-10]),\n",
    "                            jnp.einsum(\"ij,ajk->aik\",cam_pose,updated_grid)\n",
    "                            ))\n",
    "        # if pose is not valid, use the reference pose\n",
    "        valid_grid = jnp.where(valid[:,None,None], updated_grid, reference[None,...])\n",
    "        weight, trace_, reference = pose_update_v5_jit(key, trace_, valid_grid, enumerator)\n",
    "        # jprint(\"ref position is {}\", reference[:3,3])\n",
    "\n",
    "    return weight, trace_\n",
    "\n",
    "c2f_pose_update_v5_vmap_jit = jax.jit(jax.vmap(c2f_pose_update_v5, in_axes=(0,0,None,None,None)),\n",
    "                                    static_argnames=(\"enumerator\", \"obj_id\"))\n",
    "\n",
    "c2f_pose_update_v5_jit = jax.jit(c2f_pose_update_v5,static_argnames=(\"enumerator\", \"obj_id\"))\n",
    "\n",
    "def make_new_keys(key, N_keys):\n",
    "    key, other_key = jax.random.split(key)\n",
    "    new_keys = jax.random.split(other_key, N_keys)\n",
    "    return key, new_keys\n",
    "\n",
    "def update_choice_map_no_unfold(gt_depths, constant_choices, t):\n",
    "    constant_choices['depth'] = gt_depths[t]\n",
    "    return genjax.choice_map(\n",
    "                constant_choices\n",
    "            )\n",
    "\n",
    "\n",
    "def argdiffs_modelv7(trace):\n",
    "    \"\"\"\n",
    "    Argdiffs specific to mcs_single_obejct model with no unfold\n",
    "    \"\"\"\n",
    "    args = trace.get_args()\n",
    "    argdiffs = (\n",
    "        jtu.tree_map(lambda v: Diff(v, UnknownChange), args[0]),\n",
    "        *jtu.tree_map(lambda v: Diff(v, NoChange), args[1:]),\n",
    "    )\n",
    "    return argdiffs\n",
    "\n",
    "\n",
    "\n",
    "def proposal_choice_map_no_unfold(addresses, args, chm_args):\n",
    "    addr = addresses[0] # custom defined\n",
    "    return genjax.choice_map({\n",
    "                        addr: args[0]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_approach_G2(model, gt, gridding_schedules, model_args, init_state, key, friction_params, constant_choices, T, addr, n_particles):\n",
    "    \"\"\"\n",
    "    Sequential Importance Sampling on the non-unfolded HMM model\n",
    "    with 3D pose enumeration proposal\n",
    "\n",
    "    WITH JUST ONE PARTICLE\n",
    "    \"\"\"\n",
    "    \n",
    "    num_objects = init_state[2].shape[0]\n",
    "\n",
    "    def get_next_state(particle):\n",
    "        return (None,None,*particle.get_retval()[2:])\n",
    "    get_next_state_vmap = jax.vmap(get_next_state, in_axes = (0,))\n",
    "\n",
    "    # sample friction\n",
    "    key, friction_keys = make_new_keys(key, n_particles)\n",
    "    # frictions = jax.vmap(genjax.normal.sample, in_axes = (0,None,None))(friction_keys,*friction_params)\n",
    "    frictions = jnp.linspace(-0.03,0.05,n_particles)\n",
    "    # broadcast init_state to number of particles\n",
    "    init_states = jax.vmap(lambda x:(*init_state[:4], x, *init_state[4:]), in_axes=(0,))(frictions)\n",
    "\n",
    "    # define functions for SIS/SMC\n",
    "    init_fn = jax.jit(jax.vmap(model.importance, in_axes=(0,None,0)))\n",
    "    update_fn = jax.jit(model.update)\n",
    "    proposal_fn = c2f_pose_update_v5_jit\n",
    "\n",
    "    def smc_body(carry, t):\n",
    "        # get new keys\n",
    "        print(\"jit compiling\")\n",
    "        # initialize particle based on last time step\n",
    "        jprint(\"t = {}\",t)\n",
    "        \n",
    "        key, log_weights, states,  = carry\n",
    "        key, importance_keys = make_new_keys(key, n_particles)\n",
    "        key, resample_key = jax.random.split(key)\n",
    "        key, proposal_key = jax.random.split(key)\n",
    "\n",
    "        variance = jax.lax.cond(\n",
    "            jnp.less_equal(t, model_args[1][0] + 2),\n",
    "            lambda: 5 * model_args[6],\n",
    "            lambda: model_args[6]\n",
    "        )\n",
    "\n",
    "        modified_model_args = (*model_args[:6], variance, *model_args[7:])\n",
    "\n",
    "        full_args = jax.vmap(lambda x,y:(x, *y), in_axes=(0,None))(states, modified_model_args)\n",
    "\n",
    "        importance_log_weights, particles = init_fn(importance_keys, update_choice_map_no_unfold(gt,constant_choices, t), full_args)\n",
    "        # # Resampling at every time step\n",
    "        # sampled_indices = jax.random.categorical(resample_key, log_weights, shape=(n_particles,))\n",
    "        # particles = jtu.tree_map(lambda v: v[sampled_indices], particles)\n",
    "\n",
    "\n",
    "        # propose good poses based on proposal\n",
    "        def proposer(carry, p):\n",
    "            key, idx = carry\n",
    "            proposal_log_weight = 0\n",
    "            # argdiff and enumerator\n",
    "            argdiffs = argdiffs_modelv7(p)\n",
    "            enumerators = [b.make_enumerator([(addr + f'_{i}')], \n",
    "                                        chm_builder = proposal_choice_map_no_unfold,\n",
    "                                        argdiff_f=lambda x: argdiffs\n",
    "                                        ) for i in range(num_objects)] \n",
    "            for obj_id in range(num_objects):\n",
    "                key, new_key = jax.random.split(key)\n",
    "                w, p = proposal_fn(new_key, p, states[2][idx][obj_id], gridding_schedules[obj_id], enumerators[obj_id], obj_id)\n",
    "                proposal_log_weight += w\n",
    "            return (new_key, idx + 1), (proposal_log_weight, p)\n",
    "        _, (proposal_log_weights, proposed_particles) = jax.lax.scan(proposer, (proposal_key, 0), particles)\n",
    "\n",
    "        # get weights of particles\n",
    "        new_log_weight = log_weights + importance_log_weights + proposal_log_weights\n",
    "        next_states = get_next_state_vmap(proposed_particles)\n",
    "\n",
    "        return (key, new_log_weight, next_states), proposed_particles\n",
    "\n",
    "    (_, final_log_weight, _), particles = jax.lax.scan(\n",
    "        smc_body, (key, jnp.zeros(n_particles), init_states), jnp.arange(0, T))\n",
    "    rendered = particles.get_retval()[0]\n",
    "    rendered_obj = particles.get_retval()[1]\n",
    "    inferred_poses = particles.get_retval()[2]\n",
    "    print(\"SCAN finished\")\n",
    "    return final_log_weight, rendered, rendered_obj, inferred_poses, particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumeration grid\n",
    "# TODO: ADAPTIVE GRID SIZING\n",
    "# grid_widths = [1, 0.2,0.04,0.008,0.002,0.0004]\n",
    "# # grid_widths = [0.5, 0.1,0.02]\n",
    "# grid_nums = [(7,7,7),(7,7,7),(7,7,7), (7,7,7), (7,7,7), (7,7,7)]\n",
    "# gridding_schedule_trans = make_schedule_translation_3d(grid_widths, grid_nums)\n",
    "# gridding_schedule_rot = [b.utils.make_rotation_grid_enumeration(10, 15, -jnp.pi/12, jnp.pi/12, jnp.pi/12)]\n",
    "# # gridding_schedule = [gridding_schedule_trans[0], gridding_schedule_trans[1], gridding_schedule_trans[2], gridding_schedule_rot[0]]\n",
    "# gridding_schedule = [gridding_schedule_trans[0], gridding_schedule_trans[1], \n",
    "#                      gridding_schedule_trans[2], gridding_schedule_trans[3],\n",
    "#                      gridding_schedule_trans[4], gridding_schedule_trans[5]]\n",
    "\n",
    "\n",
    "gridding_schedules = []\n",
    "for box_dims in b.RENDERER.model_box_dims:\n",
    "    c2f0 = 1\n",
    "    c2f1 = 0.7 * c2f0\n",
    "    c2f2 = 0.7 * c2f1\n",
    "    c2f3 = 0.2 * c2f2\n",
    "    c2f4 = 0.2 * c2f3\n",
    "    c2f5 = 0.2 * c2f4\n",
    "    c2f6 = 0.2 * c2f5\n",
    "\n",
    "    c2fs = [c2f0,c2f1,c2f2,c2f3,c2f4,c2f5,c2f6]\n",
    "\n",
    "    x,y,z = box_dims\n",
    "    grid_widths = [[c2f*x, c2f*y, c2f*z] for c2f in c2fs]\n",
    "\n",
    "    grid_nums = [(7,7,7),(7,7,7),(7,7,7), (7,7,7), (7,7,7), (7,7,7), (7,7,7)]\n",
    "    gridding_schedule_trans = make_schedule_translation_3d_variable_grid(grid_widths, grid_nums)\n",
    "    gridding_schedules.append(gridding_schedule_trans)\n",
    "\n",
    "# Setup for inference\n",
    "T = gt_images.shape[0]\n",
    "num_registered_objects = len(registered_objects)\n",
    "friction_params = (0.01,0.005)\n",
    "INIT_STATE = (\n",
    "        None,\n",
    "        None,\n",
    "        jnp.tile(jnp.eye(4).at[2,3].set(1e+5)[None,...],(num_registered_objects,1,1)),\n",
    "        jnp.zeros((T,num_registered_objects,4,4)),\n",
    "        0\n",
    ")\n",
    "MODEL_ARGS = (\n",
    "     jnp.array([r['t_init'] for r in registered_objects]),\n",
    "     jnp.array([r['t_full'] for r in registered_objects]),\n",
    "     jnp.array([r['pose'] for r in registered_objects]),\n",
    "     jnp.array([r['full_pose'] for r in registered_objects]),\n",
    "     jnp.array([5e-0, 5e-1]),\n",
    "     9.81/4,\n",
    "     0.1,\n",
    "     None\n",
    ")\n",
    "CONSTANT_CHOICES = {}\n",
    "\n",
    "key = jax.random.PRNGKey(np.random.randint(0,2332423432))\n",
    "\n",
    "model = mcs_model\n",
    "\n",
    "start = time.time()\n",
    "lw, rendered, rendered_obj, inferred_poses, trace = inference_approach_G2(model, gt_images, \n",
    "    gridding_schedules, MODEL_ARGS, INIT_STATE, key, friction_params, CONSTANT_CHOICES, T, \"pose\", 10)\n",
    "print (\"FPS:\", rendered.shape[0] / (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = trace.project(genjax.select(\"depth\"))\n",
    "start = registered_objects[0]['t_full']+3\n",
    "gap = w.max()-w.min()\n",
    "\n",
    "rendering_ll_images = []\n",
    "\n",
    "fig, ax = plt.subplots()  # Using subplots to directly access the figure object\n",
    "lines = []\n",
    "for p_id in range(w.shape[1]):\n",
    "    line = ax.plot(np.arange(0,1),w[:,p_id][0:1], label = f\"Particle {p_id+1}\")[0]\n",
    "    lines.append(line)\n",
    "ax.set_xlim([start,T])\n",
    "ax.set_ylim([9.7,10.02])\n",
    "# ax.set_ylim([w.min()-0.1*gap,w.max()+0.1*gap])\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Log Likelihood\")\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "fig.subplots_adjust(right=0.75)\n",
    "fig.canvas.draw()\n",
    "rendering_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "\n",
    "for _ in tqdm(range(0,start)):\n",
    "    rendering_ll_images.append(rendering_ll_img.copy().resize((600,400)))\n",
    "\n",
    "for t in tqdm(range(start,T)):\n",
    "    for p_id in range(w.shape[1]):\n",
    "        lines[p_id].set_data(np.arange(start,t+1),w[:,p_id][start:t+1])\n",
    "    fig.canvas.draw()\n",
    "    rendering_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "    rendering_ll_images.append(rendering_ll_img.resize((600,400)))\n",
    "    plt.close()\n",
    "\n",
    "w = trace.project(genjax.select(\"pose_0\"))\n",
    "start = registered_objects[0]['t_full']+3\n",
    "gap = w.max()-w.min()\n",
    "\n",
    "physics_ll_images = []\n",
    "\n",
    "fig, ax = plt.subplots()  # Using subplots to directly access the figure object\n",
    "lines = []\n",
    "for p_id in range(w.shape[1]):\n",
    "    line = ax.plot(np.arange(start,start+1),w[:,p_id][start:start+1], label = f\"Particle {p_id+1}\")[0]\n",
    "    lines.append(line)\n",
    "ax.set_xlim([start,T]) \n",
    "ax.set_ylim([-10.12,-10.095])\n",
    "# ax.set_ylim([w.min()-0.1*gap,w.max()+0.1*gap])\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Log Likelihood\")\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "fig.subplots_adjust(right=0.75)\n",
    "fig.canvas.draw()\n",
    "physics_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "\n",
    "for _ in tqdm(range(0,start)):\n",
    "    physics_ll_images.append(physics_ll_img.copy().resize((600,400)))\n",
    "\n",
    "for t in tqdm(range(start,T)):\n",
    "    for p_id in range(w.shape[1]):\n",
    "        lines[p_id].set_data(np.arange(start,t+1),w[:,p_id][start:t+1])\n",
    "    fig.canvas.draw()\n",
    "    physics_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "    physics_ll_images.append(physics_ll_img.resize((600,400)))\n",
    "    plt.close()\n",
    "\n",
    "p_images = get_particle_images(intrinsics_orig, inferred_poses, T = T)\n",
    "blended_images = [b.overlay_image(p_images[i],b.get_depth_image(gt_images_orig[i][...,2])) for i in range(len(p_images))]\n",
    "images = []\n",
    "for t in tqdm(range(T)):\n",
    "    images.append(b.scale_image(b.multi_panel([\n",
    "                b.get_depth_image(gt_images_orig[t,...,2]),\n",
    "                # b.scale_image(b.get_depth_image(rendered[t,particle_id,...,2]),scale),\n",
    "                blended_images[t],\n",
    "                physics_ll_images[t],\n",
    "                rendering_ll_images[t]\n",
    "                # b.scale_image(b.get_depth_image(rendered_obj[t,particle_id,...,2]),3)\n",
    "                ],labels = ['gt/observed', 'particles',\n",
    "                            \"physics likelihood\", \"rendering likelihood\"]), 0.4))\n",
    "display_video(images, framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = registered_objects[0]['t_full']+2\n",
    "w = trace.project(genjax.select(\"depth\"))\n",
    "gap = w.max()-w.min()\n",
    "w[144,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_poses = trace.get_retval()[2][:,:,0,...]\n",
    "all_poses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_state(particle):\n",
    "    return (None,None,*particle.get_retval()[2:])\n",
    "get_next_state_vmap = jax.vmap(get_next_state, in_axes = (0,))\n",
    "init_fn = jax.jit(jax.vmap(model.importance, in_axes=(0,None,0)))\n",
    "\n",
    "particles = jtu.tree_map(lambda v: v[141], trace)\n",
    "next_states = get_next_state_vmap(particles)\n",
    "full_args = jax.vmap(lambda x,y:(x, *y), in_axes=(0,None))(next_states, MODEL_ARGS)\n",
    "key, imp_keys = make_new_keys(key, 10)\n",
    "_, particles = init_fn(imp_keys, update_choice_map_no_unfold(gt_images,{}, 142), full_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.linalg.norm((cam_pose @ all_poses[104,7,...])[:3,3] - (cam_pose @ all_poses[103,7,...])[:3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = trace.project(genjax.select((\"physics_0\", \"perturb\")))\n",
    "w.max() - w.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = trace.project(genjax.select((\"depth\")))\n",
    "# w.max() - w.min()\n",
    "w[210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = trace.project(genjax.select((\"pose_0\")))\n",
    "# w.max() - w.min()\n",
    "w[142]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_poses = trace.get_retval()[2]\n",
    "display(cam_pose @ all_poses[123,0,...])\n",
    "display(cam_pose @ all_poses[132,0,...])\n",
    "blended_images[132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.RENDERER.model_box_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_poses[131,0,...] - all_poses[123,0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = 148\n",
    "display(cam_pose @ all_poses[tt,0,...])\n",
    "display(cam_pose @ all_poses[tt-1,0,...])\n",
    "display(cam_pose @ all_poses[tt,0,...] - cam_pose @ all_poses[tt-1,0,...])\n",
    "# trace.args[7][tt,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ physics_stepper_debug(all_poses[:,0,...], 148, 135, 0, -0.03, 9.81/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.scale_image(b.get_depth_image(rendered_obj[136,0,...,2]),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ registered_objects[0]['pose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propp = registered_objects[0]['full_pose'] @ gridding_schedule[0][172]\n",
    "ggg = b.RENDERER.render(propp[None,...], jnp.array([0]))[...,:3]\n",
    "fff = splice_image(ggg, gt_images_bg[142])\n",
    "b.scale_image(b.get_depth_image(fff[...,2]),8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageLikelihoodArijit().logpdf(gt_images[142,...],fff[...],0.1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageLikelihoodArijit().logpdf(gt_images[142,...],gt_images_bg[142,...],0.1,None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_gaussian(gt_images[142,...],gt_images_bg[142,...],0.01,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridding_schedule[0][172,:3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridding_schedule[0][172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propp = registered_objects[0]['full_pose'] @ gridding_schedule[0][172]\n",
    "cam_pose @ propp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
