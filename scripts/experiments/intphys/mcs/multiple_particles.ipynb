{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import jax\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import genjax\n",
    "import bayes3d as b\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../\")\n",
    "from viz import *\n",
    "from utils import *\n",
    "from mcs_utils import *\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import bayes3d.transforms_3d as t3d\n",
    "from jax.debug import print as jprint\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from genjax._src.core.pytree.utilities import *\n",
    "from genjax.generative_functions.distributions import ExactDensity\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "import jax.tree_util as jtu\n",
    "from genjax._src.core.transforms.incremental import NoChange, UnknownChange, Diff\n",
    "console = genjax.pretty()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading and preprocessing all data and renderer\n",
    "# SCALE = 0.2\n",
    "# cam_pose = CAM_POSE_CV2\n",
    "# inverse_cam_pose = jnp.linalg.inv(CAM_POSE_CV2)\n",
    "# scene_name = 'passive_physics_validation_object_permanence_0001_02'\n",
    "# # with open(f\"/home/arijitdasgupta/bayes3d/scripts/experiments/intphys/mcs/pickled_data/{scene_name}.pkl\", 'rb') as file:\n",
    "# #     preprocessed_data = pickle.load(file)\n",
    "# observations = load_observations_npz(scene_name)\n",
    "# preprocessed_data = preprocess_mcs_physics_scene(observations, MIN_DIST_THRESH=0.6, scale=SCALE)\n",
    "# (gt_images, gt_images_bg, gt_images_obj, intrinsics),\\\n",
    "# (gt_images_orig, gt_images_bg_orig, gt_images_obj_orig, intrinsics_orig),\\\n",
    "# registered_objects, obj_pixels, is_gravity, poses = preprocessed_data\n",
    "\n",
    "# # get obj indices padded\n",
    "# all_obj_indices = [np.argwhere(gt_images_obj[i,...,2] != intrinsics.far) for i in range(gt_images.shape[0])]\n",
    "# max_rows = max(obj_indices.shape[0] for obj_indices in all_obj_indices)\n",
    "# def pad_array(array, max_rows):\n",
    "#     padding = ((0, max_rows - array.shape[0]), (0, 0))  # Pad rows, not columns\n",
    "#     return jnp.pad(array, padding, constant_values=-1)\n",
    "\n",
    "# padded_all_obj_indices = jnp.stack([pad_array(array, max_rows) for array in all_obj_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Meshes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:05<01:47,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new mesh for t = {} 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:06<00:06, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding review\n",
      "Review passed, added to init queue\n",
      "Adding new mesh for t = {} 22\n",
      "Adding review\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [00:08<00:20,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review passed, added to init queue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting downsampled data\n",
      "Unstable: 1959\n",
      "Stable: 1261\n",
      "Perc diff: 21.677018633540374\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[3;92mTrue\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "observations = np.load(\"eval_7_npzs/{}.npz\".format(\"grav_0002_28\"),allow_pickle=True)[\"arr_0\"]\n",
    "SCALE =0.2\n",
    "preprocessed_data = preprocess_mcs_physics_scene(observations, MIN_DIST_THRESH=0.6, scale=SCALE)\n",
    "# with open(f\"/home/arijitdasgupta/bayes3d/scripts/experiments/intphys/mcs/pickled_data/{scene_ID}.pkl\", 'rb') as file:\n",
    "#     preprocessed_data = pickle.load(file)\n",
    "\n",
    "(gt_images, gt_images_bg, gt_images_obj, intrinsics),\\\n",
    "(gt_images_orig, gt_images_bg_orig, gt_images_obj_orig, intrinsics_orig),\\\n",
    "registered_objects, obj_pixels, is_gravity, poses, cam_pose = preprocessed_data\n",
    "\n",
    "inverse_cam_pose = jnp.linalg.inv(cam_pose)\n",
    "\n",
    "# get obj indices padded\n",
    "all_obj_indices = [np.argwhere(gt_images_obj[i,...,2] != intrinsics.far) for i in range(gt_images.shape[0])]\n",
    "max_rows = max(obj_indices.shape[0] for obj_indices in all_obj_indices)\n",
    "def pad_array(array, max_rows):\n",
    "    padding = ((0, max_rows - array.shape[0]), (0, 0))  # Pad rows, not columns\n",
    "    return jnp.pad(array, padding, constant_values=-1)\n",
    "\n",
    "padded_all_obj_indices = jnp.stack([pad_array(array, max_rows) for array in all_obj_indices])\n",
    "\n",
    "if is_gravity:\n",
    "    plausible, plausibility_list, _ = gravity_scene_plausible(poses, intrinsics_orig, registered_objects, cam_pose, observations)\n",
    "    display(plausible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mPIL.Image.Image\u001b[0m\u001b[39m image \u001b[0m\u001b[33mmode\u001b[0m\u001b[39m=\u001b[0m\u001b[35mRGB\u001b[0m\u001b[39m \u001b[0m\u001b[33msize\u001b[0m\u001b[39m=\u001b[0m\u001b[35m60\u001b[0m\u001b[1;36m0x400\u001b[0m\u001b[39m at \u001b[0m\u001b[1;36m0x7F0F72288640\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.get_depth_image(xx[...,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m400\u001b[0m, \u001b[1;36m600\u001b[0m\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.setup_renderer(intrinsics, num_layers= 1024)\n",
    "for i,registered_obj in enumerate(registered_objects):\n",
    "    b.RENDERER.add_mesh(registered_obj['mesh'])\n",
    "    # f_p = registered_objects[i][\"full_pose\"]\n",
    "    # registered_objects[i][\"full_pose\"] = f_p.at[2,3].set(f_p[2,3] + 0.5*b.RENDERER.model_box_dims[i][2])\n",
    "if len(registered_objects) == 0:\n",
    "    t_start = gt_images.shape[0]-100\n",
    "    registered_objects.append({'t_init' : gt_images.shape[0]-100,\n",
    "                            'pose' : jnp.eye(4).at[:3,3].set([0,0,1e+5]),\n",
    "                            'full_pose' : jnp.eye(4).at[:3,3].set([0,0,1e+5]),\n",
    "                            't_full' : gt_images.shape[0]-100})\n",
    "    b.RENDERER.add_mesh_from_file(os.path.join(b.utils.get_assets_dir(),\"sample_objs/cube.obj\"), scaling_factor = 0.1)\n",
    "else:\n",
    "    t_start = np.min([x[\"t_init\"] for x in registered_objects])\n",
    "video_from_rendered(gt_images, scale = int(1/SCALE), framerate=30)\n",
    "\n",
    "height, width = intrinsics.height, intrinsics.width\n",
    "starting_indices = all_obj_indices[t_start]\n",
    "if starting_indices is not []:\n",
    "    mean_i, mean_j = np.median(starting_indices[:,0]), np.median(starting_indices[:,1])\n",
    "    from_top = (mean_i < height/2) and (mean_j > mean_i) and (mean_j < width -mean_i)\n",
    "else:\n",
    "    from_top = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model time!\n",
    "\n",
    "def get_height_bounds(i, world_pose):\n",
    "    # Half dimensions to get the corner points relative to the center\n",
    "    rotation_matrix = world_pose[:3,:3]\n",
    "    center = world_pose[:3,3]\n",
    "    dimensions = b.RENDERER.model_box_dims[i]\n",
    "    half_dims = dimensions / 2\n",
    "\n",
    "    # Local corner points of the box in its local coordinate system\n",
    "    local_corners = jnp.array([\n",
    "        [-half_dims[0], -half_dims[1], -half_dims[2]],  # Lower rear left corner\n",
    "        [ half_dims[0], -half_dims[1], -half_dims[2]],  # Lower rear right corner\n",
    "        [-half_dims[0],  half_dims[1], -half_dims[2]],  # Lower front left corner\n",
    "        [ half_dims[0],  half_dims[1], -half_dims[2]],  # Lower front right corner\n",
    "        [-half_dims[0], -half_dims[1],  half_dims[2]],  # Upper rear left corner\n",
    "        [ half_dims[0], -half_dims[1],  half_dims[2]],  # Upper rear right corner\n",
    "        [-half_dims[0],  half_dims[1],  half_dims[2]],  # Upper front left corner\n",
    "        [ half_dims[0],  half_dims[1],  half_dims[2]]   # Upper front right corner\n",
    "    ])\n",
    "\n",
    "    # Apply rotation to each corner point\n",
    "    global_corners = jnp.stack([center + rotation_matrix @ corner for corner in local_corners])\n",
    "\n",
    "    # Find the bottom-most point\n",
    "    bottom_most_point_z = jnp.min(global_corners[:,2])\n",
    "    top_most_point_z = jnp.max(global_corners[:,2])\n",
    "    # distance from centre of bbox to bottom of bbox\n",
    "    center_to_bottom_dist = center[2] - bottom_most_point_z\n",
    "    return bottom_most_point_z,top_most_point_z, center_to_bottom_dist\n",
    "\n",
    "def get_translation_direction(all_poses, t_init,t_full, t):\n",
    "    direction = all_poses[t-1][:3,3] - all_poses[t_full][:3,3]\n",
    "    direction = cam_pose[:3,:3] @ direction\n",
    "    direction_xy = direction.at[2].set(0)\n",
    "\n",
    "    normalized_direction_xy = jax.lax.cond(jnp.equal(jnp.linalg.norm(direction_xy), 0),\n",
    "                                         lambda: direction_xy,\n",
    "                                         lambda: direction_xy/jnp.linalg.norm(direction_xy))\n",
    "    return normalized_direction_xy\n",
    "\n",
    "\n",
    "# This model has to be recompiled for different # objects for now this is okay\n",
    "@genjax.gen\n",
    "def physics_stepper(all_poses, t, t_init, t_full, i, friction, gravity):\n",
    "    # TODO: SAMPLING FRICTION SCHEME --> can be of a hmm style\n",
    "\n",
    "    #################################################################\n",
    "    # First let us consider timestep t-1\n",
    "    #################################################################\n",
    "    # Step 2: find world pose\n",
    "    pose_prev = all_poses[t-1]\n",
    "    pose_prev_world = cam_pose @ pose_prev\n",
    "\n",
    "    # Step 3: check if we are already on the floor\n",
    "    bottom_z, top_z, center_to_bottom = get_height_bounds(i, pose_prev_world)\n",
    "    # within 20% of the object's height in world frame\n",
    "    already_on_floor = jnp.less_equal(bottom_z,0.2 * (top_z - bottom_z))\n",
    "    \n",
    "    # Step 1: Find world velocity\n",
    "    vel_pose_camera = jnp.linalg.solve(all_poses[t-2], all_poses[t-1])\n",
    "    pre_vel_xyz_world = cam_pose[:3,:3] @ vel_pose_camera[:3,3]\n",
    "    mag_xy = jnp.linalg.norm(pre_vel_xyz_world[:2])\n",
    "    \n",
    "    mag_xy_friction = mag_xy - friction * mag_xy\n",
    "\n",
    "    # mag_xy_friction = jax.lax.cond(\n",
    "    #     jnp.less_equal(jnp.abs(mag_xy_friction),3e-3),\n",
    "    #     lambda:0.0,\n",
    "    #     lambda:mag_xy_friction)\n",
    "    \n",
    "    mag_xy, gravity = jax.lax.cond(already_on_floor,lambda:(mag_xy_friction,gravity),lambda:(mag_xy, gravity))\n",
    "\n",
    "    dir_xy_world = get_translation_direction(all_poses, t_init, t_full, t)\n",
    "\n",
    "    # Step 7: Determine mag and gravity\n",
    "\n",
    "    vel_xyz_world = mag_xy * dir_xy_world\n",
    "    # Step 6: apply z axis change\n",
    "    vel_xyz_world = vel_xyz_world.at[2].set(pre_vel_xyz_world[2] - gravity * 1./20)\n",
    "\n",
    "    # Step 5: find peturbed velocity (equal to original norm) with random rotation\n",
    "    perturbed_rot_pose = GaussianVMFPoseUntraced()(jnp.eye(4), *(1e-20, 10000.0))  @ \"perturb\"\n",
    "\n",
    "    vel_xyz_world_perturbed = perturbed_rot_pose[:3,:3] @ vel_xyz_world # without friction\n",
    "\n",
    "    vel_xyz_camera = inverse_cam_pose[:3,:3] @ vel_xyz_world_perturbed\n",
    "\n",
    "    # Step 8: Get velocity update in camera frame\n",
    "    vel = pose_prev.at[:3,3].set(vel_xyz_camera)\n",
    "\n",
    "    # Step 9: Identify next pose\n",
    "    next_pose = pose_prev.at[:3,3].set(pose_prev[:3,3] + vel[:3,3]) # trans only, no rot\n",
    "\n",
    "    # Step 10: Ensure new bottom of object is above floor --> ground collision\n",
    "    next_pose_world = cam_pose @ next_pose\n",
    "    bottom_z,_,center_to_bottom = get_height_bounds(i, next_pose_world)\n",
    "    next_pose = jax.lax.cond(\n",
    "        jnp.less_equal(bottom_z,0),\n",
    "        lambda:inverse_cam_pose @ next_pose_world.at[2,3].set(center_to_bottom),\n",
    "        lambda:next_pose\n",
    "    )\n",
    "\n",
    "    return next_pose\n",
    "\n",
    "def threedp3_likelihood_arijit(\n",
    "    observed_xyz: jnp.ndarray,\n",
    "    rendered_xyz: jnp.ndarray,\n",
    "    variance,\n",
    "    outlier_prob,\n",
    "):\n",
    "    distances = jnp.linalg.norm(observed_xyz - rendered_xyz, axis=-1)\n",
    "    probabilities_per_pixel = (distances < variance/2) / variance\n",
    "    average_probability = 1 * probabilities_per_pixel.mean()\n",
    "    return average_probability\n",
    "\n",
    "threedp3_likelihood_arijit_vmap = jax.vmap(threedp3_likelihood_arijit, in_axes=(None,0,None,None))\n",
    "threedp3_likelihood_arijit_double_vmap = jax.vmap(threedp3_likelihood_arijit, in_axes=(0,0,None,None))\n",
    "\n",
    "def outlier_gaussian(\n",
    "    observed_xyz: jnp.ndarray,\n",
    "    rendered_xyz: jnp.ndarray,\n",
    "    variance,\n",
    "    outlier_prob,\n",
    "):\n",
    "    distances = jnp.linalg.norm(observed_xyz - rendered_xyz, axis=-1)\n",
    "    probabilities_per_pixel = jax.scipy.stats.norm.pdf(\n",
    "        distances,\n",
    "        loc=0.0, \n",
    "        scale=variance\n",
    "    )\n",
    "    average_probability = 0.01 * probabilities_per_pixel.sum()\n",
    "    return average_probability\n",
    "\n",
    "outlier_gaussian_double_vmap = jax.vmap(outlier_gaussian, in_axes=(0,0,None,None))\n",
    "outlier_gaussian_vmap = jax.vmap(outlier_gaussian, in_axes=(None,0,None,None))\n",
    "\n",
    "def outlier_gaussian_per_pixel(\n",
    "    observed_xyz: jnp.ndarray,\n",
    "    rendered_xyz: jnp.ndarray,\n",
    "    variance,\n",
    "    outlier_prob,\n",
    "):\n",
    "    distances = jnp.linalg.norm(observed_xyz - rendered_xyz, axis=-1)\n",
    "    probabilities_per_pixel = jax.scipy.stats.norm.pdf(\n",
    "        distances,\n",
    "        loc=0.0, \n",
    "        scale=variance\n",
    "    )\n",
    "    return 0.01 * probabilities_per_pixel\n",
    "\n",
    "outlier_gaussian_per_pixel_vmap = jax.vmap(outlier_gaussian_per_pixel, in_axes=(None,0,None,None))\n",
    "\n",
    "@dataclass\n",
    "class ImageLikelihoodArijit(ExactDensity):\n",
    "    def sample(self, key, img, variance, outlier_prob):\n",
    "        return img\n",
    "\n",
    "    def logpdf(self, observed_image, latent_image, variance, outlier_prob):\n",
    "        # return threedp3_likelihood_arijit(\n",
    "        #     observed_image, latent_image, variance, outlier_prob,\n",
    "        # )        \n",
    "        return outlier_gaussian(\n",
    "            observed_image, latent_image, variance, outlier_prob,\n",
    "        )\n",
    "    \n",
    "@dataclass\n",
    "class GaussianVMFPoseUntraced(ExactDensity):\n",
    "    def sample(self, key, pose_mean, var, concentration, **kwargs):\n",
    "        return b.distributions.gaussian_vmf(key, pose_mean, var, concentration)\n",
    "\n",
    "    def logpdf(self, pose, pose_mean, var, concentration, **kwargs):\n",
    "        return 0\n",
    "\n",
    "@genjax.gen\n",
    "def mcs_model(prev_state, t_inits, t_fulls, init_poses, full_poses, pose_update_params, variance, outlier_prob):\n",
    "    \"\"\"\n",
    "    Single Object Model HMM\n",
    "    \"\"\"\n",
    "\n",
    "    (_, _, poses, all_poses, friction, t, gravity) = prev_state\n",
    "\n",
    "    # jprint(\"t = {}, f = {}\",t, friction)\n",
    "    num_objects = poses.shape[0]\n",
    "    \n",
    "    # for each object\n",
    "    for i in range(num_objects):        \n",
    "\n",
    "        poses = poses.at[i].set(jax.lax.cond(\n",
    "            jnp.equal(t_fulls[i],t), # full pose at the correct time step\n",
    "            lambda:full_poses[i], \n",
    "            lambda:poses[i]))\n",
    "        \n",
    "        poses = poses.at[i].set(jax.lax.cond(\n",
    "            jnp.equal(t_inits[i],t), # init pose at the correct time step\n",
    "            lambda:init_poses[i], \n",
    "            lambda:poses[i]))\n",
    "\n",
    "        physics_prob = jnp.asarray(jax.lax.cond(jnp.greater_equal(t,t_fulls[i]+2),lambda:1,lambda:0), dtype=int)\n",
    "        physics_pose = physics_stepper(all_poses[:,i,...], t, t_inits[i], t_fulls[i], i, friction, gravity) @ f\"physics_{i}\"\n",
    "        final_pose, update_params = jax.lax.cond(physics_prob, lambda:(physics_pose, pose_update_params), lambda:(poses[i], (jnp.array([1e20,1e20,1e20]), 0.)))\n",
    "                \n",
    "        updated_pose = b.gaussian_vmf_pose(final_pose, *update_params)  @ f\"pose_{i}\"\n",
    "        poses = poses.at[i].set(updated_pose)\n",
    "        \n",
    "    all_poses = all_poses.at[t].set(poses)\n",
    "    rendered_image_obj = b.RENDERER.render(\n",
    "        poses, jnp.arange(num_objects))[...,:3]\n",
    "\n",
    "    # NOTE: gt_images_bg is a global variable here as it consumes too much memory for the trace\n",
    "    rendered_image = splice_image(rendered_image_obj, gt_images_bg[t])\n",
    "\n",
    "    sampled_image = ImageLikelihoodArijit()(rendered_image, variance, outlier_prob) @ \"depth\"\n",
    "    # sampled_image = b.old_image_likelihood(rendered_image, 0.1, 0.001,1000,None) @ \"depth\"\n",
    "\n",
    "    return (rendered_image, rendered_image_obj, poses, all_poses, friction, t+1, gravity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_update_v5(key, trace_, pose_grid, enumerator):\n",
    "    num_splits = (pose_grid.shape[0] // 400) + 1\n",
    "    all_weights = jnp.array([])\n",
    "    for split_pose_grid in jnp.array_split(pose_grid, num_splits):\n",
    "        weights = enumerator.enumerate_choices_get_scores(trace_, key, split_pose_grid)\n",
    "        all_weights = jnp.hstack([all_weights, weights])\n",
    "    sampled_idx = all_weights.argmax() # jax.random.categorical(key, weights)\n",
    "    # jprint(\"weights = {}\",all_weights)\n",
    "    # jprint(\"weight mix:{}\",jnp.unique(jnp.sort(all_weights), size = 10))\n",
    "    # jprint(\"idx chosen = {}\",sampled_idx)\n",
    "    return *enumerator.update_choices_with_weight(\n",
    "        trace_, key,\n",
    "        pose_grid[sampled_idx]\n",
    "    ), pose_grid[sampled_idx]\n",
    "\n",
    "\n",
    "pose_update_v5_jit = jax.jit(pose_update_v5, static_argnames=(\"enumerator\",))\n",
    "\n",
    "\n",
    "def c2f_pose_update_v5(key, trace_, reference, gridding_schedule, enumerator, obj_id,):\n",
    "    # for each object (TODO: gibbs sampling)\n",
    "    for i in range(len(gridding_schedule)):\n",
    "        updated_grid = jnp.einsum(\"ij,ajk->aik\", reference, gridding_schedule[i])\n",
    "        # Time to check valid poses that dont intersect with the floor\n",
    "        valid = jnp.logical_not(are_bboxes_intersecting_many_jit(\n",
    "                            (100,100,20),\n",
    "                            b.RENDERER.model_box_dims[obj_id],\n",
    "                            jnp.eye(4).at[:3,3].set([0,0,-10.1]),\n",
    "                            jnp.einsum(\"ij,ajk->aik\",cam_pose,updated_grid)\n",
    "                            ))\n",
    "        # if pose is not valid, use the reference pose\n",
    "        valid_grid = jnp.where(valid[:,None,None], updated_grid, reference[None,...])\n",
    "        weight, trace_, reference = pose_update_v5_jit(key, trace_, valid_grid, enumerator)\n",
    "        # jprint(\"ref position is {}\", reference[:3,3])\n",
    "\n",
    "    return weight, trace_\n",
    "\n",
    "c2f_pose_update_v5_vmap_jit = jax.jit(jax.vmap(c2f_pose_update_v5, in_axes=(0,0,None,None,None)),\n",
    "                                    static_argnames=(\"enumerator\", \"obj_id\"))\n",
    "\n",
    "c2f_pose_update_v5_jit = jax.jit(c2f_pose_update_v5,static_argnames=(\"enumerator\", \"obj_id\"))\n",
    "\n",
    "def make_new_keys(key, N_keys):\n",
    "    key, other_key = jax.random.split(key)\n",
    "    new_keys = jax.random.split(other_key, N_keys)\n",
    "    return key, new_keys\n",
    "\n",
    "def update_choice_map_no_unfold(gt_depths, constant_choices, t):\n",
    "    constant_choices['depth'] = gt_depths[t]\n",
    "    return genjax.choice_map(\n",
    "                constant_choices\n",
    "            )\n",
    "\n",
    "def argdiffs_modelv7(trace):\n",
    "    \"\"\"\n",
    "    Argdiffs specific to mcs_single_obejct model with no unfold\n",
    "    \"\"\"\n",
    "    args = trace.get_args()\n",
    "    argdiffs = (\n",
    "        jtu.tree_map(lambda v: Diff(v, UnknownChange), args[0]),\n",
    "        *jtu.tree_map(lambda v: Diff(v, NoChange), args[1:]),\n",
    "    )\n",
    "    return argdiffs\n",
    "\n",
    "def proposal_choice_map_no_unfold(addresses, args, chm_args):\n",
    "    addr = addresses[0] # custom defined\n",
    "    return genjax.choice_map({\n",
    "                        addr: args[0]\n",
    "            })\n",
    "\n",
    "def resampling_priority_fn(particles, all_padded_idxs, t, outlier_variance=0.1):\n",
    "    rendered = particles.get_retval()[0]\n",
    "    padded_idxs = all_padded_idxs[t]\n",
    "    max_rows, _ = padded_idxs.shape\n",
    "\n",
    "    # Create a mask for valid indices (not padded)\n",
    "    valid_mask = padded_idxs[:, 0] != -1  # Assuming -1 is the padding value\n",
    "\n",
    "    # Use the mask to select valid indices, replace invalid indices with a default valid index (e.g., 0)\n",
    "    valid_row_indices = jnp.where(valid_mask, padded_idxs[:, 0], 0)\n",
    "    valid_col_indices = jnp.where(valid_mask, padded_idxs[:, 1], 0)\n",
    "\n",
    "    # Gather rendered and ground truth values\n",
    "    rendered_values_at_indices = rendered[:, valid_row_indices, valid_col_indices, 2]\n",
    "    gt_values_at_indices = gt_images[t, valid_row_indices, valid_col_indices, 2]\n",
    "\n",
    "    # Compute inliers, using the mask to ignore the contributions of invalid indices\n",
    "    inliers = jnp.where(valid_mask, jnp.abs(rendered_values_at_indices - gt_values_at_indices[None, ...]) < outlier_variance, False)\n",
    "    inliers_per_particle = jnp.sum(inliers, axis=1)\n",
    "\n",
    "    log_probs = jnp.log(inliers_per_particle + 1e-9)  # Add a small constant to avoid log(0)\n",
    "\n",
    "    eff_ss = ess(normalize_weights(log_probs))\n",
    "\n",
    "    return eff_ss, log_probs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_approach_G2(model, gt, gridding_schedules, model_args, init_state, key, t_start, constant_choices, friction_params, T, addr, n_particles):\n",
    "    \"\"\"\n",
    "    Sequential Importance Sampling on the non-unfolded HMM model\n",
    "    with 3D pose enumeration proposal\n",
    "\n",
    "    WITH JUST ONE PARTICLE\n",
    "    \"\"\"\n",
    "    \n",
    "    num_objects = init_state[2].shape[0]\n",
    "\n",
    "    def get_next_state(particle):\n",
    "        return (None,None,*particle.get_retval()[2:])\n",
    "    get_next_state_vmap = jax.vmap(get_next_state, in_axes = (0,))\n",
    "\n",
    "    # sample friction\n",
    "    key, friction_keys = make_new_keys(key, n_particles)\n",
    "    # frictions = jax.vmap(genjax.normal.sample, in_axes = (0,None,None))(friction_keys,*friction_params)\n",
    "    # frictions = jnp.linspace(-0.03,0.07,n_particles)\n",
    "    qs = jnp.linspace(0.05,0.95,n_particles)\n",
    "    frictions = tfp.distributions.Normal(*friction_params).quantile(qs)\n",
    "    # frictions = frictions.at[n_particles-1].set(0.5)\n",
    "    gravities = jnp.linspace(0.5,2,n_particles)\n",
    "    # broadcast init_state to number of particles\n",
    "    init_states = jax.vmap(lambda f,g:(*init_state[:4], f, init_state[4], g), in_axes=(0,0))(frictions, gravities)\n",
    "\n",
    "    # define functions for SIS/SMC\n",
    "    init_fn = jax.jit(jax.vmap(model.importance, in_axes=(0,None,0)))\n",
    "    update_fn = jax.jit(model.update)\n",
    "    proposal_fn = c2f_pose_update_v5_jit\n",
    "\n",
    "    def smc_body(carry, t):\n",
    "        # get new keys\n",
    "        print(\"jit compiling\")\n",
    "        # initialize particle based on last time step\n",
    "        jprint(\"t = {}\",t)\n",
    "        \n",
    "        key, log_weights, states,  = carry\n",
    "        key, importance_keys = make_new_keys(key, n_particles)\n",
    "        key, resample_key = jax.random.split(key)\n",
    "        key, proposal_key = jax.random.split(key)\n",
    "\n",
    "        variance = jax.lax.cond(\n",
    "            jnp.less_equal(t, model_args[1][0] + 2),\n",
    "            lambda: 1 * model_args[5],\n",
    "            lambda: model_args[5]\n",
    "        )\n",
    "\n",
    "        modified_model_args = (*model_args[:5], variance, *model_args[6:])\n",
    "\n",
    "        full_args = jax.vmap(lambda x,y:(x, *y), in_axes=(0,None))(states, modified_model_args)\n",
    "\n",
    "        importance_log_weights, particles = init_fn(importance_keys, update_choice_map_no_unfold(gt,constant_choices, t), full_args)\n",
    "\n",
    "        # propose good poses based on proposal\n",
    "        def proposer(carry, p):\n",
    "            key, idx = carry\n",
    "            proposal_log_weight = 0\n",
    "            # argdiff and enumerator\n",
    "            argdiffs = argdiffs_modelv7(p)\n",
    "            enumerators = [b.make_enumerator([(addr + f'_{i}')], \n",
    "                                        chm_builder = proposal_choice_map_no_unfold,\n",
    "                                        argdiff_f=lambda x: argdiffs\n",
    "                                        ) for i in range(num_objects)] \n",
    "            for obj_id in range(num_objects):\n",
    "                key, new_key = jax.random.split(key)\n",
    "                reference = jax.lax.cond(jnp.equal(t,model_args[0][obj_id]),\n",
    "                                         lambda:model_args[2][obj_id],\n",
    "                                         lambda:states[2][idx][obj_id])\n",
    "                w, p = proposal_fn(new_key, p, reference, gridding_schedules[obj_id], enumerators[obj_id], obj_id)\n",
    "                proposal_log_weight += w\n",
    "            return (new_key, idx + 1), (proposal_log_weight, p)\n",
    "        _, (proposal_log_weights, particles) = jax.lax.scan(proposer, (proposal_key, 0), particles)\n",
    "\n",
    "        eff_ss, priority_fn_log_probs = resampling_priority_fn(particles, padded_all_obj_indices, t)\n",
    "\n",
    "        # jprint(\"t = {}, ess = {}\", t, eff_ss)\n",
    "\n",
    "        # # Resampling when ess is below threshold\n",
    "        indices = jax.lax.cond(eff_ss <= 0.9*n_particles,\n",
    "                               lambda: jax.random.categorical(resample_key, priority_fn_log_probs, shape=(n_particles,)),\n",
    "                               lambda: jnp.arange(n_particles))\n",
    "        particles = jtu.tree_map(lambda v: v[indices], particles)\n",
    "\n",
    "        # get weights of particles\n",
    "        new_log_weight = log_weights + importance_log_weights\n",
    "        next_states = get_next_state_vmap(particles)\n",
    "\n",
    "        return (key, new_log_weight, next_states), (particles, indices)\n",
    "\n",
    "    (_, final_log_weight, _), (particles, indices) = jax.lax.scan(\n",
    "        smc_body, (key, jnp.zeros(n_particles), init_states), jnp.arange(t_start, T))\n",
    "    rendered = particles.get_retval()[0]\n",
    "    rendered_obj = particles.get_retval()[1]\n",
    "    inferred_poses = particles.get_retval()[2]\n",
    "    print(\"SCAN finished\")\n",
    "    return final_log_weight, rendered, rendered_obj, inferred_poses, particles, indices\n",
    "\n",
    "def reset_renderer():\n",
    "    b.RENDERER = None\n",
    "    b.setup_renderer(intrinsics)\n",
    "    for registered_obj in registered_objects:\n",
    "        b.RENDERER.add_mesh(registered_obj['mesh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumeration grid\n",
    "# TODO: ADAPTIVE GRID SIZING\n",
    "# grid_widths = [1, 0.2,0.04,0.008,0.002,0.0004]\n",
    "# # grid_widths = [0.5, 0.1,0.02]\n",
    "# grid_nums = [(7,7,7),(7,7,7),(7,7,7), (7,7,7), (7,7,7), (7,7,7)]\n",
    "# gridding_schedule_trans = make_schedule_translation_3d(grid_widths, grid_nums)\n",
    "# gridding_schedule_rot = [b.utils.make_rotation_grid_enumeration(10, 15, -jnp.pi/12, jnp.pi/12, jnp.pi/12)]\n",
    "# # gridding_schedule = [gridding_schedule_trans[0], gridding_schedule_trans[1], gridding_schedule_trans[2], gridding_schedule_rot[0]]\n",
    "# gridding_schedule = [gridding_schedule_trans[0], gridding_schedule_trans[1], \n",
    "#                      gridding_schedule_trans[2], gridding_schedule_trans[3],\n",
    "#                      gridding_schedule_trans[4], gridding_schedule_trans[5]]\n",
    "\n",
    "\n",
    "gridding_schedules = []\n",
    "for box_dims in b.RENDERER.model_box_dims:\n",
    "    c2fm1 = 2\n",
    "    c2f0 = 1\n",
    "    c2f1 = 0.35 * c2f0\n",
    "    # c2f1 = 0.7 * c2f0\n",
    "    c2f2 = 0.7 * c2f1\n",
    "    c2f3 = 0.2 * c2f2\n",
    "    c2f4 = 0.2 * c2f3\n",
    "    c2f5 = 0.2 * c2f4\n",
    "    c2f6 = 0.2 * c2f5\n",
    "\n",
    "    c2fs = [c2f0,c2f1,c2f2,c2f3,c2f4]#,c2f5,c2f6] #c2fm1\n",
    "    # c2f0 = 1\n",
    "    # c2f1 = 0.15 * c2f0\n",
    "    # c2f2 = 0.05 * c2f1\n",
    "    # c2f3 = 0.05 * c2f2\n",
    "    # c2fs = [c2f0,c2f1,c2f2,c2f3]\n",
    "\n",
    "    x,y,z = box_dims\n",
    "    grid_widths = [[c2f*x, c2f*y, c2f*z] for c2f in c2fs]\n",
    "\n",
    "    grid_nums = [(13,13,13),(7,7,7),(7,7,7),(7,7,7), (7,7,7)]#,(7,7,7),(7,7,7)]\n",
    "    # grid_nums = [(7,7,7),(5,5,5),(5,5,5), (5,5,5), (5,5,5), (3,3,3), (3,3,3)]\n",
    "    # grid_nums = [(5,5,5),(5,5,5),(5,5,5),(5,5,5), (5,5,5), (5,5,5)]#, (5,5,5), (5,5,5)]\n",
    "    # grid_nums = [(15,15,5), (41,5,5), (41,5,5), (41,5,5)]\n",
    "    gridding_schedule_trans = make_schedule_translation_3d_variable_grid(grid_widths, grid_nums)\n",
    "    gridding_schedules.append(gridding_schedule_trans)\n",
    "\n",
    "# Setup for inference\n",
    "T = gt_images.shape[0]\n",
    "num_registered_objects = len(registered_objects)\n",
    "variance = 0.1\n",
    "INIT_STATE = (\n",
    "        None,\n",
    "        None,\n",
    "        jnp.tile(jnp.eye(4).at[2,3].set(1e+5)[None,...],(num_registered_objects,1,1)),\n",
    "        jnp.zeros((T,num_registered_objects,4,4)),\n",
    "        t_start\n",
    ")\n",
    "MODEL_ARGS = (\n",
    "     jnp.array([r['t_init'] for r in registered_objects]),\n",
    "     jnp.array([r['t_full'] for r in registered_objects]),\n",
    "     jnp.array([r['pose'] for r in registered_objects]),\n",
    "     jnp.array([r['full_pose'] for r in registered_objects]),\n",
    "    #  jnp.array([5e-0, 5e-1]),\n",
    "     (jnp.array([1e-0,1e-0,5e-1]), 5e-1),\n",
    "     variance,\n",
    "     None\n",
    ")\n",
    "CONSTANT_CHOICES = {}\n",
    "\n",
    "if from_top:\n",
    "    friction_params = (0.7,0.1)\n",
    "else:\n",
    "    friction_params = (0.02,0.05)\n",
    "\n",
    "key = jax.random.PRNGKey(np.random.randint(0,2332423432))\n",
    "if from_top:\n",
    "    n_particles = 3\n",
    "else:\n",
    "    n_particles = 30\n",
    "model = mcs_model\n",
    "\n",
    "start = time.time()\n",
    "lw, rendered, rendered_obj, inferred_poses, trace, indices = inference_approach_G2(model, gt_images, \n",
    "    gridding_schedules, MODEL_ARGS, INIT_STATE, key, t_start, CONSTANT_CHOICES,friction_params, T, \"pose\", n_particles)\n",
    "print (\"FPS:\", rendered.shape[0] / (time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scs = trace.score\n",
    "rend_ll = trace.project(genjax.select((\"depth\")))\n",
    "phy_ll = trace.project(genjax.select((\"pose_0\")))\n",
    "worst_rend = outlier_gaussian_double_vmap(gt_images[t_start:], gt_images_bg[t_start:], variance,None)\n",
    "\n",
    "w = trace.project(genjax.select(\"depth\"))\n",
    "offst = 3\n",
    "start = t_start +offst\n",
    "gap = w[offst:].max()-w[offst:].min()\n",
    "\n",
    "max_rend_ll = gt_images.shape[1] * gt_images.shape[2]*jax.scipy.stats.norm.pdf(\n",
    "        0.,\n",
    "        loc=0.0, \n",
    "        scale=variance\n",
    "    ) * 0.01\n",
    "\n",
    "rendering_ll_images = []\n",
    "\n",
    "fig, ax = plt.subplots()  # Using subplots to directly access the figure object\n",
    "lines = []\n",
    "for p_id in range(n_particles):\n",
    "    line = ax.plot(np.arange(start,T),w[offst:], label = f\"Particle {p_id+1}\")[0]\n",
    "    lines.append(line)\n",
    "line = ax.plot(np.array([start]),worst_rend[offst], label = \"Worst\", linestyle = \"--\")[0]\n",
    "lines.append(line)\n",
    "ax.set_xlim([start,T])\n",
    "ax.set_ylim([worst_rend[offst:].min(),max_rend_ll + 0.1*(max_rend_ll - worst_rend[offst:].min())])\n",
    "# ax.set_ylim([w[offst:].min()-0.1*gap,w[offst:].max()+0.1*gap])\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Log Likelihood\")\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "fig.subplots_adjust(right=0.75)\n",
    "fig.canvas.draw()\n",
    "rendering_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "\n",
    "for _ in tqdm(range(0,T)):\n",
    "    rendering_ll_images.append(rendering_ll_img.copy().resize((600,400)))\n",
    "\n",
    "# for t in tqdm(range(start,T)):\n",
    "#     for p_id in range(n_particles):\n",
    "#         lines[p_id].set_data(np.arange(start,t+1),w[:,p_id][offst:offst+t+1-start])\n",
    "#     lines[-1].set_data(np.arange(start,t+1),worst_rend[offst:offst+t+1-start])\n",
    "#     fig.canvas.draw()\n",
    "#     rendering_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "#     rendering_ll_images.append(rendering_ll_img.resize((600,400)))\n",
    "#     plt.close()\n",
    "\n",
    "w = trace.project(genjax.select(\"pose_0\"))\n",
    "offst = 3\n",
    "start = t_start+offst\n",
    "gap = w[offst:].max()-w[offst:].min()\n",
    "\n",
    "physics_ll_images = []\n",
    "\n",
    "fig, ax = plt.subplots()  # Using subplots to directly access the figure object\n",
    "lines = []\n",
    "for p_id in range(n_particles):\n",
    "    line = ax.plot(np.array([start]),w[offst,p_id], label = f\"Particle {p_id+1}\")[0]\n",
    "    lines.append(line)\n",
    "    \n",
    "ax.set_xlim([start,T]) \n",
    "ax.set_ylim([-4.66,-4.57])\n",
    "# ax.set_ylim([w[offst:].min()-0.1*gap, w[offst:].max()+0.1*gap])\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Log Likelihood\")\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "fig.subplots_adjust(right=0.75)\n",
    "fig.canvas.draw()\n",
    "physics_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "\n",
    "for _ in tqdm(range(0,start)):\n",
    "    physics_ll_images.append(physics_ll_img.copy().resize((600,400)))\n",
    "\n",
    "for t in tqdm(range(start,T)):\n",
    "    for p_id in range(n_particles):\n",
    "        lines[p_id].set_data(np.arange(start,t+1),w[:,p_id][offst:offst+t+1-start])\n",
    "    fig.canvas.draw()\n",
    "    physics_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "    physics_ll_images.append(physics_ll_img.resize((600,400)))\n",
    "    plt.close()\n",
    "\n",
    "dummy_poses = np.tile(jnp.eye(4).at[2,3].set(-1e5)[None,None,None,...], (t_start,n_particles,num_registered_objects,1,1))\n",
    "concat_inferred_poses = np.concatenate([dummy_poses, inferred_poses])\n",
    "\n",
    "p_images = get_particle_images(intrinsics_orig, concat_inferred_poses, T = T)\n",
    "blended_images = [b.overlay_image(p_images[i],b.get_depth_image(gt_images_orig[i][...,2])) for i in range(len(p_images))]\n",
    "images = []\n",
    "for t in tqdm(range(T)):\n",
    "    images.append(b.scale_image(b.multi_panel([\n",
    "                b.get_depth_image(gt_images_orig[t,...,2]),\n",
    "                # b.scale_image(b.get_depth_image(rendered[t,particle_id,...,2]),scale),\n",
    "                blended_images[t],\n",
    "                physics_ll_images[t],\n",
    "                rendering_ll_images[t]\n",
    "                # b.scale_image(b.get_depth_image(rendered_obj[t,particle_id,...,2]),3)\n",
    "                ],labels = ['gt/observed', 'particles',\n",
    "                            \"physics likelihood\", \"rendering likelihood\"]), 0.4))\n",
    "display_video(images, framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_plausibility(results, offset = 3, rend_fraction_thresh = 0.75):\n",
    "    # check to see if object is falling from top\n",
    "\n",
    "    T = results['resampled_indices'].shape[0] - offset\n",
    "    tsteps_before_start = results['inferred_poses'].shape[0] - T\n",
    "\n",
    "    height, width = results['intrinsics'].height, results['intrinsics'].width\n",
    "    starting_indices = results['all_obj_indices'][tsteps_before_start - offset]\n",
    "    if starting_indices is not []:\n",
    "        mean_i, mean_j = np.median(starting_indices[:,0]), np.median(starting_indices[:,1])\n",
    "        from_top = (mean_i < height/2) and (mean_j > mean_i) and (mean_j < width -mean_i)\n",
    "    else:\n",
    "        from_top = False\n",
    "\n",
    "    # first get base indices to reflect resampled particles\n",
    "    n_particles = results['resampled_indices'].shape[1]\n",
    "    resample_bools = np.all(results['resampled_indices'] == np.arange(n_particles), axis = 1)\n",
    "    base_indices = np.arange(n_particles)\n",
    "    for i in range(results['resampled_indices'].shape[0]):\n",
    "        base_indices = base_indices[results['resampled_indices'][i]]\n",
    "    # then get the rendering scores based on resampled_indices\n",
    "    rend = np.array(results[\"rend_ll\"][offset:,base_indices])\n",
    "    # get the worst rendered scores (object-less)\n",
    "    WR = results[\"worst_rend\"][offset:]\n",
    "    # flatten rend to get the best vector across time\n",
    "    rend = np.max(rend, axis = 1)\n",
    "\n",
    "    max_rend_possible = height * width * jax.scipy.stats.norm.pdf(\n",
    "        0.,\n",
    "        loc=0.0, \n",
    "        scale=results[\"variance\"]\n",
    "    ) * 0.01\n",
    "\n",
    "    t_violation = None\n",
    "    plausibility_list = [True for _ in range(tsteps_before_start)]\n",
    "    plausible = True\n",
    "    for t in range(T):\n",
    "        if WR[t] > rend[t]:\n",
    "            plausible = False\n",
    "            if t_violation is None:\n",
    "                t_violation = tsteps_before_start + t\n",
    "        if WR[t] < max_rend_possible and WR[t] == rend[t]:\n",
    "            plausible = False\n",
    "            if t_violation is None:\n",
    "                t_violation = tsteps_before_start + t\n",
    "        if from_top and rend[t] > WR[t] and WR[t] >= WR[t-1] and t > T/2 and results['inferred_poses'].shape[0] < 220: # CONSIDER REMOVING THIS HACK\n",
    "            WR_gap = max_rend_possible - WR[t]\n",
    "            rend_gap = max_rend_possible - rend[t]\n",
    "            rend_likelihood_fraction = (WR_gap - rend_gap)/WR_gap\n",
    "            print(t, rend_likelihood_fraction)\n",
    "            if rend_likelihood_fraction < rend_fraction_thresh:\n",
    "                plausible = False\n",
    "                if t_violation is None:\n",
    "                    t_violation = tsteps_before_start + t\n",
    "\n",
    "        plausibility_list.append(plausible)\n",
    "    return plausible, t_violation, plausibility_list, from_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_poses = np.tile(jnp.eye(4).at[2,3].set(-1e5)[None,None,None,...], (t_start,n_particles,num_registered_objects,1,1))\n",
    "concat_inferred_poses = np.concatenate([dummy_poses, inferred_poses])\n",
    "worst_rend = outlier_gaussian_double_vmap(gt_images[t_start:], gt_images_bg[t_start:], variance,None)\n",
    "\n",
    "data = {\"rend_ll\":rend_ll, \"phy_ll\":phy_ll, \"all_obj_indices\" :all_obj_indices,\n",
    "        \"inferred_poses\" : concat_inferred_poses,\n",
    "        \"resampled_indices\" : indices, \"heuristic_poses\" : poses, \"worst_rend\":worst_rend,\n",
    "        \"intrinsics\" : intrinsics, \"variance\" : variance}\n",
    "\n",
    "plausible, t_violation, plausibility_list, _ = determine_plausibility(data, 3,0.75)\n",
    "plausible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.scale_image(b.get_depth_image(rendered[-1,0,...,2]),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.scale_image(b.get_depth_image(gt_images[0+t_start,...,2]),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p_idx = np.argmax(rend_ll[-1])\n",
    "rendered_indices = np.argwhere(np.array(rendered_obj[-1][best_p_idx][...,2]) < intrinsics.far)\n",
    "gt_indices = np.argwhere(np.array(gt_images_obj[best_p_idx][...,2]) < intrinsics.far)\n",
    "\n",
    "rend_depths = rendered_obj[-1][best_p_idx][rendered_indices[:,0],rendered_indices[:,1],2]\n",
    "gt_depths = gt_images_obj[-1][rendered_indices[:,0],rendered_indices[:,1],2]\n",
    "rendered_inliers = np.abs(rend_depths - gt_depths) < 100\n",
    "print(np.sum(rendered_inliers)/rendered_inliers.shape[0])\n",
    "# gt_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rend_ll = trace.project(genjax.select((\"depth\")))\n",
    "best_p_idx = np.argmax(rend_ll[-1])\n",
    "vars = []\n",
    "fracs = []\n",
    "for var in np.linspace(0.1,1,100):\n",
    "    xx1 = threedp3_likelihood_arijit(gt_images[-1],gt_images[-1],var,None)\n",
    "    xx2 = threedp3_likelihood_arijit(gt_images[-1],rendered[-1][best_p_idx],var,None)\n",
    "    xx3 = threedp3_likelihood_arijit(gt_images[-1],gt_images_bg[-1],var,None)\n",
    "    frac = (xx2-xx3)/(xx1-xx3)\n",
    "    vars.append(var)\n",
    "    fracs.append(frac)\n",
    "\n",
    "plt.plot(vars,fracs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fracs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splice_image_double_vmap = jax.vmap(splice_image, in_axes = (0,0))\n",
    "rend_scores = []\n",
    "for p_id in tqdm(range(n_particles)):\n",
    "    # new_rendered_unspliced = b.RENDERER.render_many(inferred_poses[:,p_id,...], jnp.arange(num_registered_objects))[...,:3]\n",
    "    # new_rendered = splice_image_double_vmap(new_rendered_unspliced, gt_images_bg[t_start:])\n",
    "    scores = outlier_gaussian_double_vmap(gt_images[t_start:], gt_images_bg[t_start:], 0.1,None)\n",
    "    rend_scores.append(np.array(scores))\n",
    "rend_scores = np.stack(rend_scores).T\n",
    "rend_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_rend = outlier_gaussian_double_vmap(gt_images[t_start:], gt_images_bg[t_start:], 0.1,None)\n",
    "min_rend = worst_rend.min()\n",
    "for i in range(n_particles):\n",
    "    plt.plot(rend_ll[3:,i])\n",
    "plt.plot(worst_rend[3:], linestyle=\"--\")\n",
    "plt.ylim([min_rend, 95.75]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnge = range(t_start,t_start+40)\n",
    "\n",
    "for p_id in range(n_particles):\n",
    "    if p_id > -1:\n",
    "        xs = np.array([(cam_pose @ concat_inferred_poses[i,p_id,0])[0,3] for i in rnge])\n",
    "        ys = np.array([(cam_pose @ concat_inferred_poses[i,p_id,0])[1,3] for i in rnge])\n",
    "        plt.plot(xs,ys, marker = 'o', label = f\"p_{p_id}\")\n",
    "        # plt.scatter(xs[-1],ys[-1])\n",
    "\n",
    "nxs = []\n",
    "nys = []\n",
    "for i in rnge:\n",
    "    if len(poses[i]) > 0:\n",
    "        nxs.append((cam_pose @ poses[i][0])[0,3])\n",
    "        nys.append((cam_pose @ poses[i][0])[1,3])\n",
    "# xs = [(cam_pose @ poses[i][0])[0,3] for i in range(134,141)]\n",
    "# ys = [(cam_pose @ poses[i][0])[1,3] for i in range(134,141)]\n",
    "plt.plot(nxs,nys, marker = 'x')\n",
    "# plt.ylim(ys.min(),ys.max())\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.RENDERER.model_box_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [(cam_pose @ poses[i][0])[0,3] for i in range(134,141)]\n",
    "ys = [(cam_pose @ poses[i][0])[1,3] for i in range(134,141)]\n",
    "plt.plot(xs,ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = 204\n",
    "display(rend_ll[tt-134])\n",
    "display(phy_ll[tt-134])\n",
    "display(scs[tt-134])\n",
    "display(rend_ll[tt-134] + phy_ll[tt-134])\n",
    "concat_inferred_poses[tt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.scale_image(b.get_depth_image(imm[...,2]),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.overlay_image(b.scale_image(b.get_depth_image(imm_unspliced[...,2]),5), b.scale_image(b.get_depth_image(imm[...,2]),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.sum(jnp.linalg.norm(gt_images[123] - gt_images_bg[123], axis=-1) < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "# def splice_image(rendered_object_image, obs_image_complement, far=150.0):\n",
    "#     keep_masks = jnp.logical_or(\n",
    "#         jnp.logical_and((rendered_object_image[...,2] <= obs_image_complement[..., 2]) * \n",
    "#         rendered_object_image[...,2] > 0.0, (obs_image_complement[...,2] >= far))\n",
    "#         ,\n",
    "#         (obs_image_complement[...,2] == 0)\n",
    "#     )[...,None]\n",
    "#     rendered_images = keep_masks * rendered_object_image + (1.0 - keep_masks) * obs_image_complement\n",
    "#     return rendered_images, keep_masks\n",
    "imm_unspliced = b.RENDERER.render(inferred_poses[-1,0], jnp.array([0]))[...,:3]\n",
    "imm,k = splice_image(imm_unspliced, gt_images_bg[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridding_schedules = []\n",
    "for box_dims in b.RENDERER.model_box_dims:\n",
    "    c2fm1 = 2\n",
    "    c2f0 = 1\n",
    "    c2f1 = 0.35 * c2f0\n",
    "    # c2f1 = 0.7 * c2f0\n",
    "    c2f2 = 0.7 * c2f1\n",
    "    c2f3 = 0.2 * c2f2\n",
    "    c2f4 = 0.2 * c2f3\n",
    "    c2f5 = 0.2 * c2f4\n",
    "    c2f6 = 0.2 * c2f5\n",
    "\n",
    "    c2fs = [c2f0,c2f1,c2f2,c2f3,c2f4]#,c2f5,c2f6] #c2fm1\n",
    "    # c2f0 = 1\n",
    "    # c2f1 = 0.15 * c2f0\n",
    "    # c2f2 = 0.05 * c2f1\n",
    "    # c2f3 = 0.05 * c2f2\n",
    "    # c2fs = [c2f0,c2f1,c2f2,c2f3]\n",
    "\n",
    "    x,y,z = box_dims\n",
    "    grid_widths = [[c2f*x, c2f*y, c2f*z] for c2f in c2fs]\n",
    "\n",
    "    grid_nums = [(13,13,13),(7,7,7),(7,7,7),(7,7,7), (7,7,7)]#,(7,7,7),(7,7,7)]\n",
    "    # grid_nums = [(7,7,7),(5,5,5),(5,5,5), (5,5,5), (5,5,5), (3,3,3), (3,3,3)]\n",
    "    # grid_nums = [(5,5,5),(5,5,5),(5,5,5),(5,5,5), (5,5,5), (5,5,5)]#, (5,5,5), (5,5,5)]\n",
    "    # grid_nums = [(15,15,5), (41,5,5), (41,5,5), (41,5,5)]\n",
    "    gridding_schedule_trans = make_schedule_translation_3d_variable_grid(grid_widths, grid_nums)\n",
    "    gridding_schedules.append(gridding_schedule_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_poses = np.tile(jnp.eye(4).at[2,3].set(-1e5)[None,None,None,...], (t_start,n_particles,num_registered_objects,1,1))\n",
    "concat_inferred_poses = np.concatenate([dummy_poses, inferred_poses])\n",
    "\n",
    "# test for bad init\n",
    "tt = 93 # registered_objects[0]['t_full'] + 2\n",
    "# reference = concat_inferred_poses[tt][0,0]\n",
    "# reference = registered_objects[0]['pose']\n",
    "print(\"original \",(cam_pose @ reference)[:3,3])\n",
    "next_t_step = tt+1\n",
    "obs = gt_images[next_t_step]\n",
    "c2f_imgs = []\n",
    "\n",
    "\n",
    "orig_img = b.RENDERER.render(reference[None,...], jnp.array([0]))[...,:3]\n",
    "xxx_orig = splice_image(orig_img, gt_images_bg[next_t_step])\n",
    "c2f_imgs.append(b.scale_image(b.get_depth_image(xxx_orig[...,2]),5))\n",
    "\n",
    "for i in range(len(gridding_schedules[0])):\n",
    "    updated_grid = jnp.einsum(\"ij,ajk->aik\", reference, gridding_schedules[0][i])\n",
    "\n",
    "    valid = jnp.logical_not(are_bboxes_intersecting_many_jit(\n",
    "                        (100,100,20),\n",
    "                        b.RENDERER.model_box_dims[0],\n",
    "                        jnp.eye(4).at[:3,3].set([0,0,-10.1]),\n",
    "                        jnp.einsum(\"ij,ajk->aik\",cam_pose,updated_grid)\n",
    "                        ))\n",
    "    \n",
    "    # if pose is not valid, use the reference pose\n",
    "    updated_grid = jnp.where(valid[:,None,None], updated_grid, reference[None,...])\n",
    "\n",
    "\n",
    "\n",
    "    imgs = b.RENDERER.render_many(updated_grid[:,None,...], jnp.array([0]))[...,:3]\n",
    "    rendered_images = splice_image_vmap(imgs, gt_images_bg[next_t_step])\n",
    "    scores = outlier_gaussian_vmap(obs, rendered_images, 1,None)\n",
    "    if i == 0:\n",
    "        print(scores)\n",
    "    idx = scores.argmax()\n",
    "    reference = updated_grid[idx]\n",
    "    print((cam_pose @ reference)[:3,3])\n",
    "    c2f_imgs.append(b.scale_image(b.get_depth_image(rendered_images[idx,...,2]),5))\n",
    "    print(scores.argmax())\n",
    "for x in c2f_imgs:\n",
    "    display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.scale_image(b.get_depth_image(rendered[-1,0,...,2]),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.RENDERER.meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ref = reference.at[1,3].set(reference[1,3] + 2)\n",
    "orig_img = b.RENDERER.render(new_ref[None,...], jnp.array([0]))[...,:3]\n",
    "xxx_orig = splice_image(orig_img, gt_images_bg[next_t_step])\n",
    "b.scale_image(b.get_depth_image(xxx_orig[...,2]),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_gaussian(gt_images[-1], gt_images[-1],1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_gaussian(gt_images[-1], gt_images[-1].at[55,75,2].set(gt_images[-1][55,75,2] + 0.01),1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obj_indices[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high memory usage !!!####\n",
    "\n",
    "# b.setup_renderer(intrinsics_orig, num_layers= 1024)\n",
    "# for i,registered_obj in enumerate(registered_objects):\n",
    "#     b.RENDERER.add_mesh(registered_obj['mesh'])\n",
    "# if len(registered_objects) == 0:\n",
    "#     b.RENDERER.add_mesh_from_file(os.path.join(b.utils.get_assets_dir(),\"sample_objs/cube.obj\"), scaling_factor = 0.1)\n",
    "\n",
    "# splice_image_double_vmap = jax.vmap(splice_image, in_axes = (0,0))\n",
    "# rend_scores = []\n",
    "# for p_id in tqdm(range(n_particles)):\n",
    "#     new_rendered_unspliced = b.RENDERER.render_many(inferred_poses[:,p_id,...], jnp.arange(num_registered_objects))[...,:3]\n",
    "#     new_rendered = splice_image_double_vmap(new_rendered_unspliced, gt_images_bg_orig[t_start:])\n",
    "#     scores = threedp3_likelihood_arijit_double_vmap(gt_images_orig[t_start:], new_rendered, 0.1,None)\n",
    "#     rend_scores.append(np.array(scores))\n",
    "# rend_scores = np.stack(rend_scores).T\n",
    "# rend_scores.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
