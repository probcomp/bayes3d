{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jax\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import genjax\n",
    "import bayes3d as b\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../\")\n",
    "from viz import *\n",
    "from utils import *\n",
    "from mcs_utils import *\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import bayes3d.transforms_3d as t3d\n",
    "from jax.debug import print as jprint\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from genjax._src.core.pytree.utilities import *\n",
    "from genjax.generative_functions.distributions import ExactDensity\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "import jax.tree_util as jtu\n",
    "from genjax._src.core.transforms.incremental import NoChange, UnknownChange, Diff\n",
    "console = genjax.pretty()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and preprocessing all data and renderer\n",
    "# SCALE = 0.2\n",
    "cam_pose = CAM_POSE_CV2\n",
    "inverse_cam_pose = jnp.linalg.inv(CAM_POSE_CV2)\n",
    "scene_name = 'passive_physics_validation_spatio_temporal_continuity_0001_01'\n",
    "with open(f\"/home/arijitdasgupta/bayes3d/scripts/experiments/intphys/mcs/pickled_data/{scene_name}.pkl\", 'rb') as file:\n",
    "    preprocessed_data = pickle.load(file)\n",
    "# observations = load_observations_npz(scene_name)\n",
    "# preprocessed_data = preprocess_mcs_physics_scene(observations, MIN_DIST_THRESH=0.6, scale=SCALE)\n",
    "(gt_images, gt_images_bg, gt_images_obj, intrinsics),\\\n",
    "(gt_images_orig, gt_images_bg_orig, gt_images_obj_orig, intrinsics_orig),\\\n",
    "registered_objects, obj_pixels, is_gravity, poses = preprocessed_data\n",
    "\n",
    "# get obj indices padded\n",
    "all_obj_indices = [np.argwhere(gt_images_obj[i,...,2] != intrinsics.far) for i in range(gt_images.shape[0])]\n",
    "max_rows = max(obj_indices.shape[0] for obj_indices in all_obj_indices)\n",
    "def pad_array(array, max_rows):\n",
    "    padding = ((0, max_rows - array.shape[0]), (0, 0))  # Pad rows, not columns\n",
    "    return jnp.pad(array, padding, constant_values=-1)\n",
    "\n",
    "padded_all_obj_indices = jnp.stack([pad_array(array, max_rows) for array in all_obj_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.setup_renderer(intrinsics, num_layers= 1024)\n",
    "for i,registered_obj in enumerate(registered_objects):\n",
    "    b.RENDERER.add_mesh(registered_obj['mesh'])\n",
    "    f_p = registered_objects[i][\"full_pose\"]\n",
    "    registered_objects[i][\"full_pose\"] = f_p.at[2,3].set(f_p[2,3] + 0.5*b.RENDERER.model_box_dims[i][2])\n",
    "if len(registered_objects) == 0:\n",
    "    t_start = 0\n",
    "    registered_objects.append({'t_init' : 11,\n",
    "                            'pose' : jnp.eye(4).at[:3,3].set([0,0,1e+5]),\n",
    "                            'full_pose' : jnp.eye(4).at[:3,3].set([0,0,1e+5]),\n",
    "                            't_full' : 11})\n",
    "    b.RENDERER.add_mesh_from_file(os.path.join(b.utils.get_assets_dir(),\"sample_objs/cube.obj\"), scaling_factor = 0.1)\n",
    "else:\n",
    "    t_start = np.min([x[\"t_full\"] for x in registered_objects])\n",
    "# video_from_rendered(gt_images, scale = int(1/SCALE), framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model time!\n",
    "\n",
    "def get_height_bounds(i, world_pose):\n",
    "    # Half dimensions to get the corner points relative to the center\n",
    "    rotation_matrix = world_pose[:3,:3]\n",
    "    center = world_pose[:3,3]\n",
    "    dimensions = b.RENDERER.model_box_dims[i]\n",
    "    half_dims = dimensions / 2\n",
    "\n",
    "    # Local corner points of the box in its local coordinate system\n",
    "    local_corners = jnp.array([\n",
    "        [-half_dims[0], -half_dims[1], -half_dims[2]],  # Lower rear left corner\n",
    "        [ half_dims[0], -half_dims[1], -half_dims[2]],  # Lower rear right corner\n",
    "        [-half_dims[0],  half_dims[1], -half_dims[2]],  # Lower front left corner\n",
    "        [ half_dims[0],  half_dims[1], -half_dims[2]],  # Lower front right corner\n",
    "        [-half_dims[0], -half_dims[1],  half_dims[2]],  # Upper rear left corner\n",
    "        [ half_dims[0], -half_dims[1],  half_dims[2]],  # Upper rear right corner\n",
    "        [-half_dims[0],  half_dims[1],  half_dims[2]],  # Upper front left corner\n",
    "        [ half_dims[0],  half_dims[1],  half_dims[2]]   # Upper front right corner\n",
    "    ])\n",
    "\n",
    "    # Apply rotation to each corner point\n",
    "    global_corners = jnp.stack([center + rotation_matrix @ corner for corner in local_corners])\n",
    "\n",
    "    # Find the bottom-most point\n",
    "    bottom_most_point_z = jnp.min(global_corners[:,2])\n",
    "    top_most_point_z = jnp.max(global_corners[:,2])\n",
    "    # distance from centre of bbox to bottom of bbox\n",
    "    center_to_bottom_dist = center[2] - bottom_most_point_z\n",
    "    return bottom_most_point_z,top_most_point_z, center_to_bottom_dist\n",
    "\n",
    "def get_translation_direction(all_poses, t_full, t):\n",
    "    direction = all_poses[t-1][:3,3] - all_poses[t_full+1][:3,3]\n",
    "    direction = cam_pose[:3,:3] @ direction\n",
    "    direction_xy = direction.at[2].set(0)\n",
    "\n",
    "    normalized_direction_xy = jax.lax.cond(jnp.equal(jnp.linalg.norm(direction_xy), 0),\n",
    "                                         lambda: direction_xy,\n",
    "                                         lambda: direction_xy/jnp.linalg.norm(direction_xy))\n",
    "    return normalized_direction_xy\n",
    "\n",
    "\n",
    "# This model has to be recompiled for different # objects for now this is okay\n",
    "@genjax.gen\n",
    "def physics_stepper(all_poses, t, t_full, i, friction, gravity):\n",
    "    # TODO: SAMPLING FRICTION SCHEME --> can be of a hmm style\n",
    "\n",
    "    #################################################################\n",
    "    # First let us consider timestep t-1\n",
    "    #################################################################\n",
    "    # Step 2: find world pose\n",
    "    pose_prev = all_poses[t-1]\n",
    "    pose_prev_world = cam_pose @ pose_prev\n",
    "\n",
    "    # Step 3: check if we are already on the floor\n",
    "    bottom_z, top_z, center_to_bottom = get_height_bounds(i, pose_prev_world)\n",
    "    # within 20% of the object's height in world frame\n",
    "    already_on_floor = jnp.less_equal(bottom_z,0.2 * (top_z - bottom_z))\n",
    "    \n",
    "    # Step 1: Find world velocity\n",
    "    vel_pose_camera = jnp.linalg.solve(all_poses[t-2], all_poses[t-1])\n",
    "    pre_vel_xyz_world = cam_pose[:3,:3] @ vel_pose_camera[:3,3]\n",
    "    mag_xy = jnp.linalg.norm(pre_vel_xyz_world[:2])\n",
    "    \n",
    "    mag_xy_friction = mag_xy - friction * mag_xy\n",
    "\n",
    "    # mag_xy_friction = jax.lax.cond(\n",
    "    #     jnp.less_equal(jnp.abs(mag_xy_friction),3e-3),\n",
    "    #     lambda:0.0,\n",
    "    #     lambda:mag_xy_friction)\n",
    "    \n",
    "    mag_xy, gravity = jax.lax.cond(already_on_floor,lambda:(mag_xy_friction,gravity),lambda:(mag_xy, gravity))\n",
    "\n",
    "    dir_xy_world = get_translation_direction(all_poses, t_full, t)\n",
    "\n",
    "    # Step 7: Determine mag and gravity\n",
    "\n",
    "    vel_xyz_world = mag_xy * dir_xy_world\n",
    "    # Step 6: apply z axis change\n",
    "    vel_xyz_world = vel_xyz_world.at[2].set(pre_vel_xyz_world[2] - gravity * 1./20)\n",
    "\n",
    "    # Step 5: find peturbed velocity (equal to original norm) with random rotation\n",
    "    perturbed_rot_pose = GaussianVMFPoseUntraced()(jnp.eye(4), *(1e-20, 10000.0))  @ \"perturb\"\n",
    "\n",
    "    vel_xyz_world_perturbed = perturbed_rot_pose[:3,:3] @ vel_xyz_world # without friction\n",
    "\n",
    "    vel_xyz_camera = inverse_cam_pose[:3,:3] @ vel_xyz_world_perturbed\n",
    "\n",
    "    # Step 8: Get velocity update in camera frame\n",
    "    vel = pose_prev.at[:3,3].set(vel_xyz_camera)\n",
    "\n",
    "    # Step 9: Identify next pose\n",
    "    next_pose = pose_prev.at[:3,3].set(pose_prev[:3,3] + vel[:3,3]) # trans only, no rot\n",
    "\n",
    "    # Step 10: Ensure new bottom of object is above floor --> ground collision\n",
    "    next_pose_world = cam_pose @ next_pose\n",
    "    bottom_z,_,center_to_bottom = get_height_bounds(i, next_pose_world)\n",
    "    next_pose = jax.lax.cond(\n",
    "        jnp.less_equal(bottom_z,0),\n",
    "        lambda:inverse_cam_pose @ next_pose_world.at[2,3].set(center_to_bottom),\n",
    "        lambda:next_pose\n",
    "    )\n",
    "\n",
    "    return next_pose\n",
    "\n",
    "def threedp3_likelihood_arijit(\n",
    "    observed_xyz: jnp.ndarray,\n",
    "    rendered_xyz: jnp.ndarray,\n",
    "    variance,\n",
    "    outlier_prob,\n",
    "):\n",
    "    distances = jnp.linalg.norm(observed_xyz - rendered_xyz, axis=-1)\n",
    "    probabilities_per_pixel = (distances < variance/2) / variance\n",
    "    average_probability = 1 * probabilities_per_pixel.mean()\n",
    "    return average_probability\n",
    "\n",
    "threedp3_likelihood_arijit_vmap = jax.vmap(threedp3_likelihood_arijit, in_axes=(None,0,None,None))\n",
    "threedp3_likelihood_arijit_double_vmap = jax.vmap(threedp3_likelihood_arijit, in_axes=(0,0,None,None))\n",
    "\n",
    "def outlier_gaussian(\n",
    "    observed_xyz: jnp.ndarray,\n",
    "    rendered_xyz: jnp.ndarray,\n",
    "    variance,\n",
    "    outlier_prob,\n",
    "):\n",
    "    distances = jnp.linalg.norm(observed_xyz - rendered_xyz, axis=-1)\n",
    "    probabilities_per_pixel = jax.scipy.stats.norm.pdf(\n",
    "        distances,\n",
    "        loc=0.0, \n",
    "        scale=variance\n",
    "    )\n",
    "    average_probability = 0.01 * probabilities_per_pixel.sum()\n",
    "    return average_probability\n",
    "\n",
    "outlier_gaussian_double_vmap = jax.vmap(outlier_gaussian, in_axes=(0,0,None,None))\n",
    "\n",
    "@dataclass\n",
    "class ImageLikelihoodArijit(ExactDensity):\n",
    "    def sample(self, key, img, variance, outlier_prob):\n",
    "        return img\n",
    "\n",
    "    def logpdf(self, observed_image, latent_image, variance, outlier_prob):\n",
    "        # return threedp3_likelihood_arijit(\n",
    "        #     observed_image, latent_image, variance, outlier_prob,\n",
    "        # )        \n",
    "        return outlier_gaussian(\n",
    "            observed_image, latent_image, variance, outlier_prob,\n",
    "        )\n",
    "    \n",
    "@dataclass\n",
    "class GaussianVMFPoseUntraced(ExactDensity):\n",
    "    def sample(self, key, pose_mean, var, concentration, **kwargs):\n",
    "        return b.distributions.gaussian_vmf(key, pose_mean, var, concentration)\n",
    "\n",
    "    def logpdf(self, pose, pose_mean, var, concentration, **kwargs):\n",
    "        return 0\n",
    "\n",
    "@genjax.gen\n",
    "def mcs_model(prev_state, t_inits, t_fulls, init_poses, full_poses, pose_update_params, variance, outlier_prob):\n",
    "    \"\"\"\n",
    "    Single Object Model HMM\n",
    "    \"\"\"\n",
    "\n",
    "    (_, _, poses, all_poses, friction, t, gravity) = prev_state\n",
    "\n",
    "    # jprint(\"t = {}, f = {}\",t, friction)\n",
    "    num_objects = poses.shape[0]\n",
    "    \n",
    "    # for each object\n",
    "    for i in range(num_objects):        \n",
    "\n",
    "        poses = poses.at[i].set(jax.lax.cond(\n",
    "            jnp.equal(t_fulls[i],t), # full pose at the correct time step\n",
    "            lambda:full_poses[i], \n",
    "            lambda:poses[i]))\n",
    "        \n",
    "        poses = poses.at[i].set(jax.lax.cond(\n",
    "            jnp.equal(t_inits[i],t), # init pose at the correct time step\n",
    "            lambda:init_poses[i], \n",
    "            lambda:poses[i]))\n",
    "\n",
    "        physics_prob = jnp.asarray(jax.lax.cond(jnp.greater_equal(t,t_fulls[i]+2),lambda:1,lambda:0), dtype=int)\n",
    "        physics_pose = physics_stepper(all_poses[:,i,...], t, t_fulls[i], i, friction, gravity) @ f\"physics_{i}\"\n",
    "        final_pose, update_params = jax.lax.cond(physics_prob, lambda:(physics_pose, pose_update_params), lambda:(poses[i], (jnp.array([1e20,1e20,1e20]), 0.)))\n",
    "                \n",
    "        updated_pose = b.gaussian_vmf_pose(final_pose, *update_params)  @ f\"pose_{i}\"\n",
    "        poses = poses.at[i].set(updated_pose)\n",
    "        \n",
    "    all_poses = all_poses.at[t].set(poses)\n",
    "    rendered_image_obj = b.RENDERER.render(\n",
    "        poses, jnp.arange(num_objects))[...,:3]\n",
    "\n",
    "    # NOTE: gt_images_bg is a global variable here as it consumes too much memory for the trace\n",
    "    rendered_image = splice_image(rendered_image_obj, gt_images_bg[t])\n",
    "\n",
    "    sampled_image = ImageLikelihoodArijit()(rendered_image, variance, outlier_prob) @ \"depth\"\n",
    "    # sampled_image = b.old_image_likelihood(rendered_image, 0.1, 0.001,1000,None) @ \"depth\"\n",
    "\n",
    "    return (rendered_image, rendered_image_obj, poses, all_poses, friction, t+1, gravity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_update_v5(key, trace_, pose_grid, enumerator):\n",
    "    num_splits = (pose_grid.shape[0] // 400) + 1\n",
    "    all_weights = jnp.array([])\n",
    "    for split_pose_grid in jnp.array_split(pose_grid, num_splits):\n",
    "        weights = enumerator.enumerate_choices_get_scores(trace_, key, split_pose_grid)\n",
    "        all_weights = jnp.hstack([all_weights, weights])\n",
    "    sampled_idx = all_weights.argmax() # jax.random.categorical(key, weights)\n",
    "    # jprint(\"weights = {}\",all_weights)\n",
    "    # jprint(\"weight mix:{}\",jnp.unique(jnp.sort(all_weights), size = 10))\n",
    "    # jprint(\"idx chosen = {}\",sampled_idx)\n",
    "    return *enumerator.update_choices_with_weight(\n",
    "        trace_, key,\n",
    "        pose_grid[sampled_idx]\n",
    "    ), pose_grid[sampled_idx]\n",
    "\n",
    "\n",
    "pose_update_v5_jit = jax.jit(pose_update_v5, static_argnames=(\"enumerator\",))\n",
    "\n",
    "\n",
    "def c2f_pose_update_v5(key, trace_, reference, gridding_schedule, enumerator, obj_id):\n",
    "    # for each object (TODO: gibbs sampling)\n",
    "    for i in range(len(gridding_schedule)):\n",
    "        updated_grid = jnp.einsum(\"ij,ajk->aik\", reference, gridding_schedule[i])\n",
    "        # Time to check valid poses that dont intersect with the floor\n",
    "        valid = jnp.logical_not(are_bboxes_intersecting_many_jit(\n",
    "                            (100,100,20),\n",
    "                            b.RENDERER.model_box_dims[obj_id],\n",
    "                            jnp.eye(4).at[:3,3].set([0,0,-10]),\n",
    "                            jnp.einsum(\"ij,ajk->aik\",cam_pose,updated_grid)\n",
    "                            ))\n",
    "        # if pose is not valid, use the reference pose\n",
    "        valid_grid = jnp.where(valid[:,None,None], updated_grid, reference[None,...])\n",
    "        weight, trace_, reference = pose_update_v5_jit(key, trace_, valid_grid, enumerator)\n",
    "        # jprint(\"ref position is {}\", reference[:3,3])\n",
    "\n",
    "    return weight, trace_\n",
    "\n",
    "c2f_pose_update_v5_vmap_jit = jax.jit(jax.vmap(c2f_pose_update_v5, in_axes=(0,0,None,None,None)),\n",
    "                                    static_argnames=(\"enumerator\", \"obj_id\"))\n",
    "\n",
    "c2f_pose_update_v5_jit = jax.jit(c2f_pose_update_v5,static_argnames=(\"enumerator\", \"obj_id\"))\n",
    "\n",
    "def make_new_keys(key, N_keys):\n",
    "    key, other_key = jax.random.split(key)\n",
    "    new_keys = jax.random.split(other_key, N_keys)\n",
    "    return key, new_keys\n",
    "\n",
    "def update_choice_map_no_unfold(gt_depths, constant_choices, t):\n",
    "    constant_choices['depth'] = gt_depths[t]\n",
    "    return genjax.choice_map(\n",
    "                constant_choices\n",
    "            )\n",
    "\n",
    "\n",
    "def argdiffs_modelv7(trace):\n",
    "    \"\"\"\n",
    "    Argdiffs specific to mcs_single_obejct model with no unfold\n",
    "    \"\"\"\n",
    "    args = trace.get_args()\n",
    "    argdiffs = (\n",
    "        jtu.tree_map(lambda v: Diff(v, UnknownChange), args[0]),\n",
    "        *jtu.tree_map(lambda v: Diff(v, NoChange), args[1:]),\n",
    "    )\n",
    "    return argdiffs\n",
    "\n",
    "\n",
    "\n",
    "def proposal_choice_map_no_unfold(addresses, args, chm_args):\n",
    "    addr = addresses[0] # custom defined\n",
    "    return genjax.choice_map({\n",
    "                        addr: args[0]\n",
    "            })\n",
    "\n",
    "def resampling_priority_fn(particles, all_padded_idxs, t, outlier_variance=0.1):\n",
    "    rendered = particles.get_retval()[0]\n",
    "    padded_idxs = all_padded_idxs[t]\n",
    "    max_rows, _ = padded_idxs.shape\n",
    "\n",
    "    # Create a mask for valid indices (not padded)\n",
    "    valid_mask = padded_idxs[:, 0] != -1  # Assuming -1 is the padding value\n",
    "\n",
    "    # Use the mask to select valid indices, replace invalid indices with a default valid index (e.g., 0)\n",
    "    valid_row_indices = jnp.where(valid_mask, padded_idxs[:, 0], 0)\n",
    "    valid_col_indices = jnp.where(valid_mask, padded_idxs[:, 1], 0)\n",
    "\n",
    "    # Gather rendered and ground truth values\n",
    "    rendered_values_at_indices = rendered[:, valid_row_indices, valid_col_indices, 2]\n",
    "    gt_values_at_indices = gt_images[t, valid_row_indices, valid_col_indices, 2]\n",
    "\n",
    "    # Compute inliers, using the mask to ignore the contributions of invalid indices\n",
    "    inliers = jnp.where(valid_mask, jnp.abs(rendered_values_at_indices - gt_values_at_indices[None, ...]) < outlier_variance, False)\n",
    "    inliers_per_particle = jnp.sum(inliers, axis=1)\n",
    "\n",
    "    log_probs = jnp.log(inliers_per_particle + 1e-9)  # Add a small constant to avoid log(0)\n",
    "\n",
    "    eff_ss = ess(normalize_weights(log_probs))\n",
    "\n",
    "    return eff_ss, log_probs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_approach_G2(model, gt, gridding_schedules, model_args, init_state, key, t_start, constant_choices, T, addr, n_particles):\n",
    "    \"\"\"\n",
    "    Sequential Importance Sampling on the non-unfolded HMM model\n",
    "    with 3D pose enumeration proposal\n",
    "\n",
    "    WITH JUST ONE PARTICLE\n",
    "    \"\"\"\n",
    "    \n",
    "    num_objects = init_state[2].shape[0]\n",
    "\n",
    "    def get_next_state(particle):\n",
    "        return (None,None,*particle.get_retval()[2:])\n",
    "    get_next_state_vmap = jax.vmap(get_next_state, in_axes = (0,))\n",
    "\n",
    "    # sample friction\n",
    "    key, friction_keys = make_new_keys(key, n_particles)\n",
    "    # frictions = jax.vmap(genjax.normal.sample, in_axes = (0,None,None))(friction_keys,*friction_params)\n",
    "    # frictions = jnp.linspace(-0.03,0.07,n_particles)\n",
    "    qs = jnp.linspace(0.05,0.95,30)\n",
    "    frictions = tfp.distributions.Normal(0.02,0.05).quantile(qs)\n",
    "    gravities = jnp.linspace(0.5,2,n_particles)\n",
    "    # broadcast init_state to number of particles\n",
    "    init_states = jax.vmap(lambda f,g:(*init_state[:4], f, init_state[4], g), in_axes=(0,0))(frictions, gravities)\n",
    "\n",
    "    # define functions for SIS/SMC\n",
    "    init_fn = jax.jit(jax.vmap(model.importance, in_axes=(0,None,0)))\n",
    "    update_fn = jax.jit(model.update)\n",
    "    proposal_fn = c2f_pose_update_v5_jit\n",
    "\n",
    "    def smc_body(carry, t):\n",
    "        # get new keys\n",
    "        print(\"jit compiling\")\n",
    "        # initialize particle based on last time step\n",
    "        jprint(\"t = {}\",t)\n",
    "        \n",
    "        key, log_weights, states,  = carry\n",
    "        key, importance_keys = make_new_keys(key, n_particles)\n",
    "        key, resample_key = jax.random.split(key)\n",
    "        key, proposal_key = jax.random.split(key)\n",
    "\n",
    "        variance = jax.lax.cond(\n",
    "            jnp.less_equal(t, model_args[1][0] + 2),\n",
    "            lambda: 3 * model_args[5],\n",
    "            lambda: model_args[5]\n",
    "        )\n",
    "\n",
    "        modified_model_args = (*model_args[:5], variance, *model_args[6:])\n",
    "\n",
    "        full_args = jax.vmap(lambda x,y:(x, *y), in_axes=(0,None))(states, modified_model_args)\n",
    "\n",
    "        importance_log_weights, particles = init_fn(importance_keys, update_choice_map_no_unfold(gt,constant_choices, t), full_args)\n",
    "\n",
    "        # propose good poses based on proposal\n",
    "        def proposer(carry, p):\n",
    "            key, idx = carry\n",
    "            proposal_log_weight = 0\n",
    "            # argdiff and enumerator\n",
    "            argdiffs = argdiffs_modelv7(p)\n",
    "            enumerators = [b.make_enumerator([(addr + f'_{i}')], \n",
    "                                        chm_builder = proposal_choice_map_no_unfold,\n",
    "                                        argdiff_f=lambda x: argdiffs\n",
    "                                        ) for i in range(num_objects)] \n",
    "            for obj_id in range(num_objects):\n",
    "                key, new_key = jax.random.split(key)\n",
    "                reference = jax.lax.cond(jnp.equal(t,t_start),\n",
    "                                         lambda:model_args[3][obj_id],\n",
    "                                         lambda:states[2][idx][obj_id])\n",
    "                w, p = proposal_fn(new_key, p, reference, gridding_schedules[obj_id], enumerators[obj_id], obj_id)\n",
    "                proposal_log_weight += w\n",
    "            return (new_key, idx + 1), (proposal_log_weight, p)\n",
    "        _, (proposal_log_weights, particles) = jax.lax.scan(proposer, (proposal_key, 0), particles)\n",
    "\n",
    "        eff_ss, priority_fn_log_probs = resampling_priority_fn(particles, padded_all_obj_indices, t)\n",
    "\n",
    "        # jprint(\"t = {}, ess = {}\", t, eff_ss)\n",
    "\n",
    "        # # Resampling when ess is below threshold\n",
    "        indices = jax.lax.cond(eff_ss <= 0.9*n_particles,\n",
    "                               lambda: jax.random.categorical(resample_key, priority_fn_log_probs, shape=(n_particles,)),\n",
    "                               lambda: jnp.arange(n_particles))\n",
    "        particles = jtu.tree_map(lambda v: v[indices], particles)\n",
    "\n",
    "        # get weights of particles\n",
    "        new_log_weight = log_weights + importance_log_weights\n",
    "        next_states = get_next_state_vmap(particles)\n",
    "\n",
    "        return (key, new_log_weight, next_states), (particles, indices)\n",
    "\n",
    "    (_, final_log_weight, _), (particles, indices) = jax.lax.scan(\n",
    "        smc_body, (key, jnp.zeros(n_particles), init_states), jnp.arange(t_start, T))\n",
    "    rendered = particles.get_retval()[0]\n",
    "    rendered_obj = particles.get_retval()[1]\n",
    "    inferred_poses = particles.get_retval()[2]\n",
    "    print(\"SCAN finished\")\n",
    "    return final_log_weight, rendered, rendered_obj, inferred_poses, particles, indices\n",
    "\n",
    "def reset_renderer():\n",
    "    b.RENDERER = None\n",
    "    b.setup_renderer(intrinsics)\n",
    "    for registered_obj in registered_objects:\n",
    "        b.RENDERER.add_mesh(registered_obj['mesh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumeration grid\n",
    "# TODO: ADAPTIVE GRID SIZING\n",
    "# grid_widths = [1, 0.2,0.04,0.008,0.002,0.0004]\n",
    "# # grid_widths = [0.5, 0.1,0.02]\n",
    "# grid_nums = [(7,7,7),(7,7,7),(7,7,7), (7,7,7), (7,7,7), (7,7,7)]\n",
    "# gridding_schedule_trans = make_schedule_translation_3d(grid_widths, grid_nums)\n",
    "# gridding_schedule_rot = [b.utils.make_rotation_grid_enumeration(10, 15, -jnp.pi/12, jnp.pi/12, jnp.pi/12)]\n",
    "# # gridding_schedule = [gridding_schedule_trans[0], gridding_schedule_trans[1], gridding_schedule_trans[2], gridding_schedule_rot[0]]\n",
    "# gridding_schedule = [gridding_schedule_trans[0], gridding_schedule_trans[1], \n",
    "#                      gridding_schedule_trans[2], gridding_schedule_trans[3],\n",
    "#                      gridding_schedule_trans[4], gridding_schedule_trans[5]]\n",
    "\n",
    "\n",
    "gridding_schedules = []\n",
    "for box_dims in b.RENDERER.model_box_dims:\n",
    "    c2fm1 = 2\n",
    "    c2f0 = 1\n",
    "    c2f1 = 0.7 * c2f0\n",
    "    c2f2 = 0.7 * c2f1\n",
    "    c2f3 = 0.2 * c2f2\n",
    "    c2f4 = 0.2 * c2f3\n",
    "    c2f5 = 0.2 * c2f4\n",
    "    c2f6 = 0.2 * c2f5\n",
    "\n",
    "    c2fs = [c2f0,c2f1,c2f2,c2f3,c2f4,c2f5,c2f6] #c2fm1\n",
    "    # c2f0 = 1\n",
    "    # c2f1 = 0.15 * c2f0\n",
    "    # c2f2 = 0.05 * c2f1\n",
    "    # c2f3 = 0.05 * c2f2\n",
    "    # c2fs = [c2f0,c2f1,c2f2,c2f3]\n",
    "\n",
    "    x,y,z = box_dims\n",
    "    grid_widths = [[c2f*x, c2f*y, c2f*z] for c2f in c2fs]\n",
    "\n",
    "    grid_nums = [(13,13,13),(7,7,7),(7,7,7),(7,7,7), (7,7,7)]#,(7,7,7),(7,7,7)]\n",
    "    # grid_nums = [(7,7,7),(5,5,5),(5,5,5), (5,5,5), (5,5,5), (3,3,3), (3,3,3)]\n",
    "    # grid_nums = [(5,5,5),(5,5,5),(5,5,5),(5,5,5), (5,5,5), (5,5,5)]#, (5,5,5), (5,5,5)]\n",
    "    # grid_nums = [(15,15,5), (41,5,5), (41,5,5), (41,5,5)]\n",
    "    gridding_schedule_trans = make_schedule_translation_3d_variable_grid(grid_widths, grid_nums)\n",
    "    gridding_schedules.append(gridding_schedule_trans)\n",
    "\n",
    "# Setup for inference\n",
    "T = gt_images.shape[0]\n",
    "num_registered_objects = len(registered_objects)\n",
    "variance = 0.1\n",
    "INIT_STATE = (\n",
    "        None,\n",
    "        None,\n",
    "        jnp.tile(jnp.eye(4).at[2,3].set(1e+5)[None,...],(num_registered_objects,1,1)),\n",
    "        jnp.zeros((T,num_registered_objects,4,4)),\n",
    "        t_start\n",
    ")\n",
    "MODEL_ARGS = (\n",
    "     jnp.array([r['t_init'] for r in registered_objects]),\n",
    "     jnp.array([r['t_full'] for r in registered_objects]),\n",
    "     jnp.array([r['pose'] for r in registered_objects]),\n",
    "     jnp.array([r['full_pose'] for r in registered_objects]),\n",
    "    #  jnp.array([5e-0, 5e-1]),\n",
    "     (jnp.array([1e-0,1e-0,5e-1]), 5e-1),\n",
    "     variance,\n",
    "     None\n",
    ")\n",
    "CONSTANT_CHOICES = {}\n",
    "\n",
    "key = jax.random.PRNGKey(np.random.randint(0,2332423432))\n",
    "n_particles = 30\n",
    "model = mcs_model\n",
    "\n",
    "start = time.time()\n",
    "lw, rendered, rendered_obj, inferred_poses, trace, indices = inference_approach_G2(model, gt_images, \n",
    "    gridding_schedules, MODEL_ARGS, INIT_STATE, key, t_start, CONSTANT_CHOICES, T, \"pose\", n_particles)\n",
    "print (\"FPS:\", rendered.shape[0] / (time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scs = trace.score\n",
    "rend_ll = trace.project(genjax.select((\"depth\")))\n",
    "phy_ll = trace.project(genjax.select((\"pose_0\")))\n",
    "worst_rend = outlier_gaussian_double_vmap(gt_images[t_start:], gt_images_bg[t_start:], variance,None)\n",
    "\n",
    "w = trace.project(genjax.select(\"depth\"))\n",
    "offst = 3\n",
    "start = t_start +offst\n",
    "gap = w[offst:].max()-w[offst:].min()\n",
    "\n",
    "rendering_ll_images = []\n",
    "\n",
    "fig, ax = plt.subplots()  # Using subplots to directly access the figure object\n",
    "lines = []\n",
    "for p_id in range(n_particles):\n",
    "    line = ax.plot(np.array([start]),w[offst,p_id], label = f\"Particle {p_id+1}\")[0]\n",
    "    lines.append(line)\n",
    "line = ax.plot(np.array([start]),worst_rend[offst], label = \"Worst\", linestyle = \"--\")[0]\n",
    "lines.append(line)\n",
    "ax.set_xlim([start,T])\n",
    "ax.set_ylim([worst_rend.min(),95.75 + 0.1*(95.75 - worst_rend.min())])\n",
    "# ax.set_ylim([w[offst:].min()-0.1*gap,w[offst:].max()+0.1*gap])\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Log Likelihood\")\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "fig.subplots_adjust(right=0.75)\n",
    "fig.canvas.draw()\n",
    "rendering_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "\n",
    "for _ in tqdm(range(0,start)):\n",
    "    rendering_ll_images.append(rendering_ll_img.copy().resize((600,400)))\n",
    "\n",
    "for t in tqdm(range(start,T)):\n",
    "    for p_id in range(n_particles):\n",
    "        lines[p_id].set_data(np.arange(start,t+1),w[:,p_id][offst:offst+t+1-start])\n",
    "    lines[-1].set_data(np.arange(start,t+1),worst_rend[offst:offst+t+1-start])\n",
    "    fig.canvas.draw()\n",
    "    rendering_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "    rendering_ll_images.append(rendering_ll_img.resize((600,400)))\n",
    "    plt.close()\n",
    "\n",
    "w = trace.project(genjax.select(\"pose_0\"))\n",
    "offst = 3\n",
    "start = t_start+offst\n",
    "gap = w[offst:].max()-w[offst:].min()\n",
    "\n",
    "physics_ll_images = []\n",
    "\n",
    "fig, ax = plt.subplots()  # Using subplots to directly access the figure object\n",
    "lines = []\n",
    "for p_id in range(n_particles):\n",
    "    line = ax.plot(np.array([start]),w[offst,p_id], label = f\"Particle {p_id+1}\")[0]\n",
    "    lines.append(line)\n",
    "    \n",
    "ax.set_xlim([start,T]) \n",
    "ax.set_ylim([-4.66,-4.57])\n",
    "# ax.set_ylim([w[offst:].min()-0.1*gap, w[offst:].max()+0.1*gap])\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Log Likelihood\")\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "fig.subplots_adjust(right=0.75)\n",
    "fig.canvas.draw()\n",
    "physics_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "\n",
    "for _ in tqdm(range(0,start)):\n",
    "    physics_ll_images.append(physics_ll_img.copy().resize((600,400)))\n",
    "\n",
    "for t in tqdm(range(start,T)):\n",
    "    for p_id in range(n_particles):\n",
    "        lines[p_id].set_data(np.arange(start,t+1),w[:,p_id][offst:offst+t+1-start])\n",
    "    fig.canvas.draw()\n",
    "    physics_ll_img = b.pil_image_from_matplotlib(fig)\n",
    "    physics_ll_images.append(physics_ll_img.resize((600,400)))\n",
    "    plt.close()\n",
    "\n",
    "dummy_poses = np.tile(jnp.eye(4).at[2,3].set(-1e5)[None,None,None,...], (t_start,n_particles,num_registered_objects,1,1))\n",
    "concat_inferred_poses = np.concatenate([dummy_poses, inferred_poses])\n",
    "\n",
    "p_images = get_particle_images(intrinsics_orig, concat_inferred_poses, T = T)\n",
    "blended_images = [b.overlay_image(p_images[i],b.get_depth_image(gt_images_orig[i][...,2])) for i in range(len(p_images))]\n",
    "images = []\n",
    "for t in tqdm(range(T)):\n",
    "    images.append(b.scale_image(b.multi_panel([\n",
    "                b.get_depth_image(gt_images_orig[t,...,2]),\n",
    "                # b.scale_image(b.get_depth_image(rendered[t,particle_id,...,2]),scale),\n",
    "                blended_images[t],\n",
    "                physics_ll_images[t],\n",
    "                rendering_ll_images[t]\n",
    "                # b.scale_image(b.get_depth_image(rendered_obj[t,particle_id,...,2]),3)\n",
    "                ],labels = ['gt/observed', 'particles',\n",
    "                            \"physics likelihood\", \"rendering likelihood\"]), 0.4))\n",
    "display_video(images, framerate=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = phy_ll[3:]\n",
    "\n",
    "fig, axes = plt.subplots(6, 5, figsize=(15, 12))  # Adjust figsize as needed\n",
    "\n",
    "# Set global min and max for y-axis\n",
    "ymin, ymax = np.min(data), np.max(data)\n",
    "\n",
    "for i in range(30):\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.plot(data[3:, i])\n",
    "    ax.set_ylim([-4.66, -4.57])  # Set the same y-axis limits for all plots\n",
    "    ax.set_title(f\"Plot {i+1}\")\n",
    "    # ax.set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "data = rend_ll[3:]\n",
    "\n",
    "fig, axes = plt.subplots(6, 5, figsize=(15, 12))  # Adjust figsize as needed\n",
    "\n",
    "# Set global min and max for y-axis\n",
    "ymin, ymax = np.min(data), np.max(data)\n",
    "\n",
    "for i in range(30):\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.plot(data[3:, i])\n",
    "    ax.set_ylim([94.75, 95.75])  # Set the same y-axis limits for all plots\n",
    "    ax.set_title(f\"Plot {i+1}\")\n",
    "    # ax.set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splice_image_double_vmap = jax.vmap(splice_image, in_axes = (0,0))\n",
    "rend_scores = []\n",
    "for p_id in tqdm(range(n_particles)):\n",
    "    # new_rendered_unspliced = b.RENDERER.render_many(inferred_poses[:,p_id,...], jnp.arange(num_registered_objects))[...,:3]\n",
    "    # new_rendered = splice_image_double_vmap(new_rendered_unspliced, gt_images_bg[t_start:])\n",
    "    scores = outlier_gaussian_double_vmap(gt_images[t_start:], gt_images_bg[t_start:], 0.1,None)\n",
    "    rend_scores.append(np.array(scores))\n",
    "rend_scores = np.stack(rend_scores).T\n",
    "rend_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_rend = outlier_gaussian_double_vmap(gt_images[t_start:], gt_images_bg[t_start:], 0.1,None)\n",
    "min_rend = worst_rend.min()\n",
    "for i in range(n_particles):\n",
    "    plt.plot(rend_ll[3:,i])\n",
    "plt.plot(worst_rend[3:], linestyle=\"--\")\n",
    "plt.ylim([min_rend, 95.75]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = 0.1\n",
    "# display(scs, rend_ll, phy_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ registered_objects[0]['full_pose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ concat_inferred_poses[123,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_inferred_poses[134][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_id in range(n_particles):\n",
    "    if p_id > -1:\n",
    "        xs = [(cam_pose @ concat_inferred_poses[i,p_id,0])[0,3] for i in range(123,126)]\n",
    "        ys = [(cam_pose @ concat_inferred_poses[i,p_id,0])[1,3] for i in range(123,126)]\n",
    "        plt.plot(xs,ys)\n",
    "        # plt.scatter(xs[-1],ys[-1])\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "for i in range(134,126):\n",
    "    if len(poses[i]) > 0:\n",
    "        xs.append((cam_pose @ poses[i][0])[0,3])\n",
    "        ys.append((cam_pose @ poses[i][0])[1,3] + 0.3)\n",
    "# xs = [(cam_pose @ poses[i][0])[0,3] for i in range(134,141)]\n",
    "# ys = [(cam_pose @ poses[i][0])[1,3] for i in range(134,141)]\n",
    "plt.plot(xs,ys, marker = 'x')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(registered_objects[0]['full_pose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [(cam_pose @ poses[i][0])[0,3] for i in range(134,141)]\n",
    "ys = [(cam_pose @ poses[i][0])[1,3] for i in range(134,141)]\n",
    "plt.plot(xs,ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = 204\n",
    "display(rend_ll[tt-134])\n",
    "display(phy_ll[tt-134])\n",
    "display(scs[tt-134])\n",
    "display(rend_ll[tt-134] + phy_ll[tt-134])\n",
    "concat_inferred_poses[tt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.scale_image(b.get_depth_image(imm[...,2]),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.overlay_image(b.scale_image(b.get_depth_image(imm_unspliced[...,2]),5), b.scale_image(b.get_depth_image(imm[...,2]),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ concat_inferred_poses[134][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ concat_inferred_poses[141][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pose @ debug_physics_stepper(jnp.array(concat_inferred_poses[:,0,0,...]), 142, 134, 0, -0.03, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threedp3_likelihood_arijit(gt_images_bg[-1],gt_images[-1],0.1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_images[-1,all_obj_indices[-1][:,0],all_obj_indices[-1][:,1],2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered[-1,0,all_obj_indices[-1][:,0],all_obj_indices[-1][:,1],2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_obj_indices[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered[-1,0][25:31,30:40,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_images[-1][25:31,30:40,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.linalg.norm(gt_images[-1][20:35,20:50,:] - rendered[-1,0][20:35,20:50,:], axis=-1) < 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.sum(jnp.linalg.norm(gt_images[123] - gt_images_bg[123], axis=-1) < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def splice_image(rendered_object_image, obs_image_complement, far=150.0):\n",
    "    keep_masks = jnp.logical_or(\n",
    "        jnp.logical_and((rendered_object_image[...,2] <= obs_image_complement[..., 2]) * \n",
    "        rendered_object_image[...,2] > 0.0, (obs_image_complement[...,2] >= far))\n",
    "        ,\n",
    "        (obs_image_complement[...,2] == 0)\n",
    "    )[...,None]\n",
    "    rendered_images = keep_masks * rendered_object_image + (1.0 - keep_masks) * obs_image_complement\n",
    "    return rendered_images, keep_masks\n",
    "imm_unspliced = b.RENDERER.render(registered_objects[0]['full_pose'][None,...], jnp.array([0]))[...,:3]\n",
    "imm,k = splice_image(imm_unspliced, gt_images_bg[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(outlier_gaussian(gt_images[123],rendered[123-123,6],0.1,None))\n",
    "display(outlier_gaussian(gt_images[123],imm,0.1,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for bad init\n",
    "tt = registered_objects[0]['t_full'] + 2\n",
    "reference = inferred_poses[tt]\n",
    "obs = gt_images[tt+1]\n",
    "c2f_imgs = []\n",
    "for i in range(len(gridding_schedules[0])):\n",
    "    updated_grid = jnp.einsum(\"ij,ajk->aik\", reference, gridding_schedules[0][i])\n",
    "    imgs = b.RENDERER.render_many(updated_grid[:,None,...], jnp.array([0]))[...,:3]\n",
    "    rendered_images = splice_image_vmap(imgs, gt_images_bg[tt])\n",
    "    scores = threedp3_likelihood_arijit_vmap(obs, rendered_images, 0.5,None)\n",
    "    idx = scores.argmax()\n",
    "    reference = updated_grid[idx]\n",
    "    c2f_imgs.append(b.scale_image(b.get_depth_image(rendered_images[idx,...,2]),10))\n",
    "    print(scores.argmax())\n",
    "for x in c2f_imgs:\n",
    "    display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.array([True]) * jnp.array([False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_images[146]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threedp3_likelihood_arijit(gt_images[0],gt_images[0],0.1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high memory usage !!!####\n",
    "\n",
    "# b.setup_renderer(intrinsics_orig, num_layers= 1024)\n",
    "# for i,registered_obj in enumerate(registered_objects):\n",
    "#     b.RENDERER.add_mesh(registered_obj['mesh'])\n",
    "# if len(registered_objects) == 0:\n",
    "#     b.RENDERER.add_mesh_from_file(os.path.join(b.utils.get_assets_dir(),\"sample_objs/cube.obj\"), scaling_factor = 0.1)\n",
    "\n",
    "# splice_image_double_vmap = jax.vmap(splice_image, in_axes = (0,0))\n",
    "# rend_scores = []\n",
    "# for p_id in tqdm(range(n_particles)):\n",
    "#     new_rendered_unspliced = b.RENDERER.render_many(inferred_poses[:,p_id,...], jnp.arange(num_registered_objects))[...,:3]\n",
    "#     new_rendered = splice_image_double_vmap(new_rendered_unspliced, gt_images_bg_orig[t_start:])\n",
    "#     scores = threedp3_likelihood_arijit_double_vmap(gt_images_orig[t_start:], new_rendered, 0.1,None)\n",
    "#     rend_scores.append(np.array(scores))\n",
    "# rend_scores = np.stack(rend_scores).T\n",
    "# rend_scores.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
