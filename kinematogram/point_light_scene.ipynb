{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes3d as b\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bop_ycb_dir = os.path.join(b.utils.get_assets_dir(), \"bop/ycbv\")\n",
    "rgbd, gt_ids, gt_poses, masks = b.utils.ycb_loader.get_test_img('54', '1', bop_ycb_dir)\n",
    "# b.RENDERER.add_mesh_from_file(os.path.join(b.utils.get_assets_dir(), \"sample_objs/cube.obj\"), scaling_factor=1.0/10000000000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsics(height=480, width=640, fx=1066.778, fy=1066.778, cx=320.0, cy=240.0, near=0.01, far=2.0)\n"
     ]
    }
   ],
   "source": [
    "intrinsics = b.Intrinsics(\n",
    "    rgbd.intrinsics.height, rgbd.intrinsics.width,\n",
    "    rgbd.intrinsics.fx, rgbd.intrinsics.fx,\n",
    "    rgbd.intrinsics.width/2, rgbd.intrinsics.height/2,\n",
    "    rgbd.intrinsics.near, rgbd.intrinsics.far\n",
    ")\n",
    "print(intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7002/static/\n"
     ]
    }
   ],
   "source": [
    "b.setup_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_1 = 1\n",
    "IDX_2 = 11\n",
    "frames = 40\n",
    "devices = 1\n",
    "objs = 2\n",
    "dots = 5000 * objs\n",
    "pc = jnp.array(b.RENDERER.meshes[IDX_1].vertices)\n",
    "b.show_cloud(\"1\",pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the scene graph\n",
    "\n",
    "box_dims = [b.utils.aabb(m.vertices)[0] for m in meshes]\n",
    "box_dims = jnp.array(box_dims)\n",
    "\n",
    "absolute_poses = jnp.array([\n",
    "    jnp.eye(4),\n",
    "    jnp.eye(4),\n",
    "    jnp.eye(4),\n",
    "    jnp.eye(4),\n",
    "    jnp.eye(4),\n",
    "])\n",
    "\n",
    "parents = jnp.array([\n",
    "    -1, 0, 0, 0, 0\n",
    "])\n",
    "\n",
    "contact_params = jnp.array(\n",
    "    [\n",
    "        [0.0, 0.0, jnp.pi/4],\n",
    "        [-1.0, -0.5, jnp.pi/4],\n",
    "        [-0.2, 0.1, jnp.pi/2],\n",
    "        [2.0, -1.0, jnp.pi/2],\n",
    "        [1.0, -4.0, jnp.pi/2],\n",
    "    ]\n",
    ")\n",
    "\n",
    "face_parents = jnp.array([2,2,2,2,2])\n",
    "face_child = jnp.array([0,0,0,0,0])\n",
    "\n",
    "poses = b.scene_graph.poses_from_scene_graph_jit(\n",
    "    absolute_poses, box_dims, parents, contact_params, face_parents, face_child\n",
    ")\n",
    "\n",
    "pos = jnp.array([[10.0, -15.0, 5.0]])\n",
    "target = jnp.array([0.0, 0.0, 0.0])\n",
    "up = jnp.array([0.0, 0.0, 1.0])\n",
    "\n",
    "camera_pose = b.t3d.transform_from_pos_target_up(pos, target, up)\n",
    "\n",
    "\n",
    "\n",
    "poses_in_camera_frame = b.t3d.inverse_pose(camera_pose) @ poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.  , 1.15],\n",
       "       [0.  , 0.  , 0.  , 1.  ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rot = b.t3d.rotation_from_axis_angle(jnp.array([1,0,0]),0)\n",
    "translation = jnp.array([0,0,2.3/2])\n",
    "transform = b.t3d.transform_from_rot_and_pos(rot, translation)\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2 = b.t3d.apply_transform(jnp.array(b.RENDERER.meshes[IDX_2].vertices), transform)\n",
    "b.show_cloud(\"2\",pc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 2, 5000, 3)\n"
     ]
    }
   ],
   "source": [
    "pc = jnp.vstack((pc,pc2))\n",
    "\n",
    "lifetime = 5 #keep 1-1/5 of the dots after every frame update\n",
    "point_rad = 5\n",
    "\n",
    "\n",
    "pc_subsample_start = pc[jax.random.choice(jax.random.PRNGKey(10), jnp.arange(pc.shape[0]), shape=(dots,) )] #want 1000 dots total\n",
    "pc_replacements = pc[jax.random.choice(jax.random.PRNGKey(0), jnp.arange(pc.shape[0]), shape=(frames,dots//lifetime) )]\n",
    "\n",
    "pc_subsamples = jnp.zeros((frames,*pc_subsample_start.shape))\n",
    "pc_subsamples = pc_subsamples.at[0,...].set(pc_subsample_start)\n",
    "for i in range(1,frames):\n",
    "    pc_subsamples = pc_subsamples.at[i,...].set(pc_subsamples[i-1,...])\n",
    "    sampled_indices = jax.random.choice(jax.random.PRNGKey(i), jnp.arange(dots), shape=(dots//lifetime,) )\n",
    "    pc_subsamples = pc_subsamples.at[i,sampled_indices,...].set(pc_replacements[i,...])\n",
    "\n",
    "# pc_vec = pc_vec.reshape(2, -1, 3)\n",
    "# pc_vec.shape\n",
    "# print(pc_vec.shape)\n",
    "pc_subsamples = pc_subsamples.reshape(frames,2,-1,3)\n",
    "print(pc_subsamples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b.show_cloud(\"1\", pc_subsamples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 2, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "poses_1 = jnp.array([b.t3d.inverse_pose(b.t3d.transform_from_pos_target_up(\n",
    "        jnp.array([0.0, 2.0, 0.0]),\n",
    "        jnp.array([0.0, 0.0, 0.0]),\n",
    "        jnp.array([0.0, 0.0, 1.0]),\n",
    ")) @ b.t3d.transform_from_axis_angle(jnp.array([0.0, 0.0, 1.0]), angle) for angle in jnp.linspace(0.0, 4*jnp.pi, frames)])\n",
    "\n",
    "# poses_2 = jnp.array([b.t3d.inverse_pose(\n",
    "#     b.t3d.transform_from_rot_and_pos(rot, translation)\n",
    "# ) @ b.t3d.transform_from_axis_angle(jnp.array([1.0, 0.0, 1.0]), angle) for angle in jnp.linspace(0.0, 4*jnp.pi, frames)])\n",
    "\n",
    "poses_2 = jnp.array([b.t3d.inverse_pose(b.t3d.transform_from_pos_target_up(\n",
    "        jnp.array([0.0, 2.0, 0.0]),\n",
    "        jnp.array([0.0, 0.0, 0.0]),\n",
    "        jnp.array([0.0, 0.0, 1.0]),\n",
    ")) @ b.t3d.transform_from_axis_angle(jnp.array([0.0, 0.0, 1.0]), angle) for angle in jnp.linspace(0.0, 4*jnp.pi, frames)]) @ transform\n",
    "\n",
    "poses=jnp.stack((poses_1,poses_2),axis=1)\n",
    "print(poses.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circles(flips_xy, radius):\n",
    "    centers = jnp.array((flips_xy>0).nonzero(size=5000,fill_value=jnp.inf))\n",
    "    x,y = jnp.meshgrid(jnp.arange(flips_xy.shape[1]),jnp.arange(flips_xy.shape[0]))\n",
    "    xymesh = jnp.array([y,x])\n",
    "    distances_to_keypoints = (\n",
    "        jnp.linalg.norm(xymesh[:, :,:,None] - centers[:,None, None,:],\n",
    "        axis=0\n",
    "    ))\n",
    "    index_of_nearest_keypoint = distances_to_keypoints.argmin(2)\n",
    "    distance_to_nearest_keypoints = distances_to_keypoints.min(2)\n",
    "    DISTANCE_THRESHOLD = radius\n",
    "    valid_match_mask = (distance_to_nearest_keypoints < DISTANCE_THRESHOLD)[...,None]\n",
    "    return valid_match_mask\n",
    "\n",
    "def render_point_light(pose, pc_to_render, key):\n",
    "    pc_in_camera_frame = []\n",
    "    for o in range(len(pose)):\n",
    "        pc_in_camera_frame.append(b.t3d.apply_transform(pc_to_render[o], pose[o]))\n",
    "    pc_in_camera_frame = jnp.array(pc_in_camera_frame).reshape(-1,3)\n",
    "    \n",
    "    img = b.render_point_cloud(pc_in_camera_frame, intrinsics)\n",
    "\n",
    "    rendered_image = b.RENDERER.render_jax(pose, jnp.array([jnp.int32(IDX_1),jnp.int32(IDX_2)]))[:,:,:3]\n",
    "\n",
    "    mask = (rendered_image[:,:,2] < intrinsics.far)\n",
    "    matches = (jnp.abs(img[:,:,2] - rendered_image[:,:,2]) < 0.05)\n",
    "    flips = (jax.random.uniform(key,shape=matches.shape) < 0.0005)\n",
    "    \n",
    "    final_no_noise = circles(mask * matches,point_rad)\n",
    "    final_with_noise = circles(mask * matches + (1.0 - mask) * flips, point_rad)\n",
    "\n",
    "    return final_no_noise, final_with_noise\n",
    "\n",
    "gpus = jax.devices('gpu')\n",
    "render_point_light_parallel_jit = jax.jit(jax.vmap(render_point_light, in_axes=(0,0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(100)\n",
    "keys = jax.random.split(jax.random.PRNGKey(100), poses.shape[0])\n",
    "images_no_noise, images = render_point_light_parallel_jit(poses, pc_subsamples, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = [b.get_depth_image(1.0 - point_light_image * 1.0, cmap=matplotlib.colormaps['Greys']) for point_light_image in images ]\n",
    "b.make_gif_from_pil_images(viz, \"out_noise_scene.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz[0].save('out_frame_scene.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = [b.get_depth_image(1.0 - point_light_image * 1.0, cmap=matplotlib.colormaps['Greys']) for point_light_image in images_no_noise ]\n",
    "b.make_gif_from_pil_images(viz, \"out_clean_scene.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "static = jnp.repeat(images[0,...][jnp.newaxis,...], frames, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = [b.get_depth_image(1.0 - point_light_image * 1.0, cmap=matplotlib.colormaps['Greys']) for point_light_image in jnp.concatenate((static, images_no_noise, images),axis=2)]\n",
    "b.make_gif_from_pil_images(viz, \"out_merge_scene.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"names.csv\", \"w\") as text_file:\n",
    "    for i, name in enumerate(b.ycb_loader.MODEL_NAMES):\n",
    "        text_file.write('kinematogram_'+str(i)+', '+name+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
