{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arijit's Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/bayes3d/test this is the current working directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:44:17\n"
     ]
    }
   ],
   "source": [
    "import bayes3d as b\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import pybullet as p\n",
    "print(os.getcwd(), \"this is the current working directory\")\n",
    "\n",
    "def display_video(frames, framerate=30):\n",
    "    height, width, _ = frames[0].shape\n",
    "    dpi = 70\n",
    "    orig_backend = matplotlib.get_backend()\n",
    "    matplotlib.use('Agg')  # Switch to headless 'Agg' to inhibit figure rendering.\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "    matplotlib.use(orig_backend)  # Switch back to the original backend.\n",
    "    ax.set_axis_off()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    im = ax.imshow(frames[0])\n",
    "    def update(frame):\n",
    "      im.set_data(frame)\n",
    "      return [im]\n",
    "    interval = 1000/framerate\n",
    "    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n",
    "                                   interval=interval, blit=True, repeat=True)\n",
    "    return HTML(anim.to_html5_video())\n",
    "\n",
    "def object_pose_in_camera_frame(object_id, view_matrix):\n",
    "    object_pos, object_orn = p.getBasePositionAndOrientation(object_id) # world frame\n",
    "    world2cam = np.array(view_matrix).reshape([4,4]).T # world --> cam \n",
    "    object_transform_matrix = np.eye(4)\n",
    "    object_transform_matrix[:3, :3] = np.reshape(p.getMatrixFromQuaternion(object_orn), (3, 3))\n",
    "    object_transform_matrix[:3, 3] = object_pos\n",
    "    return world2cam @ object_transform_matrix\n",
    "\n",
    "def get_camera_pose(view_matrix):\n",
    "    # cam2world\n",
    "    world2cam = np.array(view_matrix)\n",
    "    cam2world  = np.linalg.inv(world2cam)\n",
    "    return cam2world\n",
    "\n",
    "def object_pose_in_camera_frame(object_pose, view_matrix):\n",
    "    world2cam = np.array(view_matrix).reshape([4,4]) # world --> cam \n",
    "    return world2cam @ object_pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pybullet Scene Sim with Collisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes3d.utils.pybullet_sim as pyb \n",
    "\n",
    "scene = pyb.Scene()\n",
    "scene.set_gravity([0, 0, 0])\n",
    "scene.set_timestep(1/240)\n",
    "scene.set_downsampling(4) \n",
    "\n",
    "occ1_meshscale = [0.07,0.07,0.07]\n",
    "path_to_obj = \"../assets/sample_objs/plane.obj\"\n",
    "base_position = [0,-1,1]\n",
    "base_orientation = [0.7071068, 0, 0, 0.7071068]\n",
    "base_orientation = np.array(p.getMatrixFromQuaternion(base_orientation)).reshape(3,3)\n",
    "occ1 = pyb.make_body_from_obj(path_to_obj, base_position, orientation=base_orientation,scale = occ1_meshscale, id = \"occluder\")\n",
    "occ1.set_mass(0)\n",
    "occ1.set_color([0.5,0.5,0.5])\n",
    "scene.add_body(occ1)\n",
    "\n",
    "box_mass = 1\n",
    "path_to_box = \"../assets/sample_objs/cube.obj\"\n",
    "box_position = [-3.25, 0, 1]\n",
    "box_start_velocity = [6, 0, 0]\n",
    "mesh_scale = [0.5,0.5,0.5]\n",
    "box = pyb.make_body_from_obj(path_to_box, box_position, scale = mesh_scale, restitution=1, id = \"box1\")\n",
    "box.set_velocity(box_start_velocity)\n",
    "scene.add_body(box)\n",
    "\n",
    "box2_position = [3.25, 0, 1]\n",
    "box2_start_velocity = [-6, 0, 0]\n",
    "box2 = pyb.make_body_from_obj(path_to_box, box2_position, scale = mesh_scale, restitution=1, id = \"box2\")\n",
    "box2.set_velocity(box2_start_velocity)\n",
    "box2.set_color([0.5,0.5,0.5])\n",
    "scene.add_body(box2)\n",
    "\n",
    "bull = scene.simulate(220, defaultView = True)\n",
    "bull.create_gif(\"tracking_collision.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1_poses = bull.get_body_poses()[\"box1\"]\n",
    "box2_poses = bull.get_body_poses()[\"box2\"]\n",
    "plane_pos, plane_ori = bull.floor_pos_ori\n",
    "plane_ori = p.getMatrixFromQuaternion(plane_ori)\n",
    "plane_cam_pose = np.eye(4)\n",
    "plane_cam_pose[:3, 3] = plane_pos\n",
    "plane_cam_pose[:3, :3] = np.array(plane_ori).reshape(3,3)\n",
    "view_matrix = bull.viewMatrix \n",
    "view_matrix = np.array(view_matrix).reshape([4,4]).T\n",
    "box1 = [view_matrix@pose for pose in box1_poses]\n",
    "box2 = [view_matrix@pose for pose in box2_poses]\n",
    "plane_cam_poses = view_matrix@plane_cam_pose\n",
    "occ1_pose = view_matrix@ bull.get_body_poses()['occluder'][0]\n",
    "cam_pose = get_camera_pose(view_matrix) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Information for Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_dict = {\n",
    "    'sphere1': box1, # box poses in camera view \n",
    "    'sphere2': box2, # sphere2 poses in camera view\n",
    "    'plane': plane_cam_pose, # plane pose in camera view \n",
    "    'occ1' : occ1_pose, # occluder pose in camera view\n",
    "    'occ1_meshscale' : occ1_meshscale,\n",
    "    'cam_pose' : cam_pose, # camera pose in world view\n",
    "}\n",
    "\n",
    "np.savez('scene_npzs/collision_scene_demo.npz', **array_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.          0.          0.        ]\n",
      " [ 0.          0.99619472 -0.08715574  0.90903898]\n",
      " [ 0.          0.08715574  0.99619472 -4.91664954]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[ 1.          0.          0.          0.        ]\n",
      " [-0.          0.08715574 -0.99619468 -5.97716806]\n",
      " [ 0.          0.99619468  0.08715574  0.52293444]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# sanity checks \n",
    "\n",
    "print(occ1_pose)\n",
    "print(cam_pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes3d as b\n",
    "import bayes3d.transforms_3d as t3d\n",
    "import numpy as np \n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "from jax.debug import print as jprint\n",
    "import physics_priors as p\n",
    "import importlib\n",
    "importlib.reload(p)\n",
    "import time\n",
    "import PIL.Image\n",
    "from math import sqrt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E rasterize_gl.cpp:121] OpenGL version reported as 4.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing frame buffer size to (width, height, depth) = (480, 384, 1024)\n"
     ]
    }
   ],
   "source": [
    "intrinsics = b.Intrinsics(\n",
    "    height=360,\n",
    "    width=480,\n",
    "    fx=180*sqrt(3), fy=180*sqrt(3),\n",
    "    cx=240.0, cy=180.0,\n",
    "    near=0.1, far=10.0\n",
    ")\n",
    "b.setup_renderer(intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_poses = np.load('scene_npzs/collision_scene_demo.npz')\n",
    "# Find number of timesteps\n",
    "N_tsteps = loaded_poses['sphere1'].shape[0]\n",
    "\n",
    "# load occluder poses into (N,4,4)\n",
    "occ1_meshscale = loaded_poses['occ1_meshscale']\n",
    "# occ1_meshscale = [0.0667,0.0667,0.0667]\n",
    "occ1_pose = loaded_poses['occ1']\n",
    "occ1_pose[1:3] *= -1\n",
    "occ1_poses = jnp.tile(jnp.array(occ1_pose), (N_tsteps,1,1))\n",
    "\n",
    "# occ2_meshscale = loaded_poses['occ2_meshscale']\n",
    "# occ2_pose = loaded_poses['occ2']\n",
    "# occ2_pose[1:3] *= -1\n",
    "# occ2_poses = jnp.tile(jnp.array(occ2_pose), (N_tsteps,1,1))\n",
    "\n",
    "# get object poses\n",
    "gt_poses = loaded_poses['sphere1']\n",
    "gt_poses[:,1:3,:] *= -1 # CV2 convention\n",
    "gt_poses = jnp.array(gt_poses)\n",
    "\n",
    "gt_collision_poses = loaded_poses['sphere2']\n",
    "gt_collision_poses[:,1:3,:] *= -1 # CV2 convention\n",
    "gt_collision_poses = jnp.array(gt_collision_poses)\n",
    "\n",
    "# combine the poses\n",
    "# total_gt_poses = jnp.stack([gt_poses, occ1_poses, occ2_poses], axis = 1)\n",
    "total_gt_poses = jnp.stack([gt_poses,gt_collision_poses,occ1_poses], axis = 1)\n",
    "\n",
    "# cv2 convention of cam pose\n",
    "world2cam = np.linalg.inv(loaded_poses['cam_pose'])\n",
    "world2cam[1:3] *= -1\n",
    "cam_pose = jnp.linalg.inv(jnp.array(world2cam)) \n",
    "\n",
    "b.RENDERER.add_mesh_from_file(\"../assets/sample_objs/cube.obj\",mesh_name=\"sphere_1\", scaling_factor=[0.5,0.5,0.5])\n",
    "b.RENDERER.add_mesh_from_file(\"../assets/sample_objs/cube.obj\",mesh_name=\"sphere_1\", scaling_factor=[0.5,0.5,0.5])\n",
    "b.RENDERER.add_mesh_from_file(\"../assets/sample_objs/plane.obj\",mesh_name=\"occluder1\", scaling_factor=occ1_meshscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_images = jax.vmap(b.RENDERER.render_single_object, in_axes=(0, None))(gt_poses, jnp.int32(0))\n",
    "pose_estimate = gt_poses[0]\n",
    "\n",
    "# gt_images = b.RENDERER.render_multiobject_parallel(total_gt_poses, [0,1,2])\n",
    "\n",
    "gt_images = b.RENDERER.render_many(total_gt_poses,jnp.array([0,1,2]))\n",
    "\n",
    "# gt_images = jax.vmap(b.RENDERER.render, in_axes=(0, None))(gt_poses[:,None, ...], jnp.array([0]))\n",
    "depths = [b.viz.get_depth_image(gt_images[i,:,:,2]) for i in range(gt_images.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=480x360>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx, dy, dz = 0.2, 0.2, 0.2\n",
    "translation_deltas = b.utils.make_translation_grid_enumeration(-dx, -dy, -dz, dx, dy, dz, 5,5,5)\n",
    "\n",
    "\n",
    "dx, dy, dz = 2, 2, 2\n",
    "gridding = [\n",
    "    b.utils.make_translation_grid_enumeration(\n",
    "        -dx, -dy, -dz, dx, dy, dz, 5,5,5\n",
    "    ),\n",
    "    b.utils.make_translation_grid_enumeration(\n",
    "        -dx/2.0, -dy/2, -dz/2, dx/2, dy/2, dz/2, 5,5,5\n",
    "    ),\n",
    "    b.utils.make_translation_grid_enumeration(\n",
    "        -dx/10.0, -dy/10, -dz/10, dx/10, dy/10, dz/10, 5,5,5\n",
    "    ),\n",
    "]\n",
    "\n",
    "key = jax.random.PRNGKey(314)\n",
    "rotation_deltas = jax.vmap(lambda key: b.distributions.gaussian_vmf_zero_mean(key, 0.00001, 800.0))(\n",
    "    jax.random.split(key, 100)\n",
    ")\n",
    "\n",
    "# len_proposals = gridding[0].shape[0]\n",
    "len_proposals = translation_deltas.shape[0]\n",
    "\n",
    "occ1_poses_trans = jnp.tile(occ1_pose, (len_proposals, 1, 1))\n",
    "# occ2_poses_trans = jnp.tile(occ2_pose, (len_proposals, 1, 1))\n",
    "\n",
    "occ1_poses_rot = jnp.tile(occ1_pose, (rotation_deltas.shape[0], 1, 1))\n",
    "# occ2_poses_rot = jnp.tile(occ2_pose, (rotation_deltas.shape[0], 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pose_estimate(memory, gt_image):\n",
    "\n",
    "    pose_memory, T = memory\n",
    "    old_pose_estimate = pose_memory[T,...]\n",
    "    prev_pose = pose_memory[T-1,...]\n",
    "\n",
    "    threedp3_weight = 1\n",
    "    proposals = jnp.einsum(\"ij,ajk->aik\", old_pose_estimate, translation_deltas)\n",
    "    rendered_images = b.RENDERER.render_many(jnp.stack([proposals, occ1_poses_trans],axis = 1), jnp.array([0,1]))\n",
    "    threedp3_scores = threedp3_weight * b.threedp3_likelihood_parallel(gt_image, rendered_images, 0.001, 0.1, 10**3, 3)\n",
    "    unique_best_3dp3_score = jnp.sum(threedp3_scores == threedp3_scores[jnp.argmax(threedp3_scores)]) == 1\n",
    "\n",
    "    physics_weight = jax.lax.cond(unique_best_3dp3_score, lambda _ : 5000, lambda _ : 10000, None)\n",
    "    # physics_weight = 0\n",
    "\n",
    "    physics_estimated_pose = p.physics_prior_v1_jit(old_pose_estimate, prev_pose, jnp.array([1,1,1]), cam_pose, world2cam)\n",
    "\n",
    "    physics_scores = jax.lax.cond(jnp.greater(T, 1), \n",
    "    lambda _ : physics_weight * p.physics_prior_parallel_jit(proposals, physics_estimated_pose), \n",
    "    lambda _ : jnp.zeros(threedp3_scores.shape[0]), \n",
    "    None)\n",
    "\n",
    "    scores = threedp3_scores + physics_scores\n",
    "\n",
    "    pose_estimate = proposals[jnp.argmax(scores)]\n",
    "    pose_memory = pose_memory.at[T+1,...].set(pose_estimate)\n",
    "\n",
    "    pose_world = cam_pose @ pose_estimate\n",
    "    gt_pose_world = cam_pose @ gt_poses[T-1]\n",
    "    jprint(\"{}: {}, {}\", T, unique_best_3dp3_score, pose_world[:3,3])\n",
    "    jprint(\"{}: GT, {}\\n\", T, gt_pose_world[:3,3])\n",
    "\n",
    "    # proposals = jnp.einsum(\"ij,ajk->aik\", pose_estimate, rotation_deltas)\n",
    "    # rendered_images = b.RENDERER.render_multiobject_parallel(jnp.stack([proposals, occ_poses_rot]), jnp.array([0,1]))\n",
    "    # # rendered_images = jax.vmap(b.RENDERER.render_single_object, in_axes=(0, None))(proposals, jnp.int32(0))\n",
    "    # weights_new = b.threedp3_likelihood_parallel(gt_image, rendered_images, 0.05, 0.1, 10**3, 3)\n",
    "    # pose_estimate = proposals[jnp.argmax(weights_new)]\n",
    "\n",
    "    return (pose_memory, T+1), pose_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: True, [-3.2500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "1: GT, [-3.2500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "2: True, [-3.1500001e+00 -4.7683716e-07  1.0000000e+00]\n",
      "2: GT, [-3.1500001e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "3: True, [-3.0500002e+00 -4.7683716e-07  1.0000000e+00]\n",
      "3: GT, [-3.0500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "4: True, [-2.9500003e+00 -4.7683716e-07  1.0000000e+00]\n",
      "4: GT, [-2.9500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "5: True, [-2.8500004e+00 -4.7683716e-07  1.0000000e+00]\n",
      "5: GT, [-2.8499999e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "6: True, [-2.7500005e+00 -4.7683716e-07  1.0000000e+00]\n",
      "6: GT, [-2.7500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "7: True, [-2.6500006e+00 -4.7683716e-07  1.0000000e+00]\n",
      "7: GT, [-2.6500001e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "8: True, [-2.5500007e+00 -4.7683716e-07  1.0000000e+00]\n",
      "8: GT, [-2.5500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "9: True, [-2.4500008e+00 -4.7683716e-07  1.0000000e+00]\n",
      "9: GT, [-2.4500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "10: True, [-2.3500009e+00 -4.7683716e-07  1.0000000e+00]\n",
      "10: GT, [-2.3499999e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "11: True, [-2.2500010e+00 -4.7683716e-07  1.0000000e+00]\n",
      "11: GT, [-2.2500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "12: True, [-2.1500010e+00 -4.7683716e-07  1.0000000e+00]\n",
      "12: GT, [-2.1500001e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "13: True, [-2.0500011e+00 -4.7683716e-07  1.0000000e+00]\n",
      "13: GT, [-2.0500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "14: True, [-1.9500011e+00 -4.7683716e-07  1.0000000e+00]\n",
      "14: GT, [-1.9500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "15: True, [-1.8500011e+00 -4.7683716e-07  1.0000000e+00]\n",
      "15: GT, [-1.8500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "16: True, [-1.7500011e+00 -4.7683716e-07  1.0000000e+00]\n",
      "16: GT, [-1.7500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "17: True, [-1.6500010e+00 -4.7683716e-07  1.0000000e+00]\n",
      "17: GT, [-1.6500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "18: True, [-1.5500010e+00 -4.7683716e-07  1.0000000e+00]\n",
      "18: GT, [-1.5500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "19: True, [-1.4500010e+00 -4.7683716e-07  1.0000000e+00]\n",
      "19: GT, [-1.4500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "20: True, [-1.3500010e+00 -4.7683716e-07  1.0000000e+00]\n",
      "20: GT, [-1.3500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "21: True, [-1.2500010e+00 -4.7683716e-07  1.0000000e+00]\n",
      "21: GT, [-1.2500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "22: True, [-1.1500009e+00 -4.7683716e-07  1.0000000e+00]\n",
      "22: GT, [-1.1500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "23: True, [-1.0500009e+00 -4.7683716e-07  1.0000000e+00]\n",
      "23: GT, [-1.0500000e+00 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "24: False, [-9.5000088e-01 -4.7683716e-07  1.0000000e+00]\n",
      "24: GT, [-9.4999999e-01 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "25: False, [-8.5000086e-01 -4.7683716e-07  1.0000000e+00]\n",
      "25: GT, [-8.5000002e-01 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "26: False, [-7.5000083e-01 -4.7683716e-07  1.0000000e+00]\n",
      "26: GT, [-7.5000000e-01 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "27: False, [-6.5000081e-01 -4.7683716e-07  1.0000000e+00]\n",
      "27: GT, [-6.4999998e-01 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "28: False, [-5.5000079e-01 -4.7683716e-07  1.0000000e+00]\n",
      "28: GT, [-5.5000001e-01 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "29: False, [-4.5000076e-01 -4.7683716e-07  1.0000000e+00]\n",
      "29: GT, [-4.4999999e-01 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "30: False, [-3.5000074e-01 -4.7683716e-07  1.0000000e+00]\n",
      "30: GT, [-3.4999999e-01 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "31: False, [-2.5000072e-01 -4.7683716e-07  1.0000000e+00]\n",
      "31: GT, [-2.5000000e-01 -4.7683716e-07  1.0000000e+00]\n",
      "\n",
      "32: False, [-1.5000071e-01 -4.7683716e-07  1.0000000e+00]\n",
      "32: GT, [-0.29495245  0.00678444  1.0067847 ]\n",
      "\n",
      "33: False, [-5.0000697e-02 -4.7683716e-07  1.0000000e+00]\n",
      "33: GT, [-0.39834243  0.01717424  1.0171742 ]\n",
      "\n",
      "34: False, [ 4.9999312e-02 -4.7683716e-07  1.0000000e+00]\n",
      "34: GT, [-0.5017324  0.0275631  1.0275636]\n",
      "\n",
      "35: False, [ 1.4999932e-01 -4.7683716e-07  1.0000000e+00]\n",
      "35: GT, [-0.6051224   0.03795338  1.0379531 ]\n",
      "\n",
      "36: False, [ 2.4999933e-01 -4.7683716e-07  1.0000000e+00]\n",
      "36: GT, [-0.70851237  0.0483427   1.0483427 ]\n",
      "\n",
      "37: False, [ 3.4999934e-01 -4.7683716e-07  1.0000000e+00]\n",
      "37: GT, [-0.81190234  0.05873203  1.0587323 ]\n",
      "\n",
      "38: False, [ 4.4999933e-01 -4.7683716e-07  1.0000000e+00]\n",
      "38: GT, [-0.9152923   0.06912136  1.0691218 ]\n",
      "\n",
      "39: False, [ 5.4999936e-01 -4.7683716e-07  1.0000000e+00]\n",
      "39: GT, [-1.0186824   0.07951117  1.0795114 ]\n",
      "\n",
      "40: False, [ 6.4999938e-01 -4.7683716e-07  1.0000000e+00]\n",
      "40: GT, [-1.1220723   0.08990097  1.089901  ]\n",
      "\n",
      "41: False, [ 7.4999940e-01 -4.7683716e-07  1.0000000e+00]\n",
      "41: GT, [-1.2254623  0.1002903  1.1002903]\n",
      "\n",
      "42: True, [ 8.4999943e-01 -4.7683716e-07  1.0000000e+00]\n",
      "42: GT, [-1.3288523   0.11067963  1.1106799 ]\n",
      "\n",
      "43: True, [ 1.0499995e+00 -4.7683716e-07  1.0000000e+00]\n",
      "43: GT, [-1.4322423   0.12106943  1.1210694 ]\n",
      "\n",
      "44: True, [ 1.2499995 -0.0999999  0.9      ]\n",
      "44: GT, [-1.5356323   0.13145924  1.131459  ]\n",
      "\n",
      "45: True, [ 1.4499996  -0.0999999   0.79999995]\n",
      "45: GT, [-1.6390222   0.14184809  1.1418486 ]\n",
      "\n",
      "46: True, [ 1.6499996  -0.0999999   0.79999995]\n",
      "46: GT, [-1.7424122   0.15223837  1.1522381 ]\n",
      "\n",
      "47: True, [ 1.8499997  -0.0999999   0.79999995]\n",
      "47: GT, [-1.8458022  0.1626277  1.1626277]\n",
      "\n",
      "48: True, [ 1.9499997  -0.19999981  0.8       ]\n",
      "48: GT, [-1.9491922   0.17301702  1.173017  ]\n",
      "\n",
      "49: True, [ 2.0499997  -0.19999981  0.8       ]\n",
      "49: GT, [-2.0525823   0.18340635  1.1834066 ]\n",
      "\n",
      "50: True, [ 2.1499996  -0.19999981  0.8       ]\n",
      "50: GT, [-2.1559722   0.19379616  1.1937962 ]\n",
      "\n",
      "51: True, [ 2.2499995  -0.19999981  0.8       ]\n",
      "51: GT, [-2.2593622   0.20418549  1.2041857 ]\n",
      "\n",
      "52: True, [ 2.3499994  -0.19999981  0.8       ]\n",
      "52: GT, [-2.3627522   0.21457529  1.2145753 ]\n",
      "\n",
      "53: True, [ 2.4499993  -0.19999981  0.8       ]\n",
      "53: GT, [-2.4661422   0.22496414  1.2249649 ]\n",
      "\n",
      "54: True, [ 2.5499992  -0.19999981  0.8       ]\n",
      "54: GT, [-2.5695322   0.23535442  1.2353543 ]\n",
      "\n",
      "55: True, [ 2.6499991  -0.19999981  0.8       ]\n",
      "55: GT, [-2.6729221   0.24574375  1.2457438 ]\n",
      "\n",
      "Time elapsed: 3.238206624984741\n",
      "FPS: 16.984709862440962\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(p)\n",
    "inference_program = jax.jit(lambda p,x: jax.lax.scan(\n",
    "    update_pose_estimate, \n",
    "    (jnp.tile(p, (x.shape[0]+1,1,1)),1),\n",
    "    x)[1])\n",
    "\n",
    "start = time.time()\n",
    "inferred_poses = inference_program(gt_poses[0], gt_images)\n",
    "end = time.time()\n",
    "print (\"Time elapsed:\", end - start)\n",
    "print (\"FPS:\", gt_poses.shape[0] / (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 2, 4, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_images = []\n",
    "max_depth = 10.0\n",
    "\n",
    "# inferred_poses_with_occ = jnp.stack([inferred_poses, occ1_poses], axis = 1)\n",
    "occ_image = b.viz.get_depth_image(b.RENDERER.render(occ1_pose[None,...], jnp.array([2]))[:,:,2])\n",
    "\n",
    "pred_images = b.RENDERER.render_many(inferred_poses[:,None, ...], jnp.array([0]))\n",
    "\n",
    "pred_with_occ_images = [b.overlay_image(b.viz.get_depth_image(pred_images[i,:,:,2]), \n",
    "occ_image, alpha=0.4) for i in range(pred_images.shape[0])]\n",
    "\n",
    "# gt_images = b.RENDERER.render_many(gt_poses[:,None, ...], jnp.array([0]))\n",
    "gt_images = b.RENDERER.render_many(total_gt_poses[:,:2,:,:],jnp.array([0,1]))\n",
    "gt_with_occ_images = [b.overlay_image(b.viz.get_depth_image(gt_images[i,:,:,2]), occ_image, alpha=0.5) for i in range(pred_images.shape[0])]\n",
    "\n",
    "viz_images = [\n",
    "    b.viz.multi_panel(\n",
    "        [g, b.viz.get_depth_image(p[:,:,2]), po],\n",
    "        labels = [\"Ground Truth\", \"Reconstruction w/o Occluder\", \"Reconstruction w Occluder\"],\n",
    "        title = \"Collision Scene Demo\",\n",
    "        # bottom_text = \"3DP3 + Physics Prior v1\"\n",
    "    )\n",
    "    for (g, p, po) in zip(gt_with_occ_images, pred_images, pred_with_occ_images)\n",
    "]\n",
    "# display_video(viz_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(images, filename, fps = 10):\n",
    "    duration = int(1000/fps)\n",
    "    images[0].save(\n",
    "        fp=filename,\n",
    "        format=\"GIF\",\n",
    "        append_images=images,\n",
    "        save_all=True,\n",
    "        duration=duration,\n",
    "        loop=0,\n",
    "    )\n",
    "\n",
    "make_gif(viz_images, \"scene_gifs/collision_scene_demo.gif\", fps=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
